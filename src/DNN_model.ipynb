{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "运营商竞赛",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "jDlWh8xKWiPG"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ItXfxkxvosLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Contract plans classification "
      ]
    },
    {
      "metadata": {
        "id": "Eg62Pmz3o83v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "运营商竞赛主页：https://www.datafountain.cn/competitions/311/details/data-evaluation\n",
        "\n",
        "csdn用户分享该竞赛的处理方法：https://blog.csdn.net/sjz_hahalala479/article/details/82878183\n",
        "\n",
        "This notebook classifies movie reviews as *positive* or *negative* using the text of the review. This is an example of five-class—classification, an important and widely applicable kind of machine learning problem. \n",
        "\n",
        "\n",
        "This notebook uses [tf.keras](https://www.tensorflow.org/guide/keras), a high-level API to build and train models in TensorFlow. For a more advanced text classification tutorial using `tf.keras`, see the [MLCC Text Classification Guide](https://developers.google.com/machine-learning/guides/text-classification/)."
      ]
    },
    {
      "metadata": {
        "id": "2ew7HTbPpCJH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a5f0daa-2fae-4b1f-d4b5-b46cbcae239b"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iAsKG535pHep",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Get the dataset\n",
        "\n",
        "如果不在线读取csv文件，需要在左边栏文件选项卡处，上传csv格式的数据\n",
        "\n",
        "如果从谷歌云盘存取文件的话，参考链接https://www.jianshu.com/p/d7283bc427b1           https://blog.csdn.net/popoffpopoff/article/details/81942023"
      ]
    },
    {
      "metadata": {
        "id": "L3ZJL9Efz9Nw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# upload datas.csv first\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import  OneHotEncoder\n",
        "\n",
        "#data = pd.read_csv(\"datas.csv\") # https://www.cnblogs.com/guochangyu/p/7788414.html\n",
        "data = pd.read_csv(\"https://github.com/zefang/Mobile-carrier-competition/raw/master/datas.csv\") # read online data https://blog.csdn.net/Maverick_7/article/details/79026887\n",
        "#data.head()\n",
        "test_data = pd.read_csv(\"https://github.com/never770/mobile/raw/master/test_datas.csv\")\n",
        "test_data = test_data.drop(['user_id'], axis=1) #Xnew = predict_data.iloc[:, 2:(predict_data.shape[1])].as_matrix()\n",
        "for test_column_name in test_data.columns:\n",
        "  test_column = test_data[test_column_name]\n",
        "  train_column = data[test_column_name]\n",
        "  train_column_list = (train_column<=np.max(test_column)).tolist() and (train_column>=np.min(test_column)).tolist()\n",
        "  data = data[train_column_list]\n",
        "\n",
        "#x,y = data.drop(['user_id','current_service','service_type'], axis=1).as_matrix(),data.loc[:,'service_type'].as_matrix() # https://blog.csdn.net/sinat_29957455/article/details/79477940\n",
        "#x,y = data.drop(['user_id','current_service','service_type','is_mix_service','many_over_bill','contract_type','is_promise_low_consume','net_service','complaint_level','gender'], axis=1).as_matrix(),data.loc[:,'current_service'].as_matrix() # https://blog.csdn.net/sinat_29957455/article/details/79477940\n",
        "x,y = data.drop(['user_id','current_service'], axis=1).as_matrix(),data.loc[:,'current_service'].as_matrix() \n",
        "\n",
        "#enc = OneHotEncoder(sparse=False,categorical_features = [17,18,19,20,21,22,23,24])\n",
        "#enc.fit(x)\n",
        "#x = enc.transform(x)\n",
        "\n",
        "# change gender to onehot\n",
        "#x = np.column_stack((x[:,:-1],x[:,:-1]-1))\n",
        "\n",
        "class_label = LabelEncoder() # https://blog.csdn.net/sinat_29957455/article/details/79452141\n",
        "y = class_label.fit_transform(y)\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(x,y,test_size=0.2,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "23yjvY1xhy31",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l50X3GfjpU4r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Explore the data \n",
        "\n",
        "Let's take a moment to understand the format of the data. The dataset comes preprocessed: each example is an array of integers representing the words of the movie review. Each label is an integer value of either 0 or 1, where 0 is a negative review, and 1 is a positive review."
      ]
    },
    {
      "metadata": {
        "id": "y8qCnve_-lkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "460018e8-fed5-4db7-c73c-fda4f201d48a"
      },
      "cell_type": "code",
      "source": [
        "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training entries: 594288, labels: 594288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RnKvHWW4-lkW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The text of reviews have been converted to integers, where each integer represents a specific word in a dictionary. Here's what the first review looks like:"
      ]
    },
    {
      "metadata": {
        "id": "QtTS4kpEpjbi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "f98a0b7d-c417-4776-b099-9453720ab261"
      },
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.78892427e+03 3.60000000e+01 5.10000000e+01 6.04000000e+01\n",
            " 4.60000000e+01 3.00000000e+01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.40000000e+01\n",
            " 3.00000000e+01 1.00000000e+00 0.00000000e+00 1.24316667e+02\n",
            " 9.78582849e+01 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 4.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hIE4l_72x7DP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Movie reviews may be different lengths. The below code shows the number of words in the first and second reviews. Since inputs to a neural network must be the same length, we'll need to resolve this later."
      ]
    },
    {
      "metadata": {
        "id": "X-6Ii9Pfx6Nr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a9ace14-c694-4b0b-f85e-2d52e2bfaedb"
      },
      "cell_type": "code",
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "LLC02j2g-llC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build the model\n",
        "\n",
        "The neural network is created by stacking layers—this requires two main architectural decisions:\n",
        "\n",
        "* How many layers to use in the model?\n",
        "* How many *hidden units* to use for each layer?\n",
        "\n",
        "In this example, the input data consists of an array of word-indices. The labels to predict are either 0 or 1. Let's build a model for this problem:\n",
        "\n",
        "模型参考链接：https://github.com/entron/entity-embedding-rossmann/tree/kaggle"
      ]
    },
    {
      "metadata": {
        "id": "xpKOoWgu-llD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1439
        },
        "outputId": "bbf84b41-113a-4af8-ce1f-4bafa986f778"
      },
      "cell_type": "code",
      "source": [
        "# 'service_type','is_mix_service','many_over_bill','contract_type','is_promise_low_consume','net_service','complaint_level','gender'\n",
        "\n",
        "input_continue_array = keras.layers.Input(shape=(len(train_data[0])-8,))\n",
        "\n",
        "input_service_type = keras.layers.Input(shape=(1,))\n",
        "output_service_type = keras.layers.Embedding(5,4)(input_service_type)\n",
        "output_service_type = keras.layers.Reshape(target_shape=(4,))(output_service_type)\n",
        "\n",
        "input_mix_service = keras.layers.Input(shape=(1,))\n",
        "\n",
        "input_over_bill = keras.layers.Input(shape=(1,))\n",
        "\n",
        "input_contract_type = keras.layers.Input(shape=(1,))\n",
        "output_contract_type = keras.layers.Embedding(13,7)(input_contract_type)\n",
        "output_contract_type = keras.layers.Reshape(target_shape=(7,))(output_contract_type)\n",
        "\n",
        "input_low_consume = keras.layers.Input(shape=(1,))\n",
        "\n",
        "input_net_service = keras.layers.Input(shape=(1,))\n",
        "output_net_service = keras.layers.Embedding(10,5)(input_net_service)\n",
        "output_net_service = keras.layers.Reshape(target_shape=(5,))(output_net_service)\n",
        "\n",
        "input_complaint_level = keras.layers.Input(shape=(1,))\n",
        "\n",
        "input_gender = keras.layers.Input(shape=(1,))\n",
        "\n",
        "input_model = [input_continue_array, input_service_type, input_mix_service, input_over_bill, input_contract_type, input_low_consume, input_net_service, input_complaint_level, input_gender]\n",
        "output_embeding = [input_continue_array, output_service_type, input_mix_service, input_over_bill, output_contract_type, input_low_consume, output_net_service, input_complaint_level, input_gender]\n",
        "output_model = keras.layers.Concatenate()(output_embeding)\n",
        "output_model = keras.layers.BatchNormalization()(output_model)\n",
        "#output_model = keras.layers.Dropout(0.05)(output_model)\n",
        "output_model = keras.layers.Dense(64, activation=tf.nn.relu)(output_model)\n",
        "output_model = keras.layers.BatchNormalization()(output_model)\n",
        "\n",
        "# Residual Unit https://blog.csdn.net/loveliuzz/article/details/79117397\n",
        "output_model_shortcut = output_model\n",
        "output_model = keras.layers.Dense(64, activation=tf.nn.relu)(output_model)\n",
        "#output_model = keras.layers.Dropout(0.05)(output_model)\n",
        "output_model = keras.layers.Dense(64)(output_model)\n",
        "output_model = keras.layers.BatchNormalization()(output_model)\n",
        "output_model = keras.layers.add([output_model_shortcut,output_model])\n",
        "output_model = keras.layers.Activation(\"relu\")(output_model)\n",
        "\n",
        "# Residual Unit\n",
        "output_model_shortcut = output_model\n",
        "output_model = keras.layers.Dense(64, activation=tf.nn.relu)(output_model)\n",
        "#output_model = keras.layers.Dropout(0.05)(output_model)\n",
        "output_model = keras.layers.Dense(64)(output_model)\n",
        "output_model = keras.layers.BatchNormalization()(output_model)\n",
        "output_model = keras.layers.add([output_model_shortcut,output_model])\n",
        "output_model = keras.layers.Activation(\"relu\")(output_model)\n",
        "\n",
        "output_model = keras.layers.Dense(128, activation=tf.nn.relu)(output_model)\n",
        "\n",
        "output_model = keras.layers.Dense(11, activation=tf.nn.sigmoid)(output_model)\n",
        "\n",
        "model = keras.models.Model(inputs=input_model, outputs=output_model)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1, 4)         20          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 1, 7)         91          input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 1, 5)         50          input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            (None, 17)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 4)            0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 7)            0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 5)            0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
            "                                                                 reshape[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "                                                                 reshape_1[0][0]                  \n",
            "                                                                 input_6[0][0]                    \n",
            "                                                                 reshape_2[0][0]                  \n",
            "                                                                 input_8[0][0]                    \n",
            "                                                                 input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 38)           152         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 64)           2496        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 64)           256         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           4160        batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 64)           4160        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64)           256         dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 64)           0           batch_normalization_1[0][0]      \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 64)           0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 64)           4160        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 64)           4160        dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64)           256         dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 64)           0           activation[0][0]                 \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 64)           0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 128)          8320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 11)           1419        dense_5[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 29,956\n",
            "Trainable params: 29,496\n",
            "Non-trainable params: 460\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EjcT77VbEGLp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6PbKQ6mucuKL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The layers are stacked sequentially to build the classifier:\n",
        "\n",
        "1. The first layer is an `Embedding` layer. This layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: `(batch, sequence, embedding)`.\n",
        "2. Next, a `GlobalAveragePooling1D` layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model can handle input of variable length, in the simplest way possible.\n",
        "3. This fixed-length output vector is piped through a fully-connected (`Dense`) layer with 16 hidden units.\n",
        "4. The last layer is densely connected with a single output node. Using the `sigmoid` activation function, this value is a float between 0 and 1, representing a probability, or confidence level."
      ]
    },
    {
      "metadata": {
        "id": "0XMwnDOp-llH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Hidden units\n",
        "\n",
        "The above model has two intermediate or \"hidden\" layers, between the input and output. The number of outputs (units, nodes, or neurons) is the dimension of the representational space for the layer. In other words, the amount of freedom the network is allowed when learning an internal representation.\n",
        "\n",
        "If a model has more hidden units (a higher-dimensional representation space), and/or more layers, then the network can learn more complex representations. However, it makes the network more computationally expensive and may lead to learning unwanted patterns—patterns that improve performance on training data but not on the test data. This is called *overfitting*, and we'll explore it later."
      ]
    },
    {
      "metadata": {
        "id": "L4EqVWg4-llM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loss function and optimizer\n",
        "\n",
        "A model needs a loss function and an optimizer for training. Since this is a binary classification problem and the model outputs of a probability (a single-unit layer with a sigmoid activation), we'll use the `binary_crossentropy` loss function. \n",
        "\n",
        "This isn't the only choice for a loss function, you could, for instance, choose `mean_squared_error`. But, generally, `binary_crossentropy` is better for dealing with probabilities—it measures the \"distance\" between probability distributions, or in our case, between the ground-truth distribution and the predictions.\n",
        "\n",
        "Later, when we are exploring regression problems (say, to predict the price of a house), we will see how to use another loss function called mean squared error.\n",
        "\n",
        "Now, configure the model to use an optimizer and a loss function:"
      ]
    },
    {
      "metadata": {
        "id": "Mr0GP-cQ-llN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hCWYwkug-llQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create a validation set\n",
        "\n",
        "When training, we want to check the accuracy of the model on data it hasn't seen before. Create a *validation set* by setting apart 10,000 examples from the original training data. (Why not use the testing set now? Our goal is to develop and tune our model using only the training data, then use the test data just once to evaluate our accuracy)."
      ]
    },
    {
      "metadata": {
        "id": "-NpcXY9--llS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_val = train_data[:10000]\n",
        "partial_x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "35jv_fzP-llU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "\n",
        "Train the model for 40 epochs in mini-batches of 512 samples. This is 40 iterations over all samples in the `x_train` and `y_train` tensors. While training, monitor the model's loss and accuracy on the 10,000 samples from the validation set:"
      ]
    },
    {
      "metadata": {
        "id": "aJVj0LB_IsBp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def split_features(X):\n",
        "    X_list = []\n",
        "\n",
        "    store_index = X[..., :-8]\n",
        "    X_list.append(store_index)\n",
        "    \n",
        "    day_of_week = X[..., [-8]]\n",
        "    X_list.append(day_of_week)\n",
        "\n",
        "    promo = X[..., [-7]]\n",
        "    X_list.append(promo)\n",
        "    \n",
        "    day_of_week = X[..., [-6]]\n",
        "    X_list.append(day_of_week)\n",
        "\n",
        "    promo = X[..., [-5]]\n",
        "    X_list.append(promo)\n",
        "\n",
        "    year = X[..., [-4]]\n",
        "    X_list.append(year)\n",
        "\n",
        "    month = X[..., [-3]]\n",
        "    X_list.append(month)\n",
        "\n",
        "    day = X[..., [-2]]\n",
        "    X_list.append(day)\n",
        "\n",
        "    State = X[..., [-1]] # change gender to onehot \n",
        "    X_list.append(State)\n",
        "\n",
        "    return X_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tXSGrjWZ-llW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83339
        },
        "outputId": "a1b8539a-c225-4e3c-85cb-3e09b617714a"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(split_features(partial_x_train),\n",
        "                    partial_y_train,\n",
        "                    epochs=6000,\n",
        "                    batch_size=256,\n",
        "                    validation_data=([split_features(x_val), y_val]),\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 584288 samples, validate on 10000 samples\n",
            "Epoch 1/6000\n",
            "584288/584288 [==============================] - 20s 34us/step - loss: 0.4939 - acc: 0.8087 - val_loss: 0.3705 - val_acc: 0.8552\n",
            "Epoch 2/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.3772 - acc: 0.8534 - val_loss: 0.3383 - val_acc: 0.8699\n",
            "Epoch 3/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.3473 - acc: 0.8653 - val_loss: 0.3242 - val_acc: 0.8783\n",
            "Epoch 4/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.3303 - acc: 0.8724 - val_loss: 0.3204 - val_acc: 0.8726\n",
            "Epoch 5/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.3178 - acc: 0.8773 - val_loss: 0.2982 - val_acc: 0.8834\n",
            "Epoch 6/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.3085 - acc: 0.8811 - val_loss: 0.2807 - val_acc: 0.8928\n",
            "Epoch 7/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.3004 - acc: 0.8841 - val_loss: 0.2868 - val_acc: 0.8870\n",
            "Epoch 8/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2957 - acc: 0.8861 - val_loss: 0.2823 - val_acc: 0.8925\n",
            "Epoch 9/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2906 - acc: 0.8885 - val_loss: 0.2785 - val_acc: 0.8919\n",
            "Epoch 10/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2866 - acc: 0.8898 - val_loss: 0.2790 - val_acc: 0.8926\n",
            "Epoch 11/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2824 - acc: 0.8917 - val_loss: 0.2719 - val_acc: 0.8947\n",
            "Epoch 12/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2799 - acc: 0.8927 - val_loss: 0.2781 - val_acc: 0.8941\n",
            "Epoch 13/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2779 - acc: 0.8932 - val_loss: 0.2669 - val_acc: 0.8988\n",
            "Epoch 14/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2748 - acc: 0.8946 - val_loss: 0.2702 - val_acc: 0.8957\n",
            "Epoch 15/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2715 - acc: 0.8960 - val_loss: 0.2690 - val_acc: 0.8939\n",
            "Epoch 16/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2701 - acc: 0.8962 - val_loss: 0.2733 - val_acc: 0.8947\n",
            "Epoch 17/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2687 - acc: 0.8972 - val_loss: 0.2738 - val_acc: 0.8947\n",
            "Epoch 18/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2661 - acc: 0.8978 - val_loss: 0.2727 - val_acc: 0.8956\n",
            "Epoch 19/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2647 - acc: 0.8986 - val_loss: 0.2726 - val_acc: 0.8919\n",
            "Epoch 20/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2626 - acc: 0.8993 - val_loss: 0.2698 - val_acc: 0.8957\n",
            "Epoch 21/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2610 - acc: 0.8999 - val_loss: 0.2618 - val_acc: 0.8979\n",
            "Epoch 22/6000\n",
            "584288/584288 [==============================] - 20s 34us/step - loss: 0.2602 - acc: 0.8999 - val_loss: 0.2595 - val_acc: 0.8996\n",
            "Epoch 23/6000\n",
            "584288/584288 [==============================] - 17s 28us/step - loss: 0.2583 - acc: 0.9008 - val_loss: 0.2731 - val_acc: 0.8939\n",
            "Epoch 24/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.2577 - acc: 0.9012 - val_loss: 0.2572 - val_acc: 0.9003\n",
            "Epoch 25/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.2551 - acc: 0.9021 - val_loss: 0.2701 - val_acc: 0.8953\n",
            "Epoch 26/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.2548 - acc: 0.9023 - val_loss: 0.2636 - val_acc: 0.8963\n",
            "Epoch 27/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2532 - acc: 0.9029 - val_loss: 0.2635 - val_acc: 0.8989\n",
            "Epoch 28/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2518 - acc: 0.9034 - val_loss: 0.2786 - val_acc: 0.8905\n",
            "Epoch 29/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2513 - acc: 0.9040 - val_loss: 0.2619 - val_acc: 0.8972\n",
            "Epoch 30/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2505 - acc: 0.9041 - val_loss: 0.2788 - val_acc: 0.8951\n",
            "Epoch 31/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.2495 - acc: 0.9047 - val_loss: 0.2541 - val_acc: 0.9043\n",
            "Epoch 32/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2474 - acc: 0.9052 - val_loss: 0.2638 - val_acc: 0.8974\n",
            "Epoch 33/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2477 - acc: 0.9053 - val_loss: 0.2561 - val_acc: 0.9003\n",
            "Epoch 34/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2479 - acc: 0.9049 - val_loss: 0.2530 - val_acc: 0.9049\n",
            "Epoch 35/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2454 - acc: 0.9058 - val_loss: 0.2619 - val_acc: 0.8969\n",
            "Epoch 36/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2444 - acc: 0.9063 - val_loss: 0.2610 - val_acc: 0.8995\n",
            "Epoch 37/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2447 - acc: 0.9059 - val_loss: 0.2463 - val_acc: 0.9084\n",
            "Epoch 38/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.2426 - acc: 0.9067 - val_loss: 0.2586 - val_acc: 0.9001\n",
            "Epoch 39/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2422 - acc: 0.9070 - val_loss: 0.2611 - val_acc: 0.8997\n",
            "Epoch 40/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2426 - acc: 0.9069 - val_loss: 0.2538 - val_acc: 0.9039\n",
            "Epoch 41/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2415 - acc: 0.9073 - val_loss: 0.2508 - val_acc: 0.9032\n",
            "Epoch 42/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2410 - acc: 0.9077 - val_loss: 0.2531 - val_acc: 0.9022\n",
            "Epoch 43/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2417 - acc: 0.9071 - val_loss: 0.2588 - val_acc: 0.9036\n",
            "Epoch 44/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2395 - acc: 0.9081 - val_loss: 0.2795 - val_acc: 0.8943\n",
            "Epoch 45/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2396 - acc: 0.9081 - val_loss: 0.2487 - val_acc: 0.9072\n",
            "Epoch 46/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2385 - acc: 0.9084 - val_loss: 0.2527 - val_acc: 0.9040\n",
            "Epoch 47/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2379 - acc: 0.9089 - val_loss: 0.2471 - val_acc: 0.9065\n",
            "Epoch 48/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2376 - acc: 0.9085 - val_loss: 0.2623 - val_acc: 0.8992\n",
            "Epoch 49/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2368 - acc: 0.9092 - val_loss: 0.2663 - val_acc: 0.8984\n",
            "Epoch 50/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2361 - acc: 0.9096 - val_loss: 0.2564 - val_acc: 0.9030\n",
            "Epoch 51/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2354 - acc: 0.9099 - val_loss: 0.2512 - val_acc: 0.9041\n",
            "Epoch 52/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2357 - acc: 0.9094 - val_loss: 0.2514 - val_acc: 0.9045\n",
            "Epoch 53/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2355 - acc: 0.9096 - val_loss: 0.2702 - val_acc: 0.8966\n",
            "Epoch 54/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2346 - acc: 0.9098 - val_loss: 0.2583 - val_acc: 0.9011\n",
            "Epoch 55/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2342 - acc: 0.9105 - val_loss: 0.2462 - val_acc: 0.9083\n",
            "Epoch 56/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2338 - acc: 0.9105 - val_loss: 0.2502 - val_acc: 0.9055\n",
            "Epoch 57/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2334 - acc: 0.9108 - val_loss: 0.2489 - val_acc: 0.9069\n",
            "Epoch 58/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2329 - acc: 0.9105 - val_loss: 0.2532 - val_acc: 0.9046\n",
            "Epoch 59/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2331 - acc: 0.9106 - val_loss: 0.2618 - val_acc: 0.8982\n",
            "Epoch 60/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2328 - acc: 0.9106 - val_loss: 0.2539 - val_acc: 0.9032\n",
            "Epoch 61/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2313 - acc: 0.9112 - val_loss: 0.2468 - val_acc: 0.9060\n",
            "Epoch 62/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.2318 - acc: 0.9112 - val_loss: 0.2510 - val_acc: 0.9058\n",
            "Epoch 63/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2313 - acc: 0.9114 - val_loss: 0.2448 - val_acc: 0.9070\n",
            "Epoch 64/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2305 - acc: 0.9115 - val_loss: 0.2552 - val_acc: 0.9038\n",
            "Epoch 65/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2304 - acc: 0.9117 - val_loss: 0.2551 - val_acc: 0.9028\n",
            "Epoch 66/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2298 - acc: 0.9121 - val_loss: 0.2623 - val_acc: 0.9008\n",
            "Epoch 67/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2298 - acc: 0.9116 - val_loss: 0.2555 - val_acc: 0.9035\n",
            "Epoch 68/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2295 - acc: 0.9120 - val_loss: 0.2452 - val_acc: 0.9058\n",
            "Epoch 69/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2290 - acc: 0.9122 - val_loss: 0.2416 - val_acc: 0.9086\n",
            "Epoch 70/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2289 - acc: 0.9120 - val_loss: 0.2422 - val_acc: 0.9102\n",
            "Epoch 71/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2286 - acc: 0.9123 - val_loss: 0.2481 - val_acc: 0.9077\n",
            "Epoch 72/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2274 - acc: 0.9127 - val_loss: 0.2630 - val_acc: 0.9020\n",
            "Epoch 73/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2281 - acc: 0.9127 - val_loss: 0.2613 - val_acc: 0.9025\n",
            "Epoch 74/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2276 - acc: 0.9130 - val_loss: 0.2432 - val_acc: 0.9093\n",
            "Epoch 75/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2273 - acc: 0.9128 - val_loss: 0.2580 - val_acc: 0.9024\n",
            "Epoch 76/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2275 - acc: 0.9127 - val_loss: 0.2513 - val_acc: 0.9056\n",
            "Epoch 77/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2271 - acc: 0.9128 - val_loss: 0.2741 - val_acc: 0.8959\n",
            "Epoch 78/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2267 - acc: 0.9130 - val_loss: 0.2423 - val_acc: 0.9074\n",
            "Epoch 79/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2265 - acc: 0.9128 - val_loss: 0.2509 - val_acc: 0.9036\n",
            "Epoch 80/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2261 - acc: 0.9133 - val_loss: 0.2504 - val_acc: 0.9068\n",
            "Epoch 81/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2260 - acc: 0.9130 - val_loss: 0.2629 - val_acc: 0.8994\n",
            "Epoch 82/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2254 - acc: 0.9135 - val_loss: 0.2594 - val_acc: 0.9011\n",
            "Epoch 83/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2256 - acc: 0.9135 - val_loss: 0.2530 - val_acc: 0.9043\n",
            "Epoch 84/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2258 - acc: 0.9132 - val_loss: 0.2368 - val_acc: 0.9112\n",
            "Epoch 85/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2246 - acc: 0.9136 - val_loss: 0.2577 - val_acc: 0.9031\n",
            "Epoch 86/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2244 - acc: 0.9138 - val_loss: 0.2618 - val_acc: 0.9012\n",
            "Epoch 87/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2249 - acc: 0.9138 - val_loss: 0.2576 - val_acc: 0.9023\n",
            "Epoch 88/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2247 - acc: 0.9135 - val_loss: 0.2528 - val_acc: 0.9034\n",
            "Epoch 89/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2242 - acc: 0.9139 - val_loss: 0.2541 - val_acc: 0.9057\n",
            "Epoch 90/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2236 - acc: 0.9143 - val_loss: 0.2602 - val_acc: 0.9007\n",
            "Epoch 91/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2235 - acc: 0.9142 - val_loss: 0.2489 - val_acc: 0.9054\n",
            "Epoch 92/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2238 - acc: 0.9140 - val_loss: 0.2518 - val_acc: 0.9056\n",
            "Epoch 93/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2232 - acc: 0.9140 - val_loss: 0.2467 - val_acc: 0.9045\n",
            "Epoch 94/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2230 - acc: 0.9144 - val_loss: 0.2494 - val_acc: 0.9049\n",
            "Epoch 95/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2224 - acc: 0.9142 - val_loss: 0.2678 - val_acc: 0.9015\n",
            "Epoch 96/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2229 - acc: 0.9144 - val_loss: 0.2497 - val_acc: 0.9062\n",
            "Epoch 97/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2224 - acc: 0.9145 - val_loss: 0.2564 - val_acc: 0.9028\n",
            "Epoch 98/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2220 - acc: 0.9148 - val_loss: 0.2618 - val_acc: 0.8999\n",
            "Epoch 99/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2214 - acc: 0.9151 - val_loss: 0.2662 - val_acc: 0.9014\n",
            "Epoch 100/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2228 - acc: 0.9145 - val_loss: 0.2674 - val_acc: 0.9006\n",
            "Epoch 101/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2220 - acc: 0.9147 - val_loss: 0.2471 - val_acc: 0.9081\n",
            "Epoch 102/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2213 - acc: 0.9150 - val_loss: 0.2643 - val_acc: 0.8997\n",
            "Epoch 103/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2210 - acc: 0.9151 - val_loss: 0.2511 - val_acc: 0.9070\n",
            "Epoch 104/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2213 - acc: 0.9150 - val_loss: 0.2656 - val_acc: 0.9013\n",
            "Epoch 105/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2213 - acc: 0.9148 - val_loss: 0.2513 - val_acc: 0.9043\n",
            "Epoch 106/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2217 - acc: 0.9146 - val_loss: 0.2536 - val_acc: 0.9051\n",
            "Epoch 107/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2203 - acc: 0.9150 - val_loss: 0.2570 - val_acc: 0.9030\n",
            "Epoch 108/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2204 - acc: 0.9149 - val_loss: 0.2703 - val_acc: 0.8984\n",
            "Epoch 109/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2201 - acc: 0.9155 - val_loss: 0.2737 - val_acc: 0.8976\n",
            "Epoch 110/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2202 - acc: 0.9152 - val_loss: 0.2646 - val_acc: 0.9020\n",
            "Epoch 111/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2198 - acc: 0.9153 - val_loss: 0.2577 - val_acc: 0.9047\n",
            "Epoch 112/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2196 - acc: 0.9155 - val_loss: 0.2702 - val_acc: 0.8987\n",
            "Epoch 113/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2199 - acc: 0.9155 - val_loss: 0.2498 - val_acc: 0.9021\n",
            "Epoch 114/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2194 - acc: 0.9150 - val_loss: 0.2714 - val_acc: 0.8973\n",
            "Epoch 115/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2196 - acc: 0.9153 - val_loss: 0.2594 - val_acc: 0.9005\n",
            "Epoch 116/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2194 - acc: 0.9156 - val_loss: 0.2578 - val_acc: 0.9023\n",
            "Epoch 117/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2185 - acc: 0.9161 - val_loss: 0.2904 - val_acc: 0.8922\n",
            "Epoch 118/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2190 - acc: 0.9159 - val_loss: 0.2558 - val_acc: 0.9017\n",
            "Epoch 119/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2187 - acc: 0.9161 - val_loss: 0.2749 - val_acc: 0.8966\n",
            "Epoch 120/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2192 - acc: 0.9154 - val_loss: 0.2485 - val_acc: 0.9074\n",
            "Epoch 121/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2186 - acc: 0.9158 - val_loss: 0.2707 - val_acc: 0.8999\n",
            "Epoch 122/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2187 - acc: 0.9159 - val_loss: 0.2632 - val_acc: 0.8999\n",
            "Epoch 123/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2182 - acc: 0.9161 - val_loss: 0.2807 - val_acc: 0.8980\n",
            "Epoch 124/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.2180 - acc: 0.9161 - val_loss: 0.2527 - val_acc: 0.9060\n",
            "Epoch 125/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.2181 - acc: 0.9159 - val_loss: 0.2718 - val_acc: 0.8978\n",
            "Epoch 126/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.2184 - acc: 0.9159 - val_loss: 0.2532 - val_acc: 0.9054\n",
            "Epoch 127/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2171 - acc: 0.9166 - val_loss: 0.2780 - val_acc: 0.8954\n",
            "Epoch 128/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2175 - acc: 0.9163 - val_loss: 0.2690 - val_acc: 0.8984\n",
            "Epoch 129/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2178 - acc: 0.9161 - val_loss: 0.2673 - val_acc: 0.9001\n",
            "Epoch 130/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2172 - acc: 0.9165 - val_loss: 0.2779 - val_acc: 0.8975\n",
            "Epoch 131/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2171 - acc: 0.9163 - val_loss: 0.2615 - val_acc: 0.9020\n",
            "Epoch 132/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2173 - acc: 0.9165 - val_loss: 0.2516 - val_acc: 0.9037\n",
            "Epoch 133/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.2175 - acc: 0.9162 - val_loss: 0.2706 - val_acc: 0.9011\n",
            "Epoch 134/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2164 - acc: 0.9165 - val_loss: 0.2869 - val_acc: 0.8973\n",
            "Epoch 135/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2166 - acc: 0.9166 - val_loss: 0.2596 - val_acc: 0.9057\n",
            "Epoch 136/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2161 - acc: 0.9166 - val_loss: 0.2670 - val_acc: 0.8997\n",
            "Epoch 137/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2165 - acc: 0.9167 - val_loss: 0.2589 - val_acc: 0.9033\n",
            "Epoch 138/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2158 - acc: 0.9171 - val_loss: 0.2706 - val_acc: 0.8979\n",
            "Epoch 139/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2159 - acc: 0.9164 - val_loss: 0.2587 - val_acc: 0.9031\n",
            "Epoch 140/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2163 - acc: 0.9168 - val_loss: 0.2580 - val_acc: 0.9061\n",
            "Epoch 141/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2160 - acc: 0.9168 - val_loss: 0.2580 - val_acc: 0.9026\n",
            "Epoch 142/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2159 - acc: 0.9171 - val_loss: 0.2563 - val_acc: 0.9052\n",
            "Epoch 143/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2155 - acc: 0.9169 - val_loss: 0.2667 - val_acc: 0.8998\n",
            "Epoch 144/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2152 - acc: 0.9173 - val_loss: 0.2574 - val_acc: 0.9034\n",
            "Epoch 145/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.2156 - acc: 0.9167 - val_loss: 0.2731 - val_acc: 0.9003\n",
            "Epoch 146/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2152 - acc: 0.9171 - val_loss: 0.2640 - val_acc: 0.9029\n",
            "Epoch 147/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2154 - acc: 0.9173 - val_loss: 0.2749 - val_acc: 0.8975\n",
            "Epoch 148/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2149 - acc: 0.9173 - val_loss: 0.2970 - val_acc: 0.8924\n",
            "Epoch 149/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2147 - acc: 0.9173 - val_loss: 0.2630 - val_acc: 0.9030\n",
            "Epoch 150/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2152 - acc: 0.9173 - val_loss: 0.2781 - val_acc: 0.8963\n",
            "Epoch 151/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2141 - acc: 0.9175 - val_loss: 0.2607 - val_acc: 0.9029\n",
            "Epoch 152/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2140 - acc: 0.9176 - val_loss: 0.2569 - val_acc: 0.9019\n",
            "Epoch 153/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2144 - acc: 0.9177 - val_loss: 0.2586 - val_acc: 0.9038\n",
            "Epoch 154/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2150 - acc: 0.9173 - val_loss: 0.2837 - val_acc: 0.8941\n",
            "Epoch 155/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2144 - acc: 0.9175 - val_loss: 0.2675 - val_acc: 0.9005\n",
            "Epoch 156/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2139 - acc: 0.9175 - val_loss: 0.2678 - val_acc: 0.8979\n",
            "Epoch 157/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2141 - acc: 0.9177 - val_loss: 0.2529 - val_acc: 0.9065\n",
            "Epoch 158/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2146 - acc: 0.9174 - val_loss: 0.2982 - val_acc: 0.8939\n",
            "Epoch 159/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2143 - acc: 0.9174 - val_loss: 0.2637 - val_acc: 0.8988\n",
            "Epoch 160/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2141 - acc: 0.9177 - val_loss: 0.2536 - val_acc: 0.9039\n",
            "Epoch 161/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2135 - acc: 0.9179 - val_loss: 0.2493 - val_acc: 0.9048\n",
            "Epoch 162/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2143 - acc: 0.9175 - val_loss: 0.3018 - val_acc: 0.8895\n",
            "Epoch 163/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2132 - acc: 0.9178 - val_loss: 0.2959 - val_acc: 0.8904\n",
            "Epoch 164/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2138 - acc: 0.9174 - val_loss: 0.2739 - val_acc: 0.8971\n",
            "Epoch 165/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2131 - acc: 0.9182 - val_loss: 0.2613 - val_acc: 0.9012\n",
            "Epoch 166/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2134 - acc: 0.9176 - val_loss: 0.2635 - val_acc: 0.9009\n",
            "Epoch 167/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2137 - acc: 0.9177 - val_loss: 0.2619 - val_acc: 0.8995\n",
            "Epoch 168/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2134 - acc: 0.9178 - val_loss: 0.2705 - val_acc: 0.9001\n",
            "Epoch 169/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2128 - acc: 0.9180 - val_loss: 0.2557 - val_acc: 0.9043\n",
            "Epoch 170/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2131 - acc: 0.9178 - val_loss: 0.2707 - val_acc: 0.8986\n",
            "Epoch 171/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2129 - acc: 0.9180 - val_loss: 0.2576 - val_acc: 0.9035\n",
            "Epoch 172/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2125 - acc: 0.9180 - val_loss: 0.2791 - val_acc: 0.8954\n",
            "Epoch 173/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2125 - acc: 0.9182 - val_loss: 0.2751 - val_acc: 0.8984\n",
            "Epoch 174/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2133 - acc: 0.9180 - val_loss: 0.2879 - val_acc: 0.8959\n",
            "Epoch 175/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2118 - acc: 0.9184 - val_loss: 0.2729 - val_acc: 0.8970\n",
            "Epoch 176/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2124 - acc: 0.9181 - val_loss: 0.2572 - val_acc: 0.9040\n",
            "Epoch 177/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2117 - acc: 0.9183 - val_loss: 0.3042 - val_acc: 0.8927\n",
            "Epoch 178/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2128 - acc: 0.9179 - val_loss: 0.2771 - val_acc: 0.8988\n",
            "Epoch 179/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2127 - acc: 0.9182 - val_loss: 0.2794 - val_acc: 0.8971\n",
            "Epoch 180/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.2121 - acc: 0.9184 - val_loss: 0.2994 - val_acc: 0.8920\n",
            "Epoch 181/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2133 - acc: 0.9180 - val_loss: 0.2782 - val_acc: 0.8971\n",
            "Epoch 182/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2118 - acc: 0.9184 - val_loss: 0.2524 - val_acc: 0.9035\n",
            "Epoch 183/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2116 - acc: 0.9188 - val_loss: 0.2624 - val_acc: 0.9023\n",
            "Epoch 184/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2119 - acc: 0.9185 - val_loss: 0.2617 - val_acc: 0.9042\n",
            "Epoch 185/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2120 - acc: 0.9184 - val_loss: 0.2541 - val_acc: 0.9055\n",
            "Epoch 186/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2120 - acc: 0.9184 - val_loss: 0.2758 - val_acc: 0.8988\n",
            "Epoch 187/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2118 - acc: 0.9185 - val_loss: 0.2782 - val_acc: 0.8976\n",
            "Epoch 188/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2113 - acc: 0.9188 - val_loss: 0.2827 - val_acc: 0.8979\n",
            "Epoch 189/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2111 - acc: 0.9188 - val_loss: 0.2507 - val_acc: 0.9064\n",
            "Epoch 190/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2115 - acc: 0.9187 - val_loss: 0.3106 - val_acc: 0.8905\n",
            "Epoch 191/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2123 - acc: 0.9183 - val_loss: 0.2534 - val_acc: 0.9034\n",
            "Epoch 192/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2107 - acc: 0.9190 - val_loss: 0.2699 - val_acc: 0.8995\n",
            "Epoch 193/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2112 - acc: 0.9189 - val_loss: 0.2623 - val_acc: 0.9027\n",
            "Epoch 194/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2107 - acc: 0.9192 - val_loss: 0.2791 - val_acc: 0.8976\n",
            "Epoch 195/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2112 - acc: 0.9189 - val_loss: 0.2523 - val_acc: 0.9064\n",
            "Epoch 196/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2113 - acc: 0.9188 - val_loss: 0.2781 - val_acc: 0.8989\n",
            "Epoch 197/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.2113 - acc: 0.9186 - val_loss: 0.2806 - val_acc: 0.8970\n",
            "Epoch 198/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2116 - acc: 0.9184 - val_loss: 0.2595 - val_acc: 0.8996\n",
            "Epoch 199/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2103 - acc: 0.9188 - val_loss: 0.2746 - val_acc: 0.8992\n",
            "Epoch 200/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2101 - acc: 0.9191 - val_loss: 0.2516 - val_acc: 0.9051\n",
            "Epoch 201/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2108 - acc: 0.9186 - val_loss: 0.2689 - val_acc: 0.8984\n",
            "Epoch 202/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2106 - acc: 0.9188 - val_loss: 0.2725 - val_acc: 0.8996\n",
            "Epoch 203/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2108 - acc: 0.9189 - val_loss: 0.2946 - val_acc: 0.8899\n",
            "Epoch 204/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2101 - acc: 0.9192 - val_loss: 0.2841 - val_acc: 0.8958\n",
            "Epoch 205/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2101 - acc: 0.9188 - val_loss: 0.2987 - val_acc: 0.8923\n",
            "Epoch 206/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2106 - acc: 0.9189 - val_loss: 0.2673 - val_acc: 0.8999\n",
            "Epoch 207/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2100 - acc: 0.9190 - val_loss: 0.2513 - val_acc: 0.9047\n",
            "Epoch 208/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2095 - acc: 0.9193 - val_loss: 0.2589 - val_acc: 0.9036\n",
            "Epoch 209/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2099 - acc: 0.9192 - val_loss: 0.2717 - val_acc: 0.8990\n",
            "Epoch 210/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2098 - acc: 0.9193 - val_loss: 0.2805 - val_acc: 0.8988\n",
            "Epoch 211/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2096 - acc: 0.9192 - val_loss: 0.2651 - val_acc: 0.8986\n",
            "Epoch 212/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2098 - acc: 0.9191 - val_loss: 0.2536 - val_acc: 0.9031\n",
            "Epoch 213/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2094 - acc: 0.9194 - val_loss: 0.2824 - val_acc: 0.8994\n",
            "Epoch 214/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2099 - acc: 0.9190 - val_loss: 0.2877 - val_acc: 0.8962\n",
            "Epoch 215/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2100 - acc: 0.9190 - val_loss: 0.2808 - val_acc: 0.8947\n",
            "Epoch 216/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2098 - acc: 0.9194 - val_loss: 0.2496 - val_acc: 0.9065\n",
            "Epoch 217/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2098 - acc: 0.9192 - val_loss: 0.2854 - val_acc: 0.8960\n",
            "Epoch 218/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2096 - acc: 0.9193 - val_loss: 0.2583 - val_acc: 0.9020\n",
            "Epoch 219/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2091 - acc: 0.9199 - val_loss: 0.2670 - val_acc: 0.8995\n",
            "Epoch 220/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2093 - acc: 0.9195 - val_loss: 0.3130 - val_acc: 0.8879\n",
            "Epoch 221/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2089 - acc: 0.9193 - val_loss: 0.2706 - val_acc: 0.8996\n",
            "Epoch 222/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2093 - acc: 0.9194 - val_loss: 0.2862 - val_acc: 0.8939\n",
            "Epoch 223/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2090 - acc: 0.9195 - val_loss: 0.2877 - val_acc: 0.8947\n",
            "Epoch 224/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2092 - acc: 0.9196 - val_loss: 0.2830 - val_acc: 0.8940\n",
            "Epoch 225/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2094 - acc: 0.9192 - val_loss: 0.2722 - val_acc: 0.8970\n",
            "Epoch 226/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2094 - acc: 0.9194 - val_loss: 0.2589 - val_acc: 0.9062\n",
            "Epoch 227/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2091 - acc: 0.9195 - val_loss: 0.2678 - val_acc: 0.8982\n",
            "Epoch 228/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2088 - acc: 0.9197 - val_loss: 0.3207 - val_acc: 0.8866\n",
            "Epoch 229/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2090 - acc: 0.9195 - val_loss: 0.2755 - val_acc: 0.8969\n",
            "Epoch 230/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2088 - acc: 0.9193 - val_loss: 0.2889 - val_acc: 0.8916\n",
            "Epoch 231/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2086 - acc: 0.9195 - val_loss: 0.2566 - val_acc: 0.9046\n",
            "Epoch 232/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.2083 - acc: 0.9198 - val_loss: 0.2636 - val_acc: 0.9019\n",
            "Epoch 233/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2088 - acc: 0.9195 - val_loss: 0.2879 - val_acc: 0.8963\n",
            "Epoch 234/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2086 - acc: 0.9198 - val_loss: 0.2682 - val_acc: 0.9033\n",
            "Epoch 235/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2093 - acc: 0.9194 - val_loss: 0.2645 - val_acc: 0.9026\n",
            "Epoch 236/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.2088 - acc: 0.9195 - val_loss: 0.2828 - val_acc: 0.8971\n",
            "Epoch 237/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2080 - acc: 0.9199 - val_loss: 0.2649 - val_acc: 0.9010\n",
            "Epoch 238/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2091 - acc: 0.9195 - val_loss: 0.2775 - val_acc: 0.8981\n",
            "Epoch 239/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2088 - acc: 0.9195 - val_loss: 0.2989 - val_acc: 0.8940\n",
            "Epoch 240/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2085 - acc: 0.9197 - val_loss: 0.3011 - val_acc: 0.8910\n",
            "Epoch 241/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2083 - acc: 0.9198 - val_loss: 0.2746 - val_acc: 0.8963\n",
            "Epoch 242/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2083 - acc: 0.9195 - val_loss: 0.3166 - val_acc: 0.8895\n",
            "Epoch 243/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2080 - acc: 0.9197 - val_loss: 0.2616 - val_acc: 0.9027\n",
            "Epoch 244/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2083 - acc: 0.9196 - val_loss: 0.2681 - val_acc: 0.8997\n",
            "Epoch 245/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2082 - acc: 0.9197 - val_loss: 0.2560 - val_acc: 0.9032\n",
            "Epoch 246/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2077 - acc: 0.9202 - val_loss: 0.2689 - val_acc: 0.9030\n",
            "Epoch 247/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2081 - acc: 0.9200 - val_loss: 0.2936 - val_acc: 0.8935\n",
            "Epoch 248/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2077 - acc: 0.9197 - val_loss: 0.2862 - val_acc: 0.8979\n",
            "Epoch 249/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2081 - acc: 0.9200 - val_loss: 0.2704 - val_acc: 0.8988\n",
            "Epoch 250/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2077 - acc: 0.9199 - val_loss: 0.2770 - val_acc: 0.8976\n",
            "Epoch 251/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2078 - acc: 0.9197 - val_loss: 0.2795 - val_acc: 0.9010\n",
            "Epoch 252/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2077 - acc: 0.9199 - val_loss: 0.2795 - val_acc: 0.9020\n",
            "Epoch 253/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2076 - acc: 0.9197 - val_loss: 0.2703 - val_acc: 0.9003\n",
            "Epoch 254/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2071 - acc: 0.9202 - val_loss: 0.2661 - val_acc: 0.9019\n",
            "Epoch 255/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2073 - acc: 0.9200 - val_loss: 0.2632 - val_acc: 0.9030\n",
            "Epoch 256/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2074 - acc: 0.9202 - val_loss: 0.2785 - val_acc: 0.8999\n",
            "Epoch 257/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2078 - acc: 0.9201 - val_loss: 0.2798 - val_acc: 0.8981\n",
            "Epoch 258/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2070 - acc: 0.9202 - val_loss: 0.2826 - val_acc: 0.8967\n",
            "Epoch 259/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2069 - acc: 0.9205 - val_loss: 0.3059 - val_acc: 0.8907\n",
            "Epoch 260/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2075 - acc: 0.9201 - val_loss: 0.2654 - val_acc: 0.9015\n",
            "Epoch 261/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2068 - acc: 0.9202 - val_loss: 0.2752 - val_acc: 0.8990\n",
            "Epoch 262/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2073 - acc: 0.9200 - val_loss: 0.2914 - val_acc: 0.8974\n",
            "Epoch 263/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2072 - acc: 0.9201 - val_loss: 0.2931 - val_acc: 0.8966\n",
            "Epoch 264/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2073 - acc: 0.9199 - val_loss: 0.2708 - val_acc: 0.8992\n",
            "Epoch 265/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2067 - acc: 0.9203 - val_loss: 0.2753 - val_acc: 0.8979\n",
            "Epoch 266/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2071 - acc: 0.9201 - val_loss: 0.2710 - val_acc: 0.8999\n",
            "Epoch 267/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2078 - acc: 0.9200 - val_loss: 0.2807 - val_acc: 0.8977\n",
            "Epoch 268/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2065 - acc: 0.9203 - val_loss: 0.2731 - val_acc: 0.9024\n",
            "Epoch 269/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2067 - acc: 0.9203 - val_loss: 0.2785 - val_acc: 0.8974\n",
            "Epoch 270/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2065 - acc: 0.9207 - val_loss: 0.2663 - val_acc: 0.9029\n",
            "Epoch 271/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2070 - acc: 0.9202 - val_loss: 0.2739 - val_acc: 0.8990\n",
            "Epoch 272/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2070 - acc: 0.9203 - val_loss: 0.3045 - val_acc: 0.8948\n",
            "Epoch 273/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2062 - acc: 0.9205 - val_loss: 0.2985 - val_acc: 0.8941\n",
            "Epoch 274/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2067 - acc: 0.9203 - val_loss: 0.2922 - val_acc: 0.8957\n",
            "Epoch 275/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2055 - acc: 0.9212 - val_loss: 0.2748 - val_acc: 0.9010\n",
            "Epoch 276/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2066 - acc: 0.9205 - val_loss: 0.2871 - val_acc: 0.8988\n",
            "Epoch 277/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2060 - acc: 0.9208 - val_loss: 0.2660 - val_acc: 0.9014\n",
            "Epoch 278/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2062 - acc: 0.9205 - val_loss: 0.2836 - val_acc: 0.8982\n",
            "Epoch 279/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2059 - acc: 0.9206 - val_loss: 0.2795 - val_acc: 0.8992\n",
            "Epoch 280/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2061 - acc: 0.9205 - val_loss: 0.2704 - val_acc: 0.9033\n",
            "Epoch 281/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2064 - acc: 0.9206 - val_loss: 0.2668 - val_acc: 0.9025\n",
            "Epoch 282/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2054 - acc: 0.9209 - val_loss: 0.2883 - val_acc: 0.8955\n",
            "Epoch 283/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2063 - acc: 0.9205 - val_loss: 0.2662 - val_acc: 0.9019\n",
            "Epoch 284/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.2060 - acc: 0.9205 - val_loss: 0.3398 - val_acc: 0.8880\n",
            "Epoch 285/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2056 - acc: 0.9205 - val_loss: 0.2489 - val_acc: 0.9065\n",
            "Epoch 286/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2063 - acc: 0.9205 - val_loss: 0.2966 - val_acc: 0.8980\n",
            "Epoch 287/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2059 - acc: 0.9206 - val_loss: 0.2730 - val_acc: 0.8986\n",
            "Epoch 288/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2064 - acc: 0.9208 - val_loss: 0.2897 - val_acc: 0.8967\n",
            "Epoch 289/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2058 - acc: 0.9207 - val_loss: 0.2848 - val_acc: 0.8991\n",
            "Epoch 290/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2061 - acc: 0.9206 - val_loss: 0.2781 - val_acc: 0.8968\n",
            "Epoch 291/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2057 - acc: 0.9209 - val_loss: 0.2903 - val_acc: 0.8965\n",
            "Epoch 292/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2057 - acc: 0.9211 - val_loss: 0.2883 - val_acc: 0.8963\n",
            "Epoch 293/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2057 - acc: 0.9208 - val_loss: 0.2773 - val_acc: 0.9016\n",
            "Epoch 294/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2057 - acc: 0.9210 - val_loss: 0.2670 - val_acc: 0.8993\n",
            "Epoch 295/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2057 - acc: 0.9208 - val_loss: 0.2929 - val_acc: 0.8980\n",
            "Epoch 296/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2053 - acc: 0.9210 - val_loss: 0.3014 - val_acc: 0.8952\n",
            "Epoch 297/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2056 - acc: 0.9208 - val_loss: 0.2967 - val_acc: 0.8931\n",
            "Epoch 298/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2048 - acc: 0.9209 - val_loss: 0.2708 - val_acc: 0.9008\n",
            "Epoch 299/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2052 - acc: 0.9207 - val_loss: 0.2857 - val_acc: 0.8954\n",
            "Epoch 300/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2057 - acc: 0.9208 - val_loss: 0.2784 - val_acc: 0.8998\n",
            "Epoch 301/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.2055 - acc: 0.9209 - val_loss: 0.3117 - val_acc: 0.8945\n",
            "Epoch 302/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2052 - acc: 0.9208 - val_loss: 0.2962 - val_acc: 0.8950\n",
            "Epoch 303/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2055 - acc: 0.9208 - val_loss: 0.2926 - val_acc: 0.8962\n",
            "Epoch 304/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2050 - acc: 0.9212 - val_loss: 0.2876 - val_acc: 0.8964\n",
            "Epoch 305/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2058 - acc: 0.9207 - val_loss: 0.2799 - val_acc: 0.9003\n",
            "Epoch 306/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2049 - acc: 0.9209 - val_loss: 0.2523 - val_acc: 0.9058\n",
            "Epoch 307/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2049 - acc: 0.9212 - val_loss: 0.2679 - val_acc: 0.9028\n",
            "Epoch 308/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2049 - acc: 0.9209 - val_loss: 0.2859 - val_acc: 0.8959\n",
            "Epoch 309/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2054 - acc: 0.9206 - val_loss: 0.2653 - val_acc: 0.9013\n",
            "Epoch 310/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2049 - acc: 0.9209 - val_loss: 0.2767 - val_acc: 0.9011\n",
            "Epoch 311/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2046 - acc: 0.9213 - val_loss: 0.3078 - val_acc: 0.8915\n",
            "Epoch 312/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2047 - acc: 0.9210 - val_loss: 0.2793 - val_acc: 0.8971\n",
            "Epoch 313/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2047 - acc: 0.9210 - val_loss: 0.3086 - val_acc: 0.8937\n",
            "Epoch 314/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2045 - acc: 0.9209 - val_loss: 0.2903 - val_acc: 0.8931\n",
            "Epoch 315/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2046 - acc: 0.9210 - val_loss: 0.3092 - val_acc: 0.8931\n",
            "Epoch 316/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2053 - acc: 0.9209 - val_loss: 0.2883 - val_acc: 0.8988\n",
            "Epoch 317/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2045 - acc: 0.9210 - val_loss: 0.2960 - val_acc: 0.8977\n",
            "Epoch 318/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2045 - acc: 0.9212 - val_loss: 0.3090 - val_acc: 0.8947\n",
            "Epoch 319/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2055 - acc: 0.9208 - val_loss: 0.2748 - val_acc: 0.9010\n",
            "Epoch 320/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2050 - acc: 0.9211 - val_loss: 0.3316 - val_acc: 0.8878\n",
            "Epoch 321/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2051 - acc: 0.9211 - val_loss: 0.2767 - val_acc: 0.8999\n",
            "Epoch 322/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2048 - acc: 0.9210 - val_loss: 0.2699 - val_acc: 0.9020\n",
            "Epoch 323/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2042 - acc: 0.9213 - val_loss: 0.3115 - val_acc: 0.8887\n",
            "Epoch 324/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2044 - acc: 0.9212 - val_loss: 0.2665 - val_acc: 0.9012\n",
            "Epoch 325/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2047 - acc: 0.9211 - val_loss: 0.2743 - val_acc: 0.9013\n",
            "Epoch 326/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2051 - acc: 0.9211 - val_loss: 0.2666 - val_acc: 0.9003\n",
            "Epoch 327/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2052 - acc: 0.9211 - val_loss: 0.2981 - val_acc: 0.8954\n",
            "Epoch 328/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2045 - acc: 0.9211 - val_loss: 0.2834 - val_acc: 0.8957\n",
            "Epoch 329/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2043 - acc: 0.9212 - val_loss: 0.2694 - val_acc: 0.9000\n",
            "Epoch 330/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2043 - acc: 0.9216 - val_loss: 0.3199 - val_acc: 0.8916\n",
            "Epoch 331/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2044 - acc: 0.9210 - val_loss: 0.2595 - val_acc: 0.9027\n",
            "Epoch 332/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2044 - acc: 0.9208 - val_loss: 0.2650 - val_acc: 0.8994\n",
            "Epoch 333/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2046 - acc: 0.9212 - val_loss: 0.3095 - val_acc: 0.8942\n",
            "Epoch 334/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2039 - acc: 0.9216 - val_loss: 0.2869 - val_acc: 0.8974\n",
            "Epoch 335/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2045 - acc: 0.9213 - val_loss: 0.3116 - val_acc: 0.8901\n",
            "Epoch 336/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.2044 - acc: 0.9209 - val_loss: 0.2726 - val_acc: 0.9016\n",
            "Epoch 337/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2046 - acc: 0.9215 - val_loss: 0.2820 - val_acc: 0.9004\n",
            "Epoch 338/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2035 - acc: 0.9214 - val_loss: 0.3022 - val_acc: 0.8950\n",
            "Epoch 339/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2039 - acc: 0.9214 - val_loss: 0.2552 - val_acc: 0.9065\n",
            "Epoch 340/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2038 - acc: 0.9215 - val_loss: 0.2859 - val_acc: 0.8957\n",
            "Epoch 341/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2041 - acc: 0.9214 - val_loss: 0.3118 - val_acc: 0.8930\n",
            "Epoch 342/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2034 - acc: 0.9214 - val_loss: 0.2730 - val_acc: 0.8997\n",
            "Epoch 343/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2035 - acc: 0.9215 - val_loss: 0.2906 - val_acc: 0.8962\n",
            "Epoch 344/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2041 - acc: 0.9211 - val_loss: 0.2956 - val_acc: 0.8964\n",
            "Epoch 345/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2035 - acc: 0.9213 - val_loss: 0.2767 - val_acc: 0.8996\n",
            "Epoch 346/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2036 - acc: 0.9215 - val_loss: 0.3084 - val_acc: 0.8945\n",
            "Epoch 347/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2037 - acc: 0.9215 - val_loss: 0.2731 - val_acc: 0.9016\n",
            "Epoch 348/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2032 - acc: 0.9214 - val_loss: 0.2823 - val_acc: 0.8987\n",
            "Epoch 349/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2045 - acc: 0.9213 - val_loss: 0.2720 - val_acc: 0.9030\n",
            "Epoch 350/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2037 - acc: 0.9214 - val_loss: 0.2832 - val_acc: 0.8981\n",
            "Epoch 351/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2036 - acc: 0.9213 - val_loss: 0.2776 - val_acc: 0.8987\n",
            "Epoch 352/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2040 - acc: 0.9212 - val_loss: 0.2812 - val_acc: 0.8998\n",
            "Epoch 353/6000\n",
            "584288/584288 [==============================] - 20s 33us/step - loss: 0.2042 - acc: 0.9212 - val_loss: 0.2718 - val_acc: 0.8994\n",
            "Epoch 354/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2030 - acc: 0.9218 - val_loss: 0.2974 - val_acc: 0.8926\n",
            "Epoch 355/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2032 - acc: 0.9217 - val_loss: 0.2996 - val_acc: 0.8931\n",
            "Epoch 356/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2031 - acc: 0.9218 - val_loss: 0.2739 - val_acc: 0.9033\n",
            "Epoch 357/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2029 - acc: 0.9216 - val_loss: 0.3275 - val_acc: 0.8891\n",
            "Epoch 358/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2038 - acc: 0.9215 - val_loss: 0.3284 - val_acc: 0.8862\n",
            "Epoch 359/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.2036 - acc: 0.9212 - val_loss: 0.2892 - val_acc: 0.8938\n",
            "Epoch 360/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.2031 - acc: 0.9218 - val_loss: 0.2678 - val_acc: 0.9015\n",
            "Epoch 361/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2035 - acc: 0.9218 - val_loss: 0.2865 - val_acc: 0.8972\n",
            "Epoch 362/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2032 - acc: 0.9214 - val_loss: 0.2784 - val_acc: 0.8979\n",
            "Epoch 363/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2032 - acc: 0.9217 - val_loss: 0.3058 - val_acc: 0.8904\n",
            "Epoch 364/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2027 - acc: 0.9217 - val_loss: 0.2815 - val_acc: 0.9020\n",
            "Epoch 365/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2032 - acc: 0.9216 - val_loss: 0.2824 - val_acc: 0.9005\n",
            "Epoch 366/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2034 - acc: 0.9218 - val_loss: 0.2919 - val_acc: 0.8970\n",
            "Epoch 367/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2032 - acc: 0.9218 - val_loss: 0.2813 - val_acc: 0.8986\n",
            "Epoch 368/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2027 - acc: 0.9218 - val_loss: 0.2927 - val_acc: 0.8978\n",
            "Epoch 369/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.2037 - acc: 0.9215 - val_loss: 0.2873 - val_acc: 0.9001\n",
            "Epoch 370/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.2027 - acc: 0.9219 - val_loss: 0.2948 - val_acc: 0.8976\n",
            "Epoch 371/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2030 - acc: 0.9218 - val_loss: 0.2770 - val_acc: 0.8976\n",
            "Epoch 372/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2033 - acc: 0.9217 - val_loss: 0.3319 - val_acc: 0.8850\n",
            "Epoch 373/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2024 - acc: 0.9216 - val_loss: 0.2863 - val_acc: 0.8992\n",
            "Epoch 374/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2035 - acc: 0.9214 - val_loss: 0.2768 - val_acc: 0.9005\n",
            "Epoch 375/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2028 - acc: 0.9219 - val_loss: 0.3089 - val_acc: 0.8947\n",
            "Epoch 376/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2036 - acc: 0.9213 - val_loss: 0.2953 - val_acc: 0.8984\n",
            "Epoch 377/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2029 - acc: 0.9219 - val_loss: 0.2702 - val_acc: 0.9015\n",
            "Epoch 378/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2028 - acc: 0.9219 - val_loss: 0.2940 - val_acc: 0.8975\n",
            "Epoch 379/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2033 - acc: 0.9217 - val_loss: 0.3031 - val_acc: 0.8960\n",
            "Epoch 380/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2024 - acc: 0.9220 - val_loss: 0.2926 - val_acc: 0.8976\n",
            "Epoch 381/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2025 - acc: 0.9219 - val_loss: 0.2571 - val_acc: 0.9055\n",
            "Epoch 382/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2031 - acc: 0.9216 - val_loss: 0.2818 - val_acc: 0.8996\n",
            "Epoch 383/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2023 - acc: 0.9220 - val_loss: 0.2836 - val_acc: 0.9027\n",
            "Epoch 384/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2023 - acc: 0.9220 - val_loss: 0.3213 - val_acc: 0.8921\n",
            "Epoch 385/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2033 - acc: 0.9217 - val_loss: 0.2606 - val_acc: 0.9030\n",
            "Epoch 386/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.2024 - acc: 0.9221 - val_loss: 0.2850 - val_acc: 0.8973\n",
            "Epoch 387/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2024 - acc: 0.9221 - val_loss: 0.2969 - val_acc: 0.8944\n",
            "Epoch 388/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2021 - acc: 0.9221 - val_loss: 0.2889 - val_acc: 0.8950\n",
            "Epoch 389/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2027 - acc: 0.9217 - val_loss: 0.3043 - val_acc: 0.8912\n",
            "Epoch 390/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2027 - acc: 0.9215 - val_loss: 0.2844 - val_acc: 0.8996\n",
            "Epoch 391/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2026 - acc: 0.9219 - val_loss: 0.2846 - val_acc: 0.8986\n",
            "Epoch 392/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2024 - acc: 0.9221 - val_loss: 0.3137 - val_acc: 0.8908\n",
            "Epoch 393/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2023 - acc: 0.9218 - val_loss: 0.2767 - val_acc: 0.9009\n",
            "Epoch 394/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2025 - acc: 0.9218 - val_loss: 0.2694 - val_acc: 0.9011\n",
            "Epoch 395/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2024 - acc: 0.9218 - val_loss: 0.2813 - val_acc: 0.9006\n",
            "Epoch 396/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2025 - acc: 0.9221 - val_loss: 0.3081 - val_acc: 0.8973\n",
            "Epoch 397/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2025 - acc: 0.9218 - val_loss: 0.3472 - val_acc: 0.8871\n",
            "Epoch 398/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2022 - acc: 0.9219 - val_loss: 0.3069 - val_acc: 0.8937\n",
            "Epoch 399/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2030 - acc: 0.9215 - val_loss: 0.2744 - val_acc: 0.9030\n",
            "Epoch 400/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2021 - acc: 0.9220 - val_loss: 0.2826 - val_acc: 0.8989\n",
            "Epoch 401/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2026 - acc: 0.9218 - val_loss: 0.2637 - val_acc: 0.9010\n",
            "Epoch 402/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2026 - acc: 0.9219 - val_loss: 0.2875 - val_acc: 0.9009\n",
            "Epoch 403/6000\n",
            "584288/584288 [==============================] - 20s 34us/step - loss: 0.2021 - acc: 0.9223 - val_loss: 0.2691 - val_acc: 0.9003\n",
            "Epoch 404/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2028 - acc: 0.9219 - val_loss: 0.3165 - val_acc: 0.8849\n",
            "Epoch 405/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2022 - acc: 0.9219 - val_loss: 0.2939 - val_acc: 0.8928\n",
            "Epoch 406/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2020 - acc: 0.9220 - val_loss: 0.2751 - val_acc: 0.9031\n",
            "Epoch 407/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2024 - acc: 0.9218 - val_loss: 0.2938 - val_acc: 0.8954\n",
            "Epoch 408/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2026 - acc: 0.9221 - val_loss: 0.2744 - val_acc: 0.9038\n",
            "Epoch 409/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2016 - acc: 0.9223 - val_loss: 0.2853 - val_acc: 0.8964\n",
            "Epoch 410/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2019 - acc: 0.9223 - val_loss: 0.2919 - val_acc: 0.9000\n",
            "Epoch 411/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2017 - acc: 0.9221 - val_loss: 0.2785 - val_acc: 0.8993\n",
            "Epoch 412/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2018 - acc: 0.9220 - val_loss: 0.2629 - val_acc: 0.9046\n",
            "Epoch 413/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2021 - acc: 0.9220 - val_loss: 0.2957 - val_acc: 0.8982\n",
            "Epoch 414/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2020 - acc: 0.9223 - val_loss: 0.2716 - val_acc: 0.9013\n",
            "Epoch 415/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2016 - acc: 0.9223 - val_loss: 0.2633 - val_acc: 0.9044\n",
            "Epoch 416/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2015 - acc: 0.9225 - val_loss: 0.2894 - val_acc: 0.8999\n",
            "Epoch 417/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2018 - acc: 0.9221 - val_loss: 0.2826 - val_acc: 0.9009\n",
            "Epoch 418/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2014 - acc: 0.9222 - val_loss: 0.2992 - val_acc: 0.8983\n",
            "Epoch 419/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2021 - acc: 0.9220 - val_loss: 0.3122 - val_acc: 0.8914\n",
            "Epoch 420/6000\n",
            "584288/584288 [==============================] - 20s 34us/step - loss: 0.2016 - acc: 0.9224 - val_loss: 0.2768 - val_acc: 0.8998\n",
            "Epoch 421/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2018 - acc: 0.9220 - val_loss: 0.2609 - val_acc: 0.9049\n",
            "Epoch 422/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2018 - acc: 0.9223 - val_loss: 0.2660 - val_acc: 0.9024\n",
            "Epoch 423/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2019 - acc: 0.9221 - val_loss: 0.2902 - val_acc: 0.8991\n",
            "Epoch 424/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2016 - acc: 0.9226 - val_loss: 0.2827 - val_acc: 0.8971\n",
            "Epoch 425/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2012 - acc: 0.9221 - val_loss: 0.2914 - val_acc: 0.8953\n",
            "Epoch 426/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2017 - acc: 0.9221 - val_loss: 0.3048 - val_acc: 0.8943\n",
            "Epoch 427/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2016 - acc: 0.9222 - val_loss: 0.2935 - val_acc: 0.8964\n",
            "Epoch 428/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2017 - acc: 0.9220 - val_loss: 0.3066 - val_acc: 0.8957\n",
            "Epoch 429/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2016 - acc: 0.9224 - val_loss: 0.2782 - val_acc: 0.9003\n",
            "Epoch 430/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2013 - acc: 0.9223 - val_loss: 0.2855 - val_acc: 0.8959\n",
            "Epoch 431/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2014 - acc: 0.9224 - val_loss: 0.3249 - val_acc: 0.8919\n",
            "Epoch 432/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2019 - acc: 0.9224 - val_loss: 0.3057 - val_acc: 0.8965\n",
            "Epoch 433/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2019 - acc: 0.9220 - val_loss: 0.3102 - val_acc: 0.8915\n",
            "Epoch 434/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2006 - acc: 0.9226 - val_loss: 0.3208 - val_acc: 0.8919\n",
            "Epoch 435/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2012 - acc: 0.9225 - val_loss: 0.2647 - val_acc: 0.9029\n",
            "Epoch 436/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2021 - acc: 0.9221 - val_loss: 0.2665 - val_acc: 0.9019\n",
            "Epoch 437/6000\n",
            "584288/584288 [==============================] - 20s 34us/step - loss: 0.2012 - acc: 0.9223 - val_loss: 0.2633 - val_acc: 0.9023\n",
            "Epoch 438/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2018 - acc: 0.9221 - val_loss: 0.2655 - val_acc: 0.8997\n",
            "Epoch 439/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2010 - acc: 0.9225 - val_loss: 0.3083 - val_acc: 0.8934\n",
            "Epoch 440/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2016 - acc: 0.9222 - val_loss: 0.3038 - val_acc: 0.8945\n",
            "Epoch 441/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2017 - acc: 0.9222 - val_loss: 0.2715 - val_acc: 0.9014\n",
            "Epoch 442/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2013 - acc: 0.9221 - val_loss: 0.3120 - val_acc: 0.8936\n",
            "Epoch 443/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2009 - acc: 0.9228 - val_loss: 0.2712 - val_acc: 0.8992\n",
            "Epoch 444/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2013 - acc: 0.9222 - val_loss: 0.3154 - val_acc: 0.8906\n",
            "Epoch 445/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2012 - acc: 0.9225 - val_loss: 0.2695 - val_acc: 0.9008\n",
            "Epoch 446/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2019 - acc: 0.9220 - val_loss: 0.2973 - val_acc: 0.8960\n",
            "Epoch 447/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2010 - acc: 0.9225 - val_loss: 0.2578 - val_acc: 0.9055\n",
            "Epoch 448/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2014 - acc: 0.9225 - val_loss: 0.2880 - val_acc: 0.9003\n",
            "Epoch 449/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2018 - acc: 0.9220 - val_loss: 0.2902 - val_acc: 0.8964\n",
            "Epoch 450/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2012 - acc: 0.9224 - val_loss: 0.2957 - val_acc: 0.8988\n",
            "Epoch 451/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2017 - acc: 0.9225 - val_loss: 0.3238 - val_acc: 0.8874\n",
            "Epoch 452/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2008 - acc: 0.9226 - val_loss: 0.2885 - val_acc: 0.8985\n",
            "Epoch 453/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2009 - acc: 0.9226 - val_loss: 0.2726 - val_acc: 0.9014\n",
            "Epoch 454/6000\n",
            "584288/584288 [==============================] - 20s 34us/step - loss: 0.2008 - acc: 0.9224 - val_loss: 0.3221 - val_acc: 0.8922\n",
            "Epoch 455/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2009 - acc: 0.9225 - val_loss: 0.2813 - val_acc: 0.8984\n",
            "Epoch 456/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2015 - acc: 0.9223 - val_loss: 0.2828 - val_acc: 0.8983\n",
            "Epoch 457/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2002 - acc: 0.9228 - val_loss: 0.3617 - val_acc: 0.8816\n",
            "Epoch 458/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2007 - acc: 0.9221 - val_loss: 0.2679 - val_acc: 0.9011\n",
            "Epoch 459/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2011 - acc: 0.9225 - val_loss: 0.3189 - val_acc: 0.8893\n",
            "Epoch 460/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2004 - acc: 0.9229 - val_loss: 0.2813 - val_acc: 0.9021\n",
            "Epoch 461/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2007 - acc: 0.9227 - val_loss: 0.2782 - val_acc: 0.8995\n",
            "Epoch 462/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2012 - acc: 0.9224 - val_loss: 0.2762 - val_acc: 0.9016\n",
            "Epoch 463/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2007 - acc: 0.9223 - val_loss: 0.3058 - val_acc: 0.8909\n",
            "Epoch 464/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2007 - acc: 0.9225 - val_loss: 0.3415 - val_acc: 0.8832\n",
            "Epoch 465/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2005 - acc: 0.9223 - val_loss: 0.2685 - val_acc: 0.9001\n",
            "Epoch 466/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2004 - acc: 0.9227 - val_loss: 0.3414 - val_acc: 0.8882\n",
            "Epoch 467/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2006 - acc: 0.9226 - val_loss: 0.2775 - val_acc: 0.8995\n",
            "Epoch 468/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2002 - acc: 0.9227 - val_loss: 0.2807 - val_acc: 0.8980\n",
            "Epoch 469/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2002 - acc: 0.9227 - val_loss: 0.3099 - val_acc: 0.8959\n",
            "Epoch 470/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2011 - acc: 0.9223 - val_loss: 0.2944 - val_acc: 0.8918\n",
            "Epoch 471/6000\n",
            "584288/584288 [==============================] - 20s 33us/step - loss: 0.2004 - acc: 0.9226 - val_loss: 0.3491 - val_acc: 0.8818\n",
            "Epoch 472/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2011 - acc: 0.9223 - val_loss: 0.2682 - val_acc: 0.9012\n",
            "Epoch 473/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.2001 - acc: 0.9231 - val_loss: 0.2796 - val_acc: 0.9039\n",
            "Epoch 474/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2005 - acc: 0.9227 - val_loss: 0.2873 - val_acc: 0.8977\n",
            "Epoch 475/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2008 - acc: 0.9226 - val_loss: 0.2949 - val_acc: 0.8963\n",
            "Epoch 476/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2010 - acc: 0.9223 - val_loss: 0.2897 - val_acc: 0.8986\n",
            "Epoch 477/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2005 - acc: 0.9227 - val_loss: 0.2918 - val_acc: 0.8951\n",
            "Epoch 478/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2007 - acc: 0.9224 - val_loss: 0.3026 - val_acc: 0.8965\n",
            "Epoch 479/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2004 - acc: 0.9228 - val_loss: 0.2773 - val_acc: 0.8986\n",
            "Epoch 480/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2005 - acc: 0.9227 - val_loss: 0.2938 - val_acc: 0.8971\n",
            "Epoch 481/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2007 - acc: 0.9226 - val_loss: 0.3095 - val_acc: 0.8963\n",
            "Epoch 482/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2003 - acc: 0.9228 - val_loss: 0.2833 - val_acc: 0.8996\n",
            "Epoch 483/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2004 - acc: 0.9227 - val_loss: 0.2796 - val_acc: 0.8995\n",
            "Epoch 484/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2006 - acc: 0.9224 - val_loss: 0.2884 - val_acc: 0.8960\n",
            "Epoch 485/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2003 - acc: 0.9225 - val_loss: 0.2950 - val_acc: 0.8915\n",
            "Epoch 486/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2003 - acc: 0.9227 - val_loss: 0.2925 - val_acc: 0.8998\n",
            "Epoch 487/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2006 - acc: 0.9225 - val_loss: 0.3233 - val_acc: 0.8906\n",
            "Epoch 488/6000\n",
            "584288/584288 [==============================] - 20s 33us/step - loss: 0.1996 - acc: 0.9229 - val_loss: 0.2995 - val_acc: 0.8965\n",
            "Epoch 489/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1995 - acc: 0.9229 - val_loss: 0.3381 - val_acc: 0.8888\n",
            "Epoch 490/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2007 - acc: 0.9225 - val_loss: 0.2577 - val_acc: 0.9063\n",
            "Epoch 491/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2002 - acc: 0.9227 - val_loss: 0.3125 - val_acc: 0.8899\n",
            "Epoch 492/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2000 - acc: 0.9228 - val_loss: 0.2772 - val_acc: 0.9009\n",
            "Epoch 493/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1996 - acc: 0.9229 - val_loss: 0.3086 - val_acc: 0.8925\n",
            "Epoch 494/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1997 - acc: 0.9226 - val_loss: 0.3387 - val_acc: 0.8875\n",
            "Epoch 495/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1997 - acc: 0.9230 - val_loss: 0.3344 - val_acc: 0.8866\n",
            "Epoch 496/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.2004 - acc: 0.9225 - val_loss: 0.2715 - val_acc: 0.9027\n",
            "Epoch 497/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2000 - acc: 0.9230 - val_loss: 0.3019 - val_acc: 0.8940\n",
            "Epoch 498/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2000 - acc: 0.9225 - val_loss: 0.2713 - val_acc: 0.9024\n",
            "Epoch 499/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2001 - acc: 0.9228 - val_loss: 0.2800 - val_acc: 0.9003\n",
            "Epoch 500/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2005 - acc: 0.9228 - val_loss: 0.2687 - val_acc: 0.9008\n",
            "Epoch 501/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1998 - acc: 0.9229 - val_loss: 0.2939 - val_acc: 0.8934\n",
            "Epoch 502/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2002 - acc: 0.9226 - val_loss: 0.2985 - val_acc: 0.8951\n",
            "Epoch 503/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1998 - acc: 0.9227 - val_loss: 0.3045 - val_acc: 0.8929\n",
            "Epoch 504/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2002 - acc: 0.9228 - val_loss: 0.3043 - val_acc: 0.8940\n",
            "Epoch 505/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1995 - acc: 0.9230 - val_loss: 0.2631 - val_acc: 0.9024\n",
            "Epoch 506/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1999 - acc: 0.9227 - val_loss: 0.3205 - val_acc: 0.8910\n",
            "Epoch 507/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2003 - acc: 0.9225 - val_loss: 0.2634 - val_acc: 0.9019\n",
            "Epoch 508/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1998 - acc: 0.9231 - val_loss: 0.3082 - val_acc: 0.8939\n",
            "Epoch 509/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2000 - acc: 0.9228 - val_loss: 0.2959 - val_acc: 0.8967\n",
            "Epoch 510/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2005 - acc: 0.9223 - val_loss: 0.2861 - val_acc: 0.8984\n",
            "Epoch 511/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1996 - acc: 0.9229 - val_loss: 0.2990 - val_acc: 0.8960\n",
            "Epoch 512/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1991 - acc: 0.9230 - val_loss: 0.2902 - val_acc: 0.8975\n",
            "Epoch 513/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1998 - acc: 0.9229 - val_loss: 0.3216 - val_acc: 0.8923\n",
            "Epoch 514/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2001 - acc: 0.9225 - val_loss: 0.3351 - val_acc: 0.8907\n",
            "Epoch 515/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2001 - acc: 0.9228 - val_loss: 0.3276 - val_acc: 0.8927\n",
            "Epoch 516/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1999 - acc: 0.9229 - val_loss: 0.3237 - val_acc: 0.8899\n",
            "Epoch 517/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2001 - acc: 0.9229 - val_loss: 0.3127 - val_acc: 0.8885\n",
            "Epoch 518/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1992 - acc: 0.9233 - val_loss: 0.2809 - val_acc: 0.8966\n",
            "Epoch 519/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1995 - acc: 0.9230 - val_loss: 0.3094 - val_acc: 0.8922\n",
            "Epoch 520/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1995 - acc: 0.9233 - val_loss: 0.2816 - val_acc: 0.8986\n",
            "Epoch 521/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2000 - acc: 0.9229 - val_loss: 0.2913 - val_acc: 0.8938\n",
            "Epoch 522/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1995 - acc: 0.9230 - val_loss: 0.2852 - val_acc: 0.8988\n",
            "Epoch 523/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1998 - acc: 0.9228 - val_loss: 0.2756 - val_acc: 0.8996\n",
            "Epoch 524/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2001 - acc: 0.9228 - val_loss: 0.3089 - val_acc: 0.8942\n",
            "Epoch 525/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.2001 - acc: 0.9229 - val_loss: 0.3119 - val_acc: 0.8900\n",
            "Epoch 526/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1993 - acc: 0.9230 - val_loss: 0.2873 - val_acc: 0.9006\n",
            "Epoch 527/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.2001 - acc: 0.9228 - val_loss: 0.3058 - val_acc: 0.8931\n",
            "Epoch 528/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1996 - acc: 0.9231 - val_loss: 0.3561 - val_acc: 0.8859\n",
            "Epoch 529/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1992 - acc: 0.9231 - val_loss: 0.3146 - val_acc: 0.8961\n",
            "Epoch 530/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1991 - acc: 0.9231 - val_loss: 0.3079 - val_acc: 0.8936\n",
            "Epoch 531/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1990 - acc: 0.9232 - val_loss: 0.3014 - val_acc: 0.8986\n",
            "Epoch 532/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1994 - acc: 0.9232 - val_loss: 0.3225 - val_acc: 0.8920\n",
            "Epoch 533/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1995 - acc: 0.9231 - val_loss: 0.2744 - val_acc: 0.9006\n",
            "Epoch 534/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1986 - acc: 0.9235 - val_loss: 0.3098 - val_acc: 0.8934\n",
            "Epoch 535/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1995 - acc: 0.9233 - val_loss: 0.3018 - val_acc: 0.8962\n",
            "Epoch 536/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1996 - acc: 0.9231 - val_loss: 0.2955 - val_acc: 0.8975\n",
            "Epoch 537/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1994 - acc: 0.9229 - val_loss: 0.3037 - val_acc: 0.8979\n",
            "Epoch 538/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1991 - acc: 0.9233 - val_loss: 0.2696 - val_acc: 0.8992\n",
            "Epoch 539/6000\n",
            "584288/584288 [==============================] - 20s 34us/step - loss: 0.1996 - acc: 0.9230 - val_loss: 0.2939 - val_acc: 0.8957\n",
            "Epoch 540/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1998 - acc: 0.9232 - val_loss: 0.2885 - val_acc: 0.8975\n",
            "Epoch 541/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1992 - acc: 0.9234 - val_loss: 0.3084 - val_acc: 0.8954\n",
            "Epoch 542/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1999 - acc: 0.9230 - val_loss: 0.3115 - val_acc: 0.8943\n",
            "Epoch 543/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1988 - acc: 0.9236 - val_loss: 0.3414 - val_acc: 0.8893\n",
            "Epoch 544/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1993 - acc: 0.9229 - val_loss: 0.2598 - val_acc: 0.9037\n",
            "Epoch 545/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1990 - acc: 0.9230 - val_loss: 0.2876 - val_acc: 0.8997\n",
            "Epoch 546/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1988 - acc: 0.9230 - val_loss: 0.3103 - val_acc: 0.8920\n",
            "Epoch 547/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1994 - acc: 0.9230 - val_loss: 0.2872 - val_acc: 0.8970\n",
            "Epoch 548/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1994 - acc: 0.9233 - val_loss: 0.2927 - val_acc: 0.8951\n",
            "Epoch 549/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1993 - acc: 0.9232 - val_loss: 0.3287 - val_acc: 0.8935\n",
            "Epoch 550/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1983 - acc: 0.9236 - val_loss: 0.2943 - val_acc: 0.8957\n",
            "Epoch 551/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1990 - acc: 0.9236 - val_loss: 0.2980 - val_acc: 0.8946\n",
            "Epoch 552/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1990 - acc: 0.9235 - val_loss: 0.3056 - val_acc: 0.8939\n",
            "Epoch 553/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1994 - acc: 0.9229 - val_loss: 0.2758 - val_acc: 0.9005\n",
            "Epoch 554/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1982 - acc: 0.9234 - val_loss: 0.2993 - val_acc: 0.8960\n",
            "Epoch 555/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1989 - acc: 0.9231 - val_loss: 0.3040 - val_acc: 0.8952\n",
            "Epoch 556/6000\n",
            "584288/584288 [==============================] - 20s 34us/step - loss: 0.1990 - acc: 0.9230 - val_loss: 0.3022 - val_acc: 0.8956\n",
            "Epoch 557/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1991 - acc: 0.9233 - val_loss: 0.2850 - val_acc: 0.8970\n",
            "Epoch 558/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1988 - acc: 0.9233 - val_loss: 0.2721 - val_acc: 0.8999\n",
            "Epoch 559/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1994 - acc: 0.9231 - val_loss: 0.2949 - val_acc: 0.8968\n",
            "Epoch 560/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1990 - acc: 0.9232 - val_loss: 0.3047 - val_acc: 0.8979\n",
            "Epoch 561/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1989 - acc: 0.9236 - val_loss: 0.3293 - val_acc: 0.8887\n",
            "Epoch 562/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1986 - acc: 0.9235 - val_loss: 0.3119 - val_acc: 0.8942\n",
            "Epoch 563/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1990 - acc: 0.9232 - val_loss: 0.3071 - val_acc: 0.8962\n",
            "Epoch 564/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1991 - acc: 0.9232 - val_loss: 0.3119 - val_acc: 0.8972\n",
            "Epoch 565/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1990 - acc: 0.9232 - val_loss: 0.3023 - val_acc: 0.8914\n",
            "Epoch 566/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1989 - acc: 0.9230 - val_loss: 0.2998 - val_acc: 0.8957\n",
            "Epoch 567/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1989 - acc: 0.9233 - val_loss: 0.2931 - val_acc: 0.8999\n",
            "Epoch 568/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1986 - acc: 0.9232 - val_loss: 0.3178 - val_acc: 0.8927\n",
            "Epoch 569/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1985 - acc: 0.9234 - val_loss: 0.2722 - val_acc: 0.9021\n",
            "Epoch 570/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1995 - acc: 0.9230 - val_loss: 0.3648 - val_acc: 0.8839\n",
            "Epoch 571/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1983 - acc: 0.9235 - val_loss: 0.2879 - val_acc: 0.8965\n",
            "Epoch 572/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1995 - acc: 0.9230 - val_loss: 0.3064 - val_acc: 0.8966\n",
            "Epoch 573/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1986 - acc: 0.9233 - val_loss: 0.2943 - val_acc: 0.8935\n",
            "Epoch 574/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1985 - acc: 0.9233 - val_loss: 0.2896 - val_acc: 0.8954\n",
            "Epoch 575/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1988 - acc: 0.9231 - val_loss: 0.2770 - val_acc: 0.9037\n",
            "Epoch 576/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1987 - acc: 0.9234 - val_loss: 0.3207 - val_acc: 0.8894\n",
            "Epoch 577/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1990 - acc: 0.9229 - val_loss: 0.2811 - val_acc: 0.9000\n",
            "Epoch 578/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1989 - acc: 0.9232 - val_loss: 0.2914 - val_acc: 0.8982\n",
            "Epoch 579/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1982 - acc: 0.9234 - val_loss: 0.3092 - val_acc: 0.8948\n",
            "Epoch 580/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1998 - acc: 0.9232 - val_loss: 0.3178 - val_acc: 0.8911\n",
            "Epoch 581/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1986 - acc: 0.9233 - val_loss: 0.2859 - val_acc: 0.8958\n",
            "Epoch 582/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1990 - acc: 0.9233 - val_loss: 0.3208 - val_acc: 0.8939\n",
            "Epoch 583/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1985 - acc: 0.9233 - val_loss: 0.3114 - val_acc: 0.8930\n",
            "Epoch 584/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1985 - acc: 0.9232 - val_loss: 0.3261 - val_acc: 0.8888\n",
            "Epoch 585/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1988 - acc: 0.9236 - val_loss: 0.3596 - val_acc: 0.8853\n",
            "Epoch 586/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1990 - acc: 0.9233 - val_loss: 0.3019 - val_acc: 0.8973\n",
            "Epoch 587/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1987 - acc: 0.9230 - val_loss: 0.3019 - val_acc: 0.8948\n",
            "Epoch 588/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1988 - acc: 0.9230 - val_loss: 0.2936 - val_acc: 0.9003\n",
            "Epoch 589/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1988 - acc: 0.9233 - val_loss: 0.3196 - val_acc: 0.8924\n",
            "Epoch 590/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1982 - acc: 0.9234 - val_loss: 0.3056 - val_acc: 0.8958\n",
            "Epoch 591/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1987 - acc: 0.9234 - val_loss: 0.3147 - val_acc: 0.8937\n",
            "Epoch 592/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1982 - acc: 0.9235 - val_loss: 0.2967 - val_acc: 0.8970\n",
            "Epoch 593/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1982 - acc: 0.9234 - val_loss: 0.3226 - val_acc: 0.8912\n",
            "Epoch 594/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1982 - acc: 0.9236 - val_loss: 0.3021 - val_acc: 0.8968\n",
            "Epoch 595/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1981 - acc: 0.9235 - val_loss: 0.3226 - val_acc: 0.8935\n",
            "Epoch 596/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1986 - acc: 0.9235 - val_loss: 0.2923 - val_acc: 0.8988\n",
            "Epoch 597/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1978 - acc: 0.9236 - val_loss: 0.2976 - val_acc: 0.8999\n",
            "Epoch 598/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1987 - acc: 0.9233 - val_loss: 0.2986 - val_acc: 0.8952\n",
            "Epoch 599/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1982 - acc: 0.9234 - val_loss: 0.3281 - val_acc: 0.8895\n",
            "Epoch 600/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1989 - acc: 0.9230 - val_loss: 0.3581 - val_acc: 0.8859\n",
            "Epoch 601/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1980 - acc: 0.9236 - val_loss: 0.3266 - val_acc: 0.8927\n",
            "Epoch 602/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1983 - acc: 0.9236 - val_loss: 0.2970 - val_acc: 0.8969\n",
            "Epoch 603/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1979 - acc: 0.9236 - val_loss: 0.3223 - val_acc: 0.8905\n",
            "Epoch 604/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1982 - acc: 0.9236 - val_loss: 0.2740 - val_acc: 0.9006\n",
            "Epoch 605/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1985 - acc: 0.9232 - val_loss: 0.3244 - val_acc: 0.8918\n",
            "Epoch 606/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1982 - acc: 0.9232 - val_loss: 0.3452 - val_acc: 0.8893\n",
            "Epoch 607/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1988 - acc: 0.9229 - val_loss: 0.3460 - val_acc: 0.8857\n",
            "Epoch 608/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1980 - acc: 0.9235 - val_loss: 0.3109 - val_acc: 0.8978\n",
            "Epoch 609/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1983 - acc: 0.9238 - val_loss: 0.3218 - val_acc: 0.8929\n",
            "Epoch 610/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1981 - acc: 0.9236 - val_loss: 0.2914 - val_acc: 0.8983\n",
            "Epoch 611/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1981 - acc: 0.9236 - val_loss: 0.2983 - val_acc: 0.8965\n",
            "Epoch 612/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1982 - acc: 0.9235 - val_loss: 0.3269 - val_acc: 0.8888\n",
            "Epoch 613/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1982 - acc: 0.9235 - val_loss: 0.2869 - val_acc: 0.8981\n",
            "Epoch 614/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1981 - acc: 0.9234 - val_loss: 0.2731 - val_acc: 0.9006\n",
            "Epoch 615/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1984 - acc: 0.9234 - val_loss: 0.2772 - val_acc: 0.9010\n",
            "Epoch 616/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1981 - acc: 0.9235 - val_loss: 0.3024 - val_acc: 0.8966\n",
            "Epoch 617/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1973 - acc: 0.9239 - val_loss: 0.3228 - val_acc: 0.8924\n",
            "Epoch 618/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1990 - acc: 0.9234 - val_loss: 0.2948 - val_acc: 0.8982\n",
            "Epoch 619/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1984 - acc: 0.9234 - val_loss: 0.2731 - val_acc: 0.9024\n",
            "Epoch 620/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1976 - acc: 0.9237 - val_loss: 0.3169 - val_acc: 0.8911\n",
            "Epoch 621/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1982 - acc: 0.9235 - val_loss: 0.3420 - val_acc: 0.8906\n",
            "Epoch 622/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1980 - acc: 0.9234 - val_loss: 0.2818 - val_acc: 0.8996\n",
            "Epoch 623/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1980 - acc: 0.9235 - val_loss: 0.2989 - val_acc: 0.8953\n",
            "Epoch 624/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1975 - acc: 0.9240 - val_loss: 0.3034 - val_acc: 0.8887\n",
            "Epoch 625/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1977 - acc: 0.9237 - val_loss: 0.3229 - val_acc: 0.8875\n",
            "Epoch 626/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1983 - acc: 0.9235 - val_loss: 0.3443 - val_acc: 0.8907\n",
            "Epoch 627/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1973 - acc: 0.9236 - val_loss: 0.2565 - val_acc: 0.9067\n",
            "Epoch 628/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1980 - acc: 0.9236 - val_loss: 0.3087 - val_acc: 0.8970\n",
            "Epoch 629/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1980 - acc: 0.9238 - val_loss: 0.3108 - val_acc: 0.8968\n",
            "Epoch 630/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1977 - acc: 0.9237 - val_loss: 0.3045 - val_acc: 0.8998\n",
            "Epoch 631/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1985 - acc: 0.9233 - val_loss: 0.3152 - val_acc: 0.8865\n",
            "Epoch 632/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1978 - acc: 0.9234 - val_loss: 0.2893 - val_acc: 0.8977\n",
            "Epoch 633/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1977 - acc: 0.9238 - val_loss: 0.3529 - val_acc: 0.8823\n",
            "Epoch 634/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1987 - acc: 0.9234 - val_loss: 0.3257 - val_acc: 0.8870\n",
            "Epoch 635/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1979 - acc: 0.9236 - val_loss: 0.3246 - val_acc: 0.8957\n",
            "Epoch 636/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1983 - acc: 0.9230 - val_loss: 0.2999 - val_acc: 0.8962\n",
            "Epoch 637/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1975 - acc: 0.9236 - val_loss: 0.3337 - val_acc: 0.8906\n",
            "Epoch 638/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1979 - acc: 0.9239 - val_loss: 0.3184 - val_acc: 0.8932\n",
            "Epoch 639/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1988 - acc: 0.9233 - val_loss: 0.3868 - val_acc: 0.8781\n",
            "Epoch 640/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1981 - acc: 0.9234 - val_loss: 0.2856 - val_acc: 0.8988\n",
            "Epoch 641/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1976 - acc: 0.9239 - val_loss: 0.2843 - val_acc: 0.8982\n",
            "Epoch 642/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1980 - acc: 0.9234 - val_loss: 0.3146 - val_acc: 0.8936\n",
            "Epoch 643/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1982 - acc: 0.9233 - val_loss: 0.3342 - val_acc: 0.8858\n",
            "Epoch 644/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1974 - acc: 0.9238 - val_loss: 0.3043 - val_acc: 0.8965\n",
            "Epoch 645/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1983 - acc: 0.9235 - val_loss: 0.2835 - val_acc: 0.8995\n",
            "Epoch 646/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1976 - acc: 0.9236 - val_loss: 0.2881 - val_acc: 0.8954\n",
            "Epoch 647/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1976 - acc: 0.9234 - val_loss: 0.2773 - val_acc: 0.9013\n",
            "Epoch 648/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1983 - acc: 0.9234 - val_loss: 0.3012 - val_acc: 0.8972\n",
            "Epoch 649/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1976 - acc: 0.9236 - val_loss: 0.2906 - val_acc: 0.9004\n",
            "Epoch 650/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1980 - acc: 0.9235 - val_loss: 0.3563 - val_acc: 0.8864\n",
            "Epoch 651/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1975 - acc: 0.9240 - val_loss: 0.3080 - val_acc: 0.8930\n",
            "Epoch 652/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1974 - acc: 0.9239 - val_loss: 0.2865 - val_acc: 0.8978\n",
            "Epoch 653/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1981 - acc: 0.9235 - val_loss: 0.2601 - val_acc: 0.9019\n",
            "Epoch 654/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1979 - acc: 0.9237 - val_loss: 0.3863 - val_acc: 0.8815\n",
            "Epoch 655/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1973 - acc: 0.9238 - val_loss: 0.2847 - val_acc: 0.8973\n",
            "Epoch 656/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1972 - acc: 0.9238 - val_loss: 0.2912 - val_acc: 0.8957\n",
            "Epoch 657/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1978 - acc: 0.9237 - val_loss: 0.3001 - val_acc: 0.8937\n",
            "Epoch 658/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1977 - acc: 0.9238 - val_loss: 0.2671 - val_acc: 0.9048\n",
            "Epoch 659/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1978 - acc: 0.9238 - val_loss: 0.3121 - val_acc: 0.8945\n",
            "Epoch 660/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1974 - acc: 0.9237 - val_loss: 0.3172 - val_acc: 0.8948\n",
            "Epoch 661/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1978 - acc: 0.9236 - val_loss: 0.2994 - val_acc: 0.8974\n",
            "Epoch 662/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1985 - acc: 0.9233 - val_loss: 0.3486 - val_acc: 0.8885\n",
            "Epoch 663/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1972 - acc: 0.9239 - val_loss: 0.2926 - val_acc: 0.8960\n",
            "Epoch 664/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1969 - acc: 0.9242 - val_loss: 0.2929 - val_acc: 0.8972\n",
            "Epoch 665/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1981 - acc: 0.9232 - val_loss: 0.3063 - val_acc: 0.8961\n",
            "Epoch 666/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1974 - acc: 0.9236 - val_loss: 0.3255 - val_acc: 0.8905\n",
            "Epoch 667/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1978 - acc: 0.9235 - val_loss: 0.3001 - val_acc: 0.8948\n",
            "Epoch 668/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1971 - acc: 0.9239 - val_loss: 0.3424 - val_acc: 0.8842\n",
            "Epoch 669/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1977 - acc: 0.9233 - val_loss: 0.2834 - val_acc: 0.8985\n",
            "Epoch 670/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1982 - acc: 0.9234 - val_loss: 0.3359 - val_acc: 0.8869\n",
            "Epoch 671/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1971 - acc: 0.9239 - val_loss: 0.3360 - val_acc: 0.8861\n",
            "Epoch 672/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1975 - acc: 0.9236 - val_loss: 0.2784 - val_acc: 0.8986\n",
            "Epoch 673/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1973 - acc: 0.9238 - val_loss: 0.3026 - val_acc: 0.8975\n",
            "Epoch 674/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1975 - acc: 0.9236 - val_loss: 0.3006 - val_acc: 0.8973\n",
            "Epoch 675/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1977 - acc: 0.9235 - val_loss: 0.3007 - val_acc: 0.8935\n",
            "Epoch 676/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1976 - acc: 0.9236 - val_loss: 0.3465 - val_acc: 0.8882\n",
            "Epoch 677/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1975 - acc: 0.9236 - val_loss: 0.2783 - val_acc: 0.9002\n",
            "Epoch 678/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1972 - acc: 0.9236 - val_loss: 0.3294 - val_acc: 0.8887\n",
            "Epoch 679/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1969 - acc: 0.9240 - val_loss: 0.2917 - val_acc: 0.8993\n",
            "Epoch 680/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1978 - acc: 0.9238 - val_loss: 0.2911 - val_acc: 0.8971\n",
            "Epoch 681/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1975 - acc: 0.9239 - val_loss: 0.3039 - val_acc: 0.8970\n",
            "Epoch 682/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1973 - acc: 0.9239 - val_loss: 0.2837 - val_acc: 0.9021\n",
            "Epoch 683/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1971 - acc: 0.9238 - val_loss: 0.2914 - val_acc: 0.8983\n",
            "Epoch 684/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1973 - acc: 0.9238 - val_loss: 0.3229 - val_acc: 0.8927\n",
            "Epoch 685/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1979 - acc: 0.9236 - val_loss: 0.2992 - val_acc: 0.8935\n",
            "Epoch 686/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1978 - acc: 0.9234 - val_loss: 0.2880 - val_acc: 0.8984\n",
            "Epoch 687/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1970 - acc: 0.9240 - val_loss: 0.3199 - val_acc: 0.8931\n",
            "Epoch 688/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1978 - acc: 0.9239 - val_loss: 0.3404 - val_acc: 0.8865\n",
            "Epoch 689/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1979 - acc: 0.9236 - val_loss: 0.3031 - val_acc: 0.8946\n",
            "Epoch 690/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1974 - acc: 0.9237 - val_loss: 0.2996 - val_acc: 0.8952\n",
            "Epoch 691/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1972 - acc: 0.9240 - val_loss: 0.3011 - val_acc: 0.8953\n",
            "Epoch 692/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1968 - acc: 0.9238 - val_loss: 0.3218 - val_acc: 0.8927\n",
            "Epoch 693/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1974 - acc: 0.9236 - val_loss: 0.3032 - val_acc: 0.8958\n",
            "Epoch 694/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1974 - acc: 0.9238 - val_loss: 0.2906 - val_acc: 0.8977\n",
            "Epoch 695/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1974 - acc: 0.9237 - val_loss: 0.3226 - val_acc: 0.8890\n",
            "Epoch 696/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1972 - acc: 0.9240 - val_loss: 0.3153 - val_acc: 0.8950\n",
            "Epoch 697/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1971 - acc: 0.9239 - val_loss: 0.2895 - val_acc: 0.8988\n",
            "Epoch 698/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1970 - acc: 0.9240 - val_loss: 0.2772 - val_acc: 0.8967\n",
            "Epoch 699/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1967 - acc: 0.9241 - val_loss: 0.3414 - val_acc: 0.8901\n",
            "Epoch 700/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1971 - acc: 0.9240 - val_loss: 0.3347 - val_acc: 0.8891\n",
            "Epoch 701/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1966 - acc: 0.9244 - val_loss: 0.3170 - val_acc: 0.8922\n",
            "Epoch 702/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1971 - acc: 0.9237 - val_loss: 0.3126 - val_acc: 0.8924\n",
            "Epoch 703/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1970 - acc: 0.9238 - val_loss: 0.2886 - val_acc: 0.9000\n",
            "Epoch 704/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1973 - acc: 0.9238 - val_loss: 0.3115 - val_acc: 0.8946\n",
            "Epoch 705/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1970 - acc: 0.9238 - val_loss: 0.2818 - val_acc: 0.8989\n",
            "Epoch 706/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1962 - acc: 0.9244 - val_loss: 0.2855 - val_acc: 0.9000\n",
            "Epoch 707/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1972 - acc: 0.9241 - val_loss: 0.3433 - val_acc: 0.8886\n",
            "Epoch 708/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1967 - acc: 0.9241 - val_loss: 0.2967 - val_acc: 0.8956\n",
            "Epoch 709/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1972 - acc: 0.9238 - val_loss: 0.2756 - val_acc: 0.9020\n",
            "Epoch 710/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1969 - acc: 0.9238 - val_loss: 0.3009 - val_acc: 0.8963\n",
            "Epoch 711/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1967 - acc: 0.9238 - val_loss: 0.3446 - val_acc: 0.8880\n",
            "Epoch 712/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1972 - acc: 0.9238 - val_loss: 0.2928 - val_acc: 0.8975\n",
            "Epoch 713/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1972 - acc: 0.9236 - val_loss: 0.3117 - val_acc: 0.8900\n",
            "Epoch 714/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1975 - acc: 0.9237 - val_loss: 0.2909 - val_acc: 0.8990\n",
            "Epoch 715/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1968 - acc: 0.9242 - val_loss: 0.3051 - val_acc: 0.8926\n",
            "Epoch 716/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1975 - acc: 0.9238 - val_loss: 0.2636 - val_acc: 0.9056\n",
            "Epoch 717/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1972 - acc: 0.9237 - val_loss: 0.2928 - val_acc: 0.8989\n",
            "Epoch 718/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1970 - acc: 0.9239 - val_loss: 0.3190 - val_acc: 0.8929\n",
            "Epoch 719/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1971 - acc: 0.9240 - val_loss: 0.2853 - val_acc: 0.8955\n",
            "Epoch 720/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1970 - acc: 0.9238 - val_loss: 0.3001 - val_acc: 0.8949\n",
            "Epoch 721/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1965 - acc: 0.9241 - val_loss: 0.2760 - val_acc: 0.9011\n",
            "Epoch 722/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1968 - acc: 0.9240 - val_loss: 0.2936 - val_acc: 0.8988\n",
            "Epoch 723/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1968 - acc: 0.9240 - val_loss: 0.3686 - val_acc: 0.8823\n",
            "Epoch 724/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1967 - acc: 0.9240 - val_loss: 0.3712 - val_acc: 0.8828\n",
            "Epoch 725/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1970 - acc: 0.9237 - val_loss: 0.2882 - val_acc: 0.9009\n",
            "Epoch 726/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1964 - acc: 0.9241 - val_loss: 0.2783 - val_acc: 0.9002\n",
            "Epoch 727/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1971 - acc: 0.9238 - val_loss: 0.3573 - val_acc: 0.8863\n",
            "Epoch 728/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1970 - acc: 0.9239 - val_loss: 0.3378 - val_acc: 0.8885\n",
            "Epoch 729/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1968 - acc: 0.9241 - val_loss: 0.3236 - val_acc: 0.8917\n",
            "Epoch 730/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1967 - acc: 0.9241 - val_loss: 0.3243 - val_acc: 0.8891\n",
            "Epoch 731/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1970 - acc: 0.9237 - val_loss: 0.3943 - val_acc: 0.8824\n",
            "Epoch 732/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1966 - acc: 0.9244 - val_loss: 0.3378 - val_acc: 0.8894\n",
            "Epoch 733/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1965 - acc: 0.9242 - val_loss: 0.2817 - val_acc: 0.9014\n",
            "Epoch 734/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1968 - acc: 0.9241 - val_loss: 0.2789 - val_acc: 0.9014\n",
            "Epoch 735/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1975 - acc: 0.9239 - val_loss: 0.3101 - val_acc: 0.8951\n",
            "Epoch 736/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1965 - acc: 0.9240 - val_loss: 0.2914 - val_acc: 0.8999\n",
            "Epoch 737/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1960 - acc: 0.9243 - val_loss: 0.3027 - val_acc: 0.8951\n",
            "Epoch 738/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1966 - acc: 0.9238 - val_loss: 0.2994 - val_acc: 0.8952\n",
            "Epoch 739/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1971 - acc: 0.9239 - val_loss: 0.3605 - val_acc: 0.8883\n",
            "Epoch 740/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1962 - acc: 0.9243 - val_loss: 0.2974 - val_acc: 0.8960\n",
            "Epoch 741/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1966 - acc: 0.9237 - val_loss: 0.3106 - val_acc: 0.8943\n",
            "Epoch 742/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1960 - acc: 0.9241 - val_loss: 0.3219 - val_acc: 0.8918\n",
            "Epoch 743/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1965 - acc: 0.9244 - val_loss: 0.3108 - val_acc: 0.8966\n",
            "Epoch 744/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1964 - acc: 0.9242 - val_loss: 0.3220 - val_acc: 0.8939\n",
            "Epoch 745/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1971 - acc: 0.9239 - val_loss: 0.3018 - val_acc: 0.8964\n",
            "Epoch 746/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1968 - acc: 0.9240 - val_loss: 0.2891 - val_acc: 0.8994\n",
            "Epoch 747/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1964 - acc: 0.9240 - val_loss: 0.3255 - val_acc: 0.8888\n",
            "Epoch 748/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1971 - acc: 0.9242 - val_loss: 0.3421 - val_acc: 0.8869\n",
            "Epoch 749/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1964 - acc: 0.9242 - val_loss: 0.2959 - val_acc: 0.8958\n",
            "Epoch 750/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1964 - acc: 0.9241 - val_loss: 0.2914 - val_acc: 0.8975\n",
            "Epoch 751/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1964 - acc: 0.9240 - val_loss: 0.3071 - val_acc: 0.8946\n",
            "Epoch 752/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1964 - acc: 0.9241 - val_loss: 0.3235 - val_acc: 0.8922\n",
            "Epoch 753/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1971 - acc: 0.9239 - val_loss: 0.3051 - val_acc: 0.8964\n",
            "Epoch 754/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1966 - acc: 0.9240 - val_loss: 0.3095 - val_acc: 0.8943\n",
            "Epoch 755/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1964 - acc: 0.9243 - val_loss: 0.2988 - val_acc: 0.8961\n",
            "Epoch 756/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1966 - acc: 0.9239 - val_loss: 0.3130 - val_acc: 0.8929\n",
            "Epoch 757/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1966 - acc: 0.9241 - val_loss: 0.3106 - val_acc: 0.8940\n",
            "Epoch 758/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1967 - acc: 0.9242 - val_loss: 0.3347 - val_acc: 0.8900\n",
            "Epoch 759/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1969 - acc: 0.9239 - val_loss: 0.3234 - val_acc: 0.8946\n",
            "Epoch 760/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1964 - acc: 0.9241 - val_loss: 0.3177 - val_acc: 0.8908\n",
            "Epoch 761/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1963 - acc: 0.9243 - val_loss: 0.3792 - val_acc: 0.8840\n",
            "Epoch 762/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1963 - acc: 0.9244 - val_loss: 0.2842 - val_acc: 0.8998\n",
            "Epoch 763/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1965 - acc: 0.9240 - val_loss: 0.3159 - val_acc: 0.8888\n",
            "Epoch 764/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1962 - acc: 0.9241 - val_loss: 0.3462 - val_acc: 0.8866\n",
            "Epoch 765/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1966 - acc: 0.9239 - val_loss: 0.3293 - val_acc: 0.8935\n",
            "Epoch 766/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1957 - acc: 0.9243 - val_loss: 0.3075 - val_acc: 0.8933\n",
            "Epoch 767/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1963 - acc: 0.9240 - val_loss: 0.2964 - val_acc: 0.8966\n",
            "Epoch 768/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1964 - acc: 0.9242 - val_loss: 0.2927 - val_acc: 0.9003\n",
            "Epoch 769/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1970 - acc: 0.9240 - val_loss: 0.3741 - val_acc: 0.8847\n",
            "Epoch 770/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1966 - acc: 0.9241 - val_loss: 0.3281 - val_acc: 0.8933\n",
            "Epoch 771/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1971 - acc: 0.9239 - val_loss: 0.2734 - val_acc: 0.9020\n",
            "Epoch 772/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1956 - acc: 0.9243 - val_loss: 0.3138 - val_acc: 0.8968\n",
            "Epoch 773/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1962 - acc: 0.9245 - val_loss: 0.2893 - val_acc: 0.9006\n",
            "Epoch 774/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1958 - acc: 0.9245 - val_loss: 0.3147 - val_acc: 0.8944\n",
            "Epoch 775/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1962 - acc: 0.9241 - val_loss: 0.3396 - val_acc: 0.8913\n",
            "Epoch 776/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1966 - acc: 0.9241 - val_loss: 0.3387 - val_acc: 0.8896\n",
            "Epoch 777/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1965 - acc: 0.9242 - val_loss: 0.3428 - val_acc: 0.8863\n",
            "Epoch 778/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1968 - acc: 0.9240 - val_loss: 0.3241 - val_acc: 0.8929\n",
            "Epoch 779/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1956 - acc: 0.9243 - val_loss: 0.3539 - val_acc: 0.8847\n",
            "Epoch 780/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1966 - acc: 0.9239 - val_loss: 0.2847 - val_acc: 0.9002\n",
            "Epoch 781/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1952 - acc: 0.9246 - val_loss: 0.3092 - val_acc: 0.8946\n",
            "Epoch 782/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1963 - acc: 0.9242 - val_loss: 0.3187 - val_acc: 0.8914\n",
            "Epoch 783/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1965 - acc: 0.9241 - val_loss: 0.3383 - val_acc: 0.8907\n",
            "Epoch 784/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1957 - acc: 0.9243 - val_loss: 0.3165 - val_acc: 0.8929\n",
            "Epoch 785/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1959 - acc: 0.9244 - val_loss: 0.3821 - val_acc: 0.8790\n",
            "Epoch 786/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1959 - acc: 0.9243 - val_loss: 0.2962 - val_acc: 0.8983\n",
            "Epoch 787/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1966 - acc: 0.9240 - val_loss: 0.3206 - val_acc: 0.8921\n",
            "Epoch 788/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1964 - acc: 0.9241 - val_loss: 0.3181 - val_acc: 0.8944\n",
            "Epoch 789/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1953 - acc: 0.9246 - val_loss: 0.3103 - val_acc: 0.8944\n",
            "Epoch 790/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1956 - acc: 0.9243 - val_loss: 0.2962 - val_acc: 0.8971\n",
            "Epoch 791/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1959 - acc: 0.9244 - val_loss: 0.3460 - val_acc: 0.8878\n",
            "Epoch 792/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1961 - acc: 0.9245 - val_loss: 0.3892 - val_acc: 0.8813\n",
            "Epoch 793/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1958 - acc: 0.9244 - val_loss: 0.3080 - val_acc: 0.8944\n",
            "Epoch 794/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1958 - acc: 0.9243 - val_loss: 0.3038 - val_acc: 0.8967\n",
            "Epoch 795/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1963 - acc: 0.9241 - val_loss: 0.3013 - val_acc: 0.8985\n",
            "Epoch 796/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1966 - acc: 0.9243 - val_loss: 0.2809 - val_acc: 0.8988\n",
            "Epoch 797/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1961 - acc: 0.9241 - val_loss: 0.2847 - val_acc: 0.8987\n",
            "Epoch 798/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1966 - acc: 0.9240 - val_loss: 0.2999 - val_acc: 0.8978\n",
            "Epoch 799/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1957 - acc: 0.9246 - val_loss: 0.3004 - val_acc: 0.8949\n",
            "Epoch 800/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1960 - acc: 0.9244 - val_loss: 0.3010 - val_acc: 0.8927\n",
            "Epoch 801/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1956 - acc: 0.9241 - val_loss: 0.2794 - val_acc: 0.9019\n",
            "Epoch 802/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1965 - acc: 0.9239 - val_loss: 0.3500 - val_acc: 0.8888\n",
            "Epoch 803/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1961 - acc: 0.9244 - val_loss: 0.3223 - val_acc: 0.8915\n",
            "Epoch 804/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1964 - acc: 0.9241 - val_loss: 0.3298 - val_acc: 0.8908\n",
            "Epoch 805/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1958 - acc: 0.9241 - val_loss: 0.2995 - val_acc: 0.8965\n",
            "Epoch 806/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1958 - acc: 0.9243 - val_loss: 0.3018 - val_acc: 0.8968\n",
            "Epoch 807/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1960 - acc: 0.9242 - val_loss: 0.3345 - val_acc: 0.8908\n",
            "Epoch 808/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1956 - acc: 0.9246 - val_loss: 0.3044 - val_acc: 0.8943\n",
            "Epoch 809/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1957 - acc: 0.9243 - val_loss: 0.2968 - val_acc: 0.8976\n",
            "Epoch 810/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1963 - acc: 0.9243 - val_loss: 0.3188 - val_acc: 0.8932\n",
            "Epoch 811/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1964 - acc: 0.9241 - val_loss: 0.2737 - val_acc: 0.9014\n",
            "Epoch 812/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1961 - acc: 0.9242 - val_loss: 0.3080 - val_acc: 0.8943\n",
            "Epoch 813/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1964 - acc: 0.9240 - val_loss: 0.2863 - val_acc: 0.8982\n",
            "Epoch 814/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1961 - acc: 0.9244 - val_loss: 0.3079 - val_acc: 0.8953\n",
            "Epoch 815/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1958 - acc: 0.9246 - val_loss: 0.3598 - val_acc: 0.8860\n",
            "Epoch 816/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1951 - acc: 0.9245 - val_loss: 0.3353 - val_acc: 0.8900\n",
            "Epoch 817/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1955 - acc: 0.9245 - val_loss: 0.3073 - val_acc: 0.8971\n",
            "Epoch 818/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1959 - acc: 0.9246 - val_loss: 0.3258 - val_acc: 0.8917\n",
            "Epoch 819/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1957 - acc: 0.9247 - val_loss: 0.3484 - val_acc: 0.8892\n",
            "Epoch 820/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1958 - acc: 0.9242 - val_loss: 0.3224 - val_acc: 0.8913\n",
            "Epoch 821/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1957 - acc: 0.9244 - val_loss: 0.3035 - val_acc: 0.8971\n",
            "Epoch 822/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1962 - acc: 0.9240 - val_loss: 0.3456 - val_acc: 0.8889\n",
            "Epoch 823/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1950 - acc: 0.9246 - val_loss: 0.3567 - val_acc: 0.8872\n",
            "Epoch 824/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1960 - acc: 0.9241 - val_loss: 0.2678 - val_acc: 0.9022\n",
            "Epoch 825/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1961 - acc: 0.9243 - val_loss: 0.3251 - val_acc: 0.8898\n",
            "Epoch 826/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1962 - acc: 0.9243 - val_loss: 0.3241 - val_acc: 0.8926\n",
            "Epoch 827/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1961 - acc: 0.9243 - val_loss: 0.3526 - val_acc: 0.8880\n",
            "Epoch 828/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1960 - acc: 0.9241 - val_loss: 0.2916 - val_acc: 0.8965\n",
            "Epoch 829/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1965 - acc: 0.9239 - val_loss: 0.3310 - val_acc: 0.8912\n",
            "Epoch 830/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1950 - acc: 0.9246 - val_loss: 0.3551 - val_acc: 0.8822\n",
            "Epoch 831/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1955 - acc: 0.9243 - val_loss: 0.3567 - val_acc: 0.8862\n",
            "Epoch 832/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1957 - acc: 0.9243 - val_loss: 0.3463 - val_acc: 0.8906\n",
            "Epoch 833/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1961 - acc: 0.9244 - val_loss: 0.3242 - val_acc: 0.8893\n",
            "Epoch 834/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1957 - acc: 0.9244 - val_loss: 0.3146 - val_acc: 0.8933\n",
            "Epoch 835/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1955 - acc: 0.9246 - val_loss: 0.3175 - val_acc: 0.8865\n",
            "Epoch 836/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1958 - acc: 0.9244 - val_loss: 0.3770 - val_acc: 0.8851\n",
            "Epoch 837/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1953 - acc: 0.9246 - val_loss: 0.4034 - val_acc: 0.8812\n",
            "Epoch 838/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1955 - acc: 0.9242 - val_loss: 0.3789 - val_acc: 0.8827\n",
            "Epoch 839/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1955 - acc: 0.9245 - val_loss: 0.3211 - val_acc: 0.8934\n",
            "Epoch 840/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1957 - acc: 0.9242 - val_loss: 0.3298 - val_acc: 0.8920\n",
            "Epoch 841/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1955 - acc: 0.9247 - val_loss: 0.3235 - val_acc: 0.8902\n",
            "Epoch 842/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1955 - acc: 0.9244 - val_loss: 0.3301 - val_acc: 0.8916\n",
            "Epoch 843/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1959 - acc: 0.9245 - val_loss: 0.3365 - val_acc: 0.8926\n",
            "Epoch 844/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1956 - acc: 0.9246 - val_loss: 0.3383 - val_acc: 0.8895\n",
            "Epoch 845/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1967 - acc: 0.9239 - val_loss: 0.3121 - val_acc: 0.8953\n",
            "Epoch 846/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1960 - acc: 0.9242 - val_loss: 0.3055 - val_acc: 0.8951\n",
            "Epoch 847/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1957 - acc: 0.9243 - val_loss: 0.3178 - val_acc: 0.8926\n",
            "Epoch 848/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1955 - acc: 0.9244 - val_loss: 0.3063 - val_acc: 0.8966\n",
            "Epoch 849/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1955 - acc: 0.9246 - val_loss: 0.3035 - val_acc: 0.8942\n",
            "Epoch 850/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1955 - acc: 0.9243 - val_loss: 0.3070 - val_acc: 0.8961\n",
            "Epoch 851/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1959 - acc: 0.9245 - val_loss: 0.2838 - val_acc: 0.9006\n",
            "Epoch 852/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1954 - acc: 0.9245 - val_loss: 0.3473 - val_acc: 0.8858\n",
            "Epoch 853/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1958 - acc: 0.9242 - val_loss: 0.3420 - val_acc: 0.8907\n",
            "Epoch 854/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1965 - acc: 0.9241 - val_loss: 0.3520 - val_acc: 0.8883\n",
            "Epoch 855/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1953 - acc: 0.9244 - val_loss: 0.3261 - val_acc: 0.8910\n",
            "Epoch 856/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1956 - acc: 0.9246 - val_loss: 0.3330 - val_acc: 0.8944\n",
            "Epoch 857/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1952 - acc: 0.9247 - val_loss: 0.2761 - val_acc: 0.9021\n",
            "Epoch 858/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1960 - acc: 0.9242 - val_loss: 0.3433 - val_acc: 0.8892\n",
            "Epoch 859/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1965 - acc: 0.9242 - val_loss: 0.3196 - val_acc: 0.8933\n",
            "Epoch 860/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1960 - acc: 0.9244 - val_loss: 0.3346 - val_acc: 0.8918\n",
            "Epoch 861/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1949 - acc: 0.9246 - val_loss: 0.2956 - val_acc: 0.8982\n",
            "Epoch 862/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1951 - acc: 0.9247 - val_loss: 0.3429 - val_acc: 0.8885\n",
            "Epoch 863/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1946 - acc: 0.9248 - val_loss: 0.3448 - val_acc: 0.8906\n",
            "Epoch 864/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1961 - acc: 0.9244 - val_loss: 0.3542 - val_acc: 0.8859\n",
            "Epoch 865/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1957 - acc: 0.9247 - val_loss: 0.3325 - val_acc: 0.8907\n",
            "Epoch 866/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1955 - acc: 0.9246 - val_loss: 0.3552 - val_acc: 0.8867\n",
            "Epoch 867/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1956 - acc: 0.9245 - val_loss: 0.3109 - val_acc: 0.8953\n",
            "Epoch 868/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1957 - acc: 0.9245 - val_loss: 0.3613 - val_acc: 0.8849\n",
            "Epoch 869/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1962 - acc: 0.9243 - val_loss: 0.2793 - val_acc: 0.9010\n",
            "Epoch 870/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1951 - acc: 0.9246 - val_loss: 0.3692 - val_acc: 0.8891\n",
            "Epoch 871/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1953 - acc: 0.9249 - val_loss: 0.3412 - val_acc: 0.8911\n",
            "Epoch 872/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1950 - acc: 0.9247 - val_loss: 0.3321 - val_acc: 0.8934\n",
            "Epoch 873/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1955 - acc: 0.9244 - val_loss: 0.2946 - val_acc: 0.8963\n",
            "Epoch 874/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1952 - acc: 0.9246 - val_loss: 0.3159 - val_acc: 0.8938\n",
            "Epoch 875/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1965 - acc: 0.9240 - val_loss: 0.3719 - val_acc: 0.8842\n",
            "Epoch 876/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1948 - acc: 0.9247 - val_loss: 0.3356 - val_acc: 0.8886\n",
            "Epoch 877/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1954 - acc: 0.9246 - val_loss: 0.3064 - val_acc: 0.8942\n",
            "Epoch 878/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1958 - acc: 0.9241 - val_loss: 0.3294 - val_acc: 0.8928\n",
            "Epoch 879/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1955 - acc: 0.9245 - val_loss: 0.3433 - val_acc: 0.8914\n",
            "Epoch 880/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1946 - acc: 0.9250 - val_loss: 0.3118 - val_acc: 0.8941\n",
            "Epoch 881/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1955 - acc: 0.9245 - val_loss: 0.3345 - val_acc: 0.8935\n",
            "Epoch 882/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1961 - acc: 0.9243 - val_loss: 0.3080 - val_acc: 0.8939\n",
            "Epoch 883/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1952 - acc: 0.9246 - val_loss: 0.3077 - val_acc: 0.8950\n",
            "Epoch 884/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1957 - acc: 0.9243 - val_loss: 0.3323 - val_acc: 0.8923\n",
            "Epoch 885/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1958 - acc: 0.9244 - val_loss: 0.3562 - val_acc: 0.8853\n",
            "Epoch 886/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1951 - acc: 0.9245 - val_loss: 0.2933 - val_acc: 0.8993\n",
            "Epoch 887/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1956 - acc: 0.9245 - val_loss: 0.3468 - val_acc: 0.8909\n",
            "Epoch 888/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1953 - acc: 0.9248 - val_loss: 0.3486 - val_acc: 0.8908\n",
            "Epoch 889/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1947 - acc: 0.9250 - val_loss: 0.3609 - val_acc: 0.8860\n",
            "Epoch 890/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1954 - acc: 0.9246 - val_loss: 0.3097 - val_acc: 0.8931\n",
            "Epoch 891/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1951 - acc: 0.9245 - val_loss: 0.3353 - val_acc: 0.8916\n",
            "Epoch 892/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1954 - acc: 0.9247 - val_loss: 0.3198 - val_acc: 0.8907\n",
            "Epoch 893/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1951 - acc: 0.9250 - val_loss: 0.3155 - val_acc: 0.8938\n",
            "Epoch 894/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1953 - acc: 0.9244 - val_loss: 0.3138 - val_acc: 0.8920\n",
            "Epoch 895/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1950 - acc: 0.9247 - val_loss: 0.3533 - val_acc: 0.8856\n",
            "Epoch 896/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1952 - acc: 0.9248 - val_loss: 0.3051 - val_acc: 0.8980\n",
            "Epoch 897/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1954 - acc: 0.9244 - val_loss: 0.3179 - val_acc: 0.8938\n",
            "Epoch 898/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1948 - acc: 0.9247 - val_loss: 0.3393 - val_acc: 0.8890\n",
            "Epoch 899/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1951 - acc: 0.9246 - val_loss: 0.3121 - val_acc: 0.8940\n",
            "Epoch 900/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1950 - acc: 0.9248 - val_loss: 0.3206 - val_acc: 0.8910\n",
            "Epoch 901/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1957 - acc: 0.9243 - val_loss: 0.3334 - val_acc: 0.8930\n",
            "Epoch 902/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1950 - acc: 0.9249 - val_loss: 0.3716 - val_acc: 0.8834\n",
            "Epoch 903/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1948 - acc: 0.9247 - val_loss: 0.3096 - val_acc: 0.8938\n",
            "Epoch 904/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1959 - acc: 0.9245 - val_loss: 0.3079 - val_acc: 0.8970\n",
            "Epoch 905/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1951 - acc: 0.9244 - val_loss: 0.3202 - val_acc: 0.8934\n",
            "Epoch 906/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1953 - acc: 0.9245 - val_loss: 0.3370 - val_acc: 0.8876\n",
            "Epoch 907/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1950 - acc: 0.9247 - val_loss: 0.3349 - val_acc: 0.8915\n",
            "Epoch 908/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1954 - acc: 0.9248 - val_loss: 0.2978 - val_acc: 0.8943\n",
            "Epoch 909/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1952 - acc: 0.9246 - val_loss: 0.3304 - val_acc: 0.8898\n",
            "Epoch 910/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1954 - acc: 0.9243 - val_loss: 0.3597 - val_acc: 0.8851\n",
            "Epoch 911/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1949 - acc: 0.9245 - val_loss: 0.3084 - val_acc: 0.8941\n",
            "Epoch 912/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1950 - acc: 0.9245 - val_loss: 0.3126 - val_acc: 0.8878\n",
            "Epoch 913/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1949 - acc: 0.9248 - val_loss: 0.2988 - val_acc: 0.8972\n",
            "Epoch 914/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1946 - acc: 0.9248 - val_loss: 0.3258 - val_acc: 0.8930\n",
            "Epoch 915/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1952 - acc: 0.9247 - val_loss: 0.3342 - val_acc: 0.8903\n",
            "Epoch 916/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1953 - acc: 0.9244 - val_loss: 0.3525 - val_acc: 0.8887\n",
            "Epoch 917/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1956 - acc: 0.9244 - val_loss: 0.3304 - val_acc: 0.8903\n",
            "Epoch 918/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1942 - acc: 0.9250 - val_loss: 0.3209 - val_acc: 0.8903\n",
            "Epoch 919/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1947 - acc: 0.9252 - val_loss: 0.2883 - val_acc: 0.8994\n",
            "Epoch 920/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1949 - acc: 0.9247 - val_loss: 0.3719 - val_acc: 0.8819\n",
            "Epoch 921/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1949 - acc: 0.9246 - val_loss: 0.3154 - val_acc: 0.8951\n",
            "Epoch 922/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1955 - acc: 0.9246 - val_loss: 0.3213 - val_acc: 0.8938\n",
            "Epoch 923/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1951 - acc: 0.9249 - val_loss: 0.3077 - val_acc: 0.8961\n",
            "Epoch 924/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1954 - acc: 0.9246 - val_loss: 0.3471 - val_acc: 0.8860\n",
            "Epoch 925/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1947 - acc: 0.9247 - val_loss: 0.3217 - val_acc: 0.8857\n",
            "Epoch 926/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1952 - acc: 0.9250 - val_loss: 0.3846 - val_acc: 0.8805\n",
            "Epoch 927/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1948 - acc: 0.9243 - val_loss: 0.3160 - val_acc: 0.8942\n",
            "Epoch 928/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1951 - acc: 0.9245 - val_loss: 0.3187 - val_acc: 0.8950\n",
            "Epoch 929/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1952 - acc: 0.9245 - val_loss: 0.3119 - val_acc: 0.8938\n",
            "Epoch 930/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1942 - acc: 0.9248 - val_loss: 0.3241 - val_acc: 0.8919\n",
            "Epoch 931/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1952 - acc: 0.9247 - val_loss: 0.2816 - val_acc: 0.9012\n",
            "Epoch 932/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1950 - acc: 0.9245 - val_loss: 0.2956 - val_acc: 0.8961\n",
            "Epoch 933/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1944 - acc: 0.9251 - val_loss: 0.3217 - val_acc: 0.8912\n",
            "Epoch 934/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1952 - acc: 0.9247 - val_loss: 0.3474 - val_acc: 0.8886\n",
            "Epoch 935/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1944 - acc: 0.9248 - val_loss: 0.3430 - val_acc: 0.8894\n",
            "Epoch 936/6000\n",
            "584288/584288 [==============================] - 20s 34us/step - loss: 0.1951 - acc: 0.9248 - val_loss: 0.3068 - val_acc: 0.8956\n",
            "Epoch 937/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1957 - acc: 0.9242 - val_loss: 0.2964 - val_acc: 0.8955\n",
            "Epoch 938/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1944 - acc: 0.9249 - val_loss: 0.3252 - val_acc: 0.8940\n",
            "Epoch 939/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1947 - acc: 0.9247 - val_loss: 0.3523 - val_acc: 0.8840\n",
            "Epoch 940/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1948 - acc: 0.9246 - val_loss: 0.3387 - val_acc: 0.8901\n",
            "Epoch 941/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1950 - acc: 0.9246 - val_loss: 0.4017 - val_acc: 0.8811\n",
            "Epoch 942/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1941 - acc: 0.9250 - val_loss: 0.3413 - val_acc: 0.8821\n",
            "Epoch 943/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1948 - acc: 0.9245 - val_loss: 0.3247 - val_acc: 0.8931\n",
            "Epoch 944/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1948 - acc: 0.9245 - val_loss: 0.3068 - val_acc: 0.8962\n",
            "Epoch 945/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1951 - acc: 0.9249 - val_loss: 0.3842 - val_acc: 0.8816\n",
            "Epoch 946/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1945 - acc: 0.9248 - val_loss: 0.2873 - val_acc: 0.8984\n",
            "Epoch 947/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1946 - acc: 0.9248 - val_loss: 0.3366 - val_acc: 0.8902\n",
            "Epoch 948/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1953 - acc: 0.9248 - val_loss: 0.3204 - val_acc: 0.8909\n",
            "Epoch 949/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1952 - acc: 0.9246 - val_loss: 0.3344 - val_acc: 0.8917\n",
            "Epoch 950/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1949 - acc: 0.9244 - val_loss: 0.3184 - val_acc: 0.8939\n",
            "Epoch 951/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1947 - acc: 0.9245 - val_loss: 0.3464 - val_acc: 0.8882\n",
            "Epoch 952/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1954 - acc: 0.9246 - val_loss: 0.3118 - val_acc: 0.8927\n",
            "Epoch 953/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1947 - acc: 0.9246 - val_loss: 0.3722 - val_acc: 0.8874\n",
            "Epoch 954/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1946 - acc: 0.9250 - val_loss: 0.2861 - val_acc: 0.8983\n",
            "Epoch 955/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1956 - acc: 0.9245 - val_loss: 0.3430 - val_acc: 0.8809\n",
            "Epoch 956/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1949 - acc: 0.9247 - val_loss: 0.3390 - val_acc: 0.8895\n",
            "Epoch 957/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1952 - acc: 0.9246 - val_loss: 0.3553 - val_acc: 0.8898\n",
            "Epoch 958/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1950 - acc: 0.9247 - val_loss: 0.3748 - val_acc: 0.8827\n",
            "Epoch 959/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1943 - acc: 0.9252 - val_loss: 0.2890 - val_acc: 0.8982\n",
            "Epoch 960/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1951 - acc: 0.9245 - val_loss: 0.3254 - val_acc: 0.8935\n",
            "Epoch 961/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1954 - acc: 0.9245 - val_loss: 0.3271 - val_acc: 0.8929\n",
            "Epoch 962/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1946 - acc: 0.9248 - val_loss: 0.2945 - val_acc: 0.8971\n",
            "Epoch 963/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1947 - acc: 0.9247 - val_loss: 0.3266 - val_acc: 0.8924\n",
            "Epoch 964/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1946 - acc: 0.9246 - val_loss: 0.3104 - val_acc: 0.8944\n",
            "Epoch 965/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1946 - acc: 0.9247 - val_loss: 0.3224 - val_acc: 0.8892\n",
            "Epoch 966/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1944 - acc: 0.9251 - val_loss: 0.2969 - val_acc: 0.8974\n",
            "Epoch 967/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1940 - acc: 0.9251 - val_loss: 0.3056 - val_acc: 0.8984\n",
            "Epoch 968/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1950 - acc: 0.9248 - val_loss: 0.2887 - val_acc: 0.8977\n",
            "Epoch 969/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1949 - acc: 0.9249 - val_loss: 0.3200 - val_acc: 0.8908\n",
            "Epoch 970/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1951 - acc: 0.9247 - val_loss: 0.2815 - val_acc: 0.9013\n",
            "Epoch 971/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1950 - acc: 0.9247 - val_loss: 0.3054 - val_acc: 0.8949\n",
            "Epoch 972/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1942 - acc: 0.9249 - val_loss: 0.3219 - val_acc: 0.8911\n",
            "Epoch 973/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1945 - acc: 0.9250 - val_loss: 0.3180 - val_acc: 0.8940\n",
            "Epoch 974/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1949 - acc: 0.9248 - val_loss: 0.2953 - val_acc: 0.8932\n",
            "Epoch 975/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1948 - acc: 0.9247 - val_loss: 0.2957 - val_acc: 0.8973\n",
            "Epoch 976/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1949 - acc: 0.9246 - val_loss: 0.3578 - val_acc: 0.8832\n",
            "Epoch 977/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1948 - acc: 0.9250 - val_loss: 0.3110 - val_acc: 0.8946\n",
            "Epoch 978/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1946 - acc: 0.9247 - val_loss: 0.3109 - val_acc: 0.8934\n",
            "Epoch 979/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1949 - acc: 0.9249 - val_loss: 0.3716 - val_acc: 0.8861\n",
            "Epoch 980/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1951 - acc: 0.9246 - val_loss: 0.3351 - val_acc: 0.8882\n",
            "Epoch 981/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1938 - acc: 0.9256 - val_loss: 0.3263 - val_acc: 0.8913\n",
            "Epoch 982/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1944 - acc: 0.9247 - val_loss: 0.3314 - val_acc: 0.8908\n",
            "Epoch 983/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1939 - acc: 0.9254 - val_loss: 0.3147 - val_acc: 0.8935\n",
            "Epoch 984/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1941 - acc: 0.9251 - val_loss: 0.3225 - val_acc: 0.8908\n",
            "Epoch 985/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1943 - acc: 0.9250 - val_loss: 0.3808 - val_acc: 0.8862\n",
            "Epoch 986/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1952 - acc: 0.9246 - val_loss: 0.3257 - val_acc: 0.8926\n",
            "Epoch 987/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1941 - acc: 0.9251 - val_loss: 0.3207 - val_acc: 0.8927\n",
            "Epoch 988/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1943 - acc: 0.9251 - val_loss: 0.3553 - val_acc: 0.8864\n",
            "Epoch 989/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1950 - acc: 0.9247 - val_loss: 0.3211 - val_acc: 0.8946\n",
            "Epoch 990/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1936 - acc: 0.9250 - val_loss: 0.3192 - val_acc: 0.8909\n",
            "Epoch 991/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1946 - acc: 0.9247 - val_loss: 0.3142 - val_acc: 0.8914\n",
            "Epoch 992/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1938 - acc: 0.9250 - val_loss: 0.3235 - val_acc: 0.8898\n",
            "Epoch 993/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1950 - acc: 0.9248 - val_loss: 0.3112 - val_acc: 0.8961\n",
            "Epoch 994/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1945 - acc: 0.9250 - val_loss: 0.3607 - val_acc: 0.8856\n",
            "Epoch 995/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1944 - acc: 0.9250 - val_loss: 0.3154 - val_acc: 0.8973\n",
            "Epoch 996/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1950 - acc: 0.9248 - val_loss: 0.3021 - val_acc: 0.8979\n",
            "Epoch 997/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1939 - acc: 0.9251 - val_loss: 0.2770 - val_acc: 0.9002\n",
            "Epoch 998/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1947 - acc: 0.9250 - val_loss: 0.3647 - val_acc: 0.8841\n",
            "Epoch 999/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1950 - acc: 0.9247 - val_loss: 0.3086 - val_acc: 0.8955\n",
            "Epoch 1000/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1943 - acc: 0.9253 - val_loss: 0.3094 - val_acc: 0.8975\n",
            "Epoch 1001/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1943 - acc: 0.9250 - val_loss: 0.3062 - val_acc: 0.8947\n",
            "Epoch 1002/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1947 - acc: 0.9247 - val_loss: 0.3124 - val_acc: 0.8934\n",
            "Epoch 1003/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1946 - acc: 0.9247 - val_loss: 0.3408 - val_acc: 0.8886\n",
            "Epoch 1004/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1943 - acc: 0.9249 - val_loss: 0.3299 - val_acc: 0.8930\n",
            "Epoch 1005/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1940 - acc: 0.9252 - val_loss: 0.3340 - val_acc: 0.8933\n",
            "Epoch 1006/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1942 - acc: 0.9248 - val_loss: 0.3263 - val_acc: 0.8925\n",
            "Epoch 1007/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1943 - acc: 0.9249 - val_loss: 0.3004 - val_acc: 0.8961\n",
            "Epoch 1008/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1945 - acc: 0.9247 - val_loss: 0.2988 - val_acc: 0.8961\n",
            "Epoch 1009/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1948 - acc: 0.9249 - val_loss: 0.3129 - val_acc: 0.8944\n",
            "Epoch 1010/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1951 - acc: 0.9248 - val_loss: 0.3390 - val_acc: 0.8880\n",
            "Epoch 1011/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1944 - acc: 0.9248 - val_loss: 0.3229 - val_acc: 0.8910\n",
            "Epoch 1012/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1948 - acc: 0.9248 - val_loss: 0.3610 - val_acc: 0.8856\n",
            "Epoch 1013/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1945 - acc: 0.9247 - val_loss: 0.3179 - val_acc: 0.8928\n",
            "Epoch 1014/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1944 - acc: 0.9249 - val_loss: 0.4358 - val_acc: 0.8752\n",
            "Epoch 1015/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1947 - acc: 0.9249 - val_loss: 0.3214 - val_acc: 0.8927\n",
            "Epoch 1016/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1946 - acc: 0.9245 - val_loss: 0.3116 - val_acc: 0.8948\n",
            "Epoch 1017/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1940 - acc: 0.9250 - val_loss: 0.3195 - val_acc: 0.8929\n",
            "Epoch 1018/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1939 - acc: 0.9252 - val_loss: 0.3157 - val_acc: 0.8955\n",
            "Epoch 1019/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1947 - acc: 0.9249 - val_loss: 0.3552 - val_acc: 0.8870\n",
            "Epoch 1020/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1936 - acc: 0.9254 - val_loss: 0.2846 - val_acc: 0.8989\n",
            "Epoch 1021/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1941 - acc: 0.9248 - val_loss: 0.3503 - val_acc: 0.8880\n",
            "Epoch 1022/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1948 - acc: 0.9250 - val_loss: 0.3679 - val_acc: 0.8844\n",
            "Epoch 1023/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1940 - acc: 0.9249 - val_loss: 0.3350 - val_acc: 0.8918\n",
            "Epoch 1024/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1941 - acc: 0.9249 - val_loss: 0.3299 - val_acc: 0.8902\n",
            "Epoch 1025/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1946 - acc: 0.9250 - val_loss: 0.3235 - val_acc: 0.8942\n",
            "Epoch 1026/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1947 - acc: 0.9248 - val_loss: 0.3113 - val_acc: 0.8944\n",
            "Epoch 1027/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1943 - acc: 0.9250 - val_loss: 0.3307 - val_acc: 0.8917\n",
            "Epoch 1028/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1942 - acc: 0.9249 - val_loss: 0.3025 - val_acc: 0.8985\n",
            "Epoch 1029/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1940 - acc: 0.9250 - val_loss: 0.2871 - val_acc: 0.9022\n",
            "Epoch 1030/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1946 - acc: 0.9248 - val_loss: 0.3433 - val_acc: 0.8883\n",
            "Epoch 1031/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1937 - acc: 0.9251 - val_loss: 0.3413 - val_acc: 0.8913\n",
            "Epoch 1032/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1940 - acc: 0.9250 - val_loss: 0.3029 - val_acc: 0.8961\n",
            "Epoch 1033/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1941 - acc: 0.9248 - val_loss: 0.2797 - val_acc: 0.8998\n",
            "Epoch 1034/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1946 - acc: 0.9247 - val_loss: 0.3047 - val_acc: 0.8977\n",
            "Epoch 1035/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1940 - acc: 0.9248 - val_loss: 0.3377 - val_acc: 0.8901\n",
            "Epoch 1036/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1935 - acc: 0.9253 - val_loss: 0.3005 - val_acc: 0.8968\n",
            "Epoch 1037/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1949 - acc: 0.9248 - val_loss: 0.3922 - val_acc: 0.8808\n",
            "Epoch 1038/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1937 - acc: 0.9254 - val_loss: 0.3366 - val_acc: 0.8923\n",
            "Epoch 1039/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1941 - acc: 0.9252 - val_loss: 0.3938 - val_acc: 0.8779\n",
            "Epoch 1040/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1945 - acc: 0.9251 - val_loss: 0.3648 - val_acc: 0.8865\n",
            "Epoch 1041/6000\n",
            "584288/584288 [==============================] - 20s 34us/step - loss: 0.1944 - acc: 0.9251 - val_loss: 0.3275 - val_acc: 0.8929\n",
            "Epoch 1042/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1939 - acc: 0.9249 - val_loss: 0.3885 - val_acc: 0.8844\n",
            "Epoch 1043/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1936 - acc: 0.9250 - val_loss: 0.2876 - val_acc: 0.8987\n",
            "Epoch 1044/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1940 - acc: 0.9249 - val_loss: 0.3120 - val_acc: 0.8925\n",
            "Epoch 1045/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1945 - acc: 0.9250 - val_loss: 0.3175 - val_acc: 0.8935\n",
            "Epoch 1046/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1949 - acc: 0.9248 - val_loss: 0.2963 - val_acc: 0.8925\n",
            "Epoch 1047/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1939 - acc: 0.9253 - val_loss: 0.3608 - val_acc: 0.8865\n",
            "Epoch 1048/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1945 - acc: 0.9249 - val_loss: 0.2947 - val_acc: 0.8982\n",
            "Epoch 1049/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1942 - acc: 0.9249 - val_loss: 0.3221 - val_acc: 0.8945\n",
            "Epoch 1050/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1940 - acc: 0.9251 - val_loss: 0.3026 - val_acc: 0.8971\n",
            "Epoch 1051/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1942 - acc: 0.9250 - val_loss: 0.3017 - val_acc: 0.8972\n",
            "Epoch 1052/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1941 - acc: 0.9248 - val_loss: 0.2902 - val_acc: 0.8997\n",
            "Epoch 1053/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1939 - acc: 0.9252 - val_loss: 0.2897 - val_acc: 0.9002\n",
            "Epoch 1054/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1943 - acc: 0.9249 - val_loss: 0.3451 - val_acc: 0.8906\n",
            "Epoch 1055/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1947 - acc: 0.9247 - val_loss: 0.3322 - val_acc: 0.8924\n",
            "Epoch 1056/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1936 - acc: 0.9252 - val_loss: 0.2938 - val_acc: 0.8984\n",
            "Epoch 1057/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1944 - acc: 0.9246 - val_loss: 0.3420 - val_acc: 0.8929\n",
            "Epoch 1058/6000\n",
            "584288/584288 [==============================] - 20s 34us/step - loss: 0.1949 - acc: 0.9248 - val_loss: 0.3441 - val_acc: 0.8866\n",
            "Epoch 1059/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1931 - acc: 0.9253 - val_loss: 0.3216 - val_acc: 0.8947\n",
            "Epoch 1060/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1943 - acc: 0.9249 - val_loss: 0.3487 - val_acc: 0.8896\n",
            "Epoch 1061/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1941 - acc: 0.9253 - val_loss: 0.3015 - val_acc: 0.8945\n",
            "Epoch 1062/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1936 - acc: 0.9252 - val_loss: 0.3528 - val_acc: 0.8906\n",
            "Epoch 1063/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1939 - acc: 0.9252 - val_loss: 0.3456 - val_acc: 0.8910\n",
            "Epoch 1064/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1939 - acc: 0.9250 - val_loss: 0.3057 - val_acc: 0.8938\n",
            "Epoch 1065/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1938 - acc: 0.9251 - val_loss: 0.3556 - val_acc: 0.8894\n",
            "Epoch 1066/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1937 - acc: 0.9248 - val_loss: 0.3572 - val_acc: 0.8877\n",
            "Epoch 1067/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1937 - acc: 0.9248 - val_loss: 0.3379 - val_acc: 0.8916\n",
            "Epoch 1068/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1940 - acc: 0.9251 - val_loss: 0.3499 - val_acc: 0.8871\n",
            "Epoch 1069/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1936 - acc: 0.9254 - val_loss: 0.3938 - val_acc: 0.8829\n",
            "Epoch 1070/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1938 - acc: 0.9251 - val_loss: 0.2869 - val_acc: 0.9001\n",
            "Epoch 1071/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1936 - acc: 0.9252 - val_loss: 0.3306 - val_acc: 0.8909\n",
            "Epoch 1072/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1944 - acc: 0.9246 - val_loss: 0.3583 - val_acc: 0.8839\n",
            "Epoch 1073/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1937 - acc: 0.9253 - val_loss: 0.3133 - val_acc: 0.8960\n",
            "Epoch 1074/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1938 - acc: 0.9250 - val_loss: 0.3414 - val_acc: 0.8855\n",
            "Epoch 1075/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1949 - acc: 0.9245 - val_loss: 0.3957 - val_acc: 0.8813\n",
            "Epoch 1076/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1939 - acc: 0.9251 - val_loss: 0.3899 - val_acc: 0.8830\n",
            "Epoch 1077/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1938 - acc: 0.9249 - val_loss: 0.3407 - val_acc: 0.8895\n",
            "Epoch 1078/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1942 - acc: 0.9248 - val_loss: 0.3319 - val_acc: 0.8894\n",
            "Epoch 1079/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1937 - acc: 0.9252 - val_loss: 0.3398 - val_acc: 0.8849\n",
            "Epoch 1080/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1936 - acc: 0.9250 - val_loss: 0.3169 - val_acc: 0.8937\n",
            "Epoch 1081/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1939 - acc: 0.9250 - val_loss: 0.3312 - val_acc: 0.8898\n",
            "Epoch 1082/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1946 - acc: 0.9247 - val_loss: 0.3169 - val_acc: 0.8948\n",
            "Epoch 1083/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1945 - acc: 0.9248 - val_loss: 0.3227 - val_acc: 0.8936\n",
            "Epoch 1084/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1939 - acc: 0.9251 - val_loss: 0.3301 - val_acc: 0.8922\n",
            "Epoch 1085/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1943 - acc: 0.9250 - val_loss: 0.3744 - val_acc: 0.8831\n",
            "Epoch 1086/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1937 - acc: 0.9249 - val_loss: 0.3199 - val_acc: 0.8948\n",
            "Epoch 1087/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1935 - acc: 0.9253 - val_loss: 0.3361 - val_acc: 0.8906\n",
            "Epoch 1088/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1944 - acc: 0.9248 - val_loss: 0.3368 - val_acc: 0.8887\n",
            "Epoch 1089/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1936 - acc: 0.9251 - val_loss: 0.3579 - val_acc: 0.8862\n",
            "Epoch 1090/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1938 - acc: 0.9251 - val_loss: 0.3796 - val_acc: 0.8811\n",
            "Epoch 1091/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1935 - acc: 0.9249 - val_loss: 0.3022 - val_acc: 0.8951\n",
            "Epoch 1092/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1938 - acc: 0.9252 - val_loss: 0.2898 - val_acc: 0.8990\n",
            "Epoch 1093/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1937 - acc: 0.9255 - val_loss: 0.3007 - val_acc: 0.8956\n",
            "Epoch 1094/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1933 - acc: 0.9253 - val_loss: 0.3052 - val_acc: 0.8960\n",
            "Epoch 1095/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1942 - acc: 0.9252 - val_loss: 0.3011 - val_acc: 0.8945\n",
            "Epoch 1096/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1940 - acc: 0.9247 - val_loss: 0.3226 - val_acc: 0.8924\n",
            "Epoch 1097/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1932 - acc: 0.9253 - val_loss: 0.3125 - val_acc: 0.8937\n",
            "Epoch 1098/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1934 - acc: 0.9253 - val_loss: 0.3327 - val_acc: 0.8939\n",
            "Epoch 1099/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1939 - acc: 0.9251 - val_loss: 0.3684 - val_acc: 0.8839\n",
            "Epoch 1100/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1935 - acc: 0.9250 - val_loss: 0.3128 - val_acc: 0.8940\n",
            "Epoch 1101/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1944 - acc: 0.9251 - val_loss: 0.3198 - val_acc: 0.8918\n",
            "Epoch 1102/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1938 - acc: 0.9252 - val_loss: 0.3162 - val_acc: 0.8928\n",
            "Epoch 1103/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1942 - acc: 0.9250 - val_loss: 0.3304 - val_acc: 0.8908\n",
            "Epoch 1104/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1940 - acc: 0.9250 - val_loss: 0.3258 - val_acc: 0.8925\n",
            "Epoch 1105/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1934 - acc: 0.9249 - val_loss: 0.3722 - val_acc: 0.8834\n",
            "Epoch 1106/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1935 - acc: 0.9252 - val_loss: 0.3293 - val_acc: 0.8928\n",
            "Epoch 1107/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1938 - acc: 0.9256 - val_loss: 0.3009 - val_acc: 0.8966\n",
            "Epoch 1108/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1945 - acc: 0.9247 - val_loss: 0.3111 - val_acc: 0.8954\n",
            "Epoch 1109/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1937 - acc: 0.9252 - val_loss: 0.3189 - val_acc: 0.8934\n",
            "Epoch 1110/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1941 - acc: 0.9250 - val_loss: 0.2965 - val_acc: 0.8979\n",
            "Epoch 1111/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1941 - acc: 0.9249 - val_loss: 0.2853 - val_acc: 0.8998\n",
            "Epoch 1112/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1935 - acc: 0.9253 - val_loss: 0.3474 - val_acc: 0.8893\n",
            "Epoch 1113/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1938 - acc: 0.9251 - val_loss: 0.3281 - val_acc: 0.8928\n",
            "Epoch 1114/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1935 - acc: 0.9253 - val_loss: 0.3254 - val_acc: 0.8924\n",
            "Epoch 1115/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1940 - acc: 0.9247 - val_loss: 0.3733 - val_acc: 0.8890\n",
            "Epoch 1116/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1937 - acc: 0.9250 - val_loss: 0.3800 - val_acc: 0.8851\n",
            "Epoch 1117/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1932 - acc: 0.9252 - val_loss: 0.4025 - val_acc: 0.8785\n",
            "Epoch 1118/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1933 - acc: 0.9253 - val_loss: 0.3074 - val_acc: 0.8951\n",
            "Epoch 1119/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1933 - acc: 0.9252 - val_loss: 0.3471 - val_acc: 0.8911\n",
            "Epoch 1120/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1942 - acc: 0.9249 - val_loss: 0.3451 - val_acc: 0.8858\n",
            "Epoch 1121/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1923 - acc: 0.9257 - val_loss: 0.3162 - val_acc: 0.8925\n",
            "Epoch 1122/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1937 - acc: 0.9252 - val_loss: 0.3209 - val_acc: 0.8921\n",
            "Epoch 1123/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1934 - acc: 0.9249 - val_loss: 0.3074 - val_acc: 0.8968\n",
            "Epoch 1124/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1937 - acc: 0.9252 - val_loss: 0.2904 - val_acc: 0.9005\n",
            "Epoch 1125/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1935 - acc: 0.9254 - val_loss: 0.2918 - val_acc: 0.8967\n",
            "Epoch 1126/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1935 - acc: 0.9251 - val_loss: 0.3289 - val_acc: 0.8916\n",
            "Epoch 1127/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1936 - acc: 0.9252 - val_loss: 0.2892 - val_acc: 0.8992\n",
            "Epoch 1128/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1940 - acc: 0.9250 - val_loss: 0.3109 - val_acc: 0.8949\n",
            "Epoch 1129/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1939 - acc: 0.9250 - val_loss: 0.3160 - val_acc: 0.8916\n",
            "Epoch 1130/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1933 - acc: 0.9251 - val_loss: 0.3296 - val_acc: 0.8916\n",
            "Epoch 1131/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1931 - acc: 0.9254 - val_loss: 0.3012 - val_acc: 0.8958\n",
            "Epoch 1132/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1933 - acc: 0.9254 - val_loss: 0.3040 - val_acc: 0.8943\n",
            "Epoch 1133/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1934 - acc: 0.9255 - val_loss: 0.2972 - val_acc: 0.8970\n",
            "Epoch 1134/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1931 - acc: 0.9253 - val_loss: 0.3592 - val_acc: 0.8883\n",
            "Epoch 1135/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1931 - acc: 0.9252 - val_loss: 0.3122 - val_acc: 0.8949\n",
            "Epoch 1136/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1933 - acc: 0.9256 - val_loss: 0.3060 - val_acc: 0.8941\n",
            "Epoch 1137/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1934 - acc: 0.9253 - val_loss: 0.3608 - val_acc: 0.8861\n",
            "Epoch 1138/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1931 - acc: 0.9255 - val_loss: 0.3225 - val_acc: 0.8911\n",
            "Epoch 1139/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1931 - acc: 0.9254 - val_loss: 0.2998 - val_acc: 0.8930\n",
            "Epoch 1140/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1933 - acc: 0.9252 - val_loss: 0.3036 - val_acc: 0.8958\n",
            "Epoch 1141/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1933 - acc: 0.9254 - val_loss: 0.3170 - val_acc: 0.8927\n",
            "Epoch 1142/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1932 - acc: 0.9253 - val_loss: 0.3123 - val_acc: 0.8936\n",
            "Epoch 1143/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1928 - acc: 0.9255 - val_loss: 0.3138 - val_acc: 0.8957\n",
            "Epoch 1144/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1940 - acc: 0.9253 - val_loss: 0.3160 - val_acc: 0.8933\n",
            "Epoch 1145/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1934 - acc: 0.9251 - val_loss: 0.3090 - val_acc: 0.8959\n",
            "Epoch 1146/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1926 - acc: 0.9258 - val_loss: 0.4016 - val_acc: 0.8812\n",
            "Epoch 1147/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1938 - acc: 0.9251 - val_loss: 0.3488 - val_acc: 0.8899\n",
            "Epoch 1148/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1936 - acc: 0.9251 - val_loss: 0.3154 - val_acc: 0.8932\n",
            "Epoch 1149/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1935 - acc: 0.9256 - val_loss: 0.3419 - val_acc: 0.8913\n",
            "Epoch 1150/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1932 - acc: 0.9252 - val_loss: 0.3521 - val_acc: 0.8883\n",
            "Epoch 1151/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1942 - acc: 0.9248 - val_loss: 0.3378 - val_acc: 0.8921\n",
            "Epoch 1152/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1937 - acc: 0.9251 - val_loss: 0.3673 - val_acc: 0.8865\n",
            "Epoch 1153/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1935 - acc: 0.9251 - val_loss: 0.3057 - val_acc: 0.8971\n",
            "Epoch 1154/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1945 - acc: 0.9248 - val_loss: 0.3223 - val_acc: 0.8957\n",
            "Epoch 1155/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1934 - acc: 0.9252 - val_loss: 0.3383 - val_acc: 0.8904\n",
            "Epoch 1156/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1932 - acc: 0.9255 - val_loss: 0.3780 - val_acc: 0.8836\n",
            "Epoch 1157/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1932 - acc: 0.9254 - val_loss: 0.3392 - val_acc: 0.8890\n",
            "Epoch 1158/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1936 - acc: 0.9251 - val_loss: 0.3816 - val_acc: 0.8850\n",
            "Epoch 1159/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1930 - acc: 0.9254 - val_loss: 0.3021 - val_acc: 0.8961\n",
            "Epoch 1160/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1934 - acc: 0.9254 - val_loss: 0.3304 - val_acc: 0.8926\n",
            "Epoch 1161/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1933 - acc: 0.9251 - val_loss: 0.3518 - val_acc: 0.8876\n",
            "Epoch 1162/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1936 - acc: 0.9251 - val_loss: 0.3122 - val_acc: 0.8955\n",
            "Epoch 1163/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1934 - acc: 0.9251 - val_loss: 0.3760 - val_acc: 0.8871\n",
            "Epoch 1164/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1932 - acc: 0.9256 - val_loss: 0.3767 - val_acc: 0.8853\n",
            "Epoch 1165/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1936 - acc: 0.9252 - val_loss: 0.3472 - val_acc: 0.8916\n",
            "Epoch 1166/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1938 - acc: 0.9250 - val_loss: 0.3273 - val_acc: 0.8928\n",
            "Epoch 1167/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1924 - acc: 0.9258 - val_loss: 0.3692 - val_acc: 0.8862\n",
            "Epoch 1168/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1934 - acc: 0.9250 - val_loss: 0.2898 - val_acc: 0.8979\n",
            "Epoch 1169/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1929 - acc: 0.9255 - val_loss: 0.3203 - val_acc: 0.8910\n",
            "Epoch 1170/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1931 - acc: 0.9254 - val_loss: 0.3378 - val_acc: 0.8913\n",
            "Epoch 1171/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1930 - acc: 0.9252 - val_loss: 0.3307 - val_acc: 0.8910\n",
            "Epoch 1172/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1942 - acc: 0.9253 - val_loss: 0.3189 - val_acc: 0.8942\n",
            "Epoch 1173/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1925 - acc: 0.9258 - val_loss: 0.3826 - val_acc: 0.8827\n",
            "Epoch 1174/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1933 - acc: 0.9254 - val_loss: 0.3052 - val_acc: 0.9001\n",
            "Epoch 1175/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1930 - acc: 0.9252 - val_loss: 0.3101 - val_acc: 0.8945\n",
            "Epoch 1176/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1931 - acc: 0.9254 - val_loss: 0.3177 - val_acc: 0.8925\n",
            "Epoch 1177/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1935 - acc: 0.9250 - val_loss: 0.3187 - val_acc: 0.8953\n",
            "Epoch 1178/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1926 - acc: 0.9259 - val_loss: 0.3804 - val_acc: 0.8868\n",
            "Epoch 1179/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1928 - acc: 0.9254 - val_loss: 0.3504 - val_acc: 0.8881\n",
            "Epoch 1180/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1935 - acc: 0.9255 - val_loss: 0.3478 - val_acc: 0.8889\n",
            "Epoch 1181/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1930 - acc: 0.9254 - val_loss: 0.3230 - val_acc: 0.8943\n",
            "Epoch 1182/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1930 - acc: 0.9255 - val_loss: 0.3518 - val_acc: 0.8840\n",
            "Epoch 1183/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1924 - acc: 0.9259 - val_loss: 0.3437 - val_acc: 0.8910\n",
            "Epoch 1184/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1930 - acc: 0.9251 - val_loss: 0.2832 - val_acc: 0.8997\n",
            "Epoch 1185/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1930 - acc: 0.9253 - val_loss: 0.3323 - val_acc: 0.8919\n",
            "Epoch 1186/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1939 - acc: 0.9249 - val_loss: 0.3141 - val_acc: 0.8942\n",
            "Epoch 1187/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1933 - acc: 0.9256 - val_loss: 0.3235 - val_acc: 0.8942\n",
            "Epoch 1188/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1937 - acc: 0.9253 - val_loss: 0.3857 - val_acc: 0.8830\n",
            "Epoch 1189/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1931 - acc: 0.9254 - val_loss: 0.3637 - val_acc: 0.8877\n",
            "Epoch 1190/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1931 - acc: 0.9254 - val_loss: 0.3078 - val_acc: 0.8929\n",
            "Epoch 1191/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1931 - acc: 0.9255 - val_loss: 0.3615 - val_acc: 0.8873\n",
            "Epoch 1192/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1932 - acc: 0.9254 - val_loss: 0.3167 - val_acc: 0.8934\n",
            "Epoch 1193/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1935 - acc: 0.9253 - val_loss: 0.3009 - val_acc: 0.8979\n",
            "Epoch 1194/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1931 - acc: 0.9259 - val_loss: 0.3064 - val_acc: 0.8973\n",
            "Epoch 1195/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1936 - acc: 0.9253 - val_loss: 0.3570 - val_acc: 0.8871\n",
            "Epoch 1196/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1931 - acc: 0.9253 - val_loss: 0.2918 - val_acc: 0.8997\n",
            "Epoch 1197/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1931 - acc: 0.9251 - val_loss: 0.3066 - val_acc: 0.8952\n",
            "Epoch 1198/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1935 - acc: 0.9253 - val_loss: 0.2973 - val_acc: 0.8960\n",
            "Epoch 1199/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1926 - acc: 0.9258 - val_loss: 0.3124 - val_acc: 0.8923\n",
            "Epoch 1200/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1929 - acc: 0.9256 - val_loss: 0.3001 - val_acc: 0.8947\n",
            "Epoch 1201/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1930 - acc: 0.9255 - val_loss: 0.3302 - val_acc: 0.8915\n",
            "Epoch 1202/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1925 - acc: 0.9255 - val_loss: 0.3476 - val_acc: 0.8890\n",
            "Epoch 1203/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1928 - acc: 0.9255 - val_loss: 0.3844 - val_acc: 0.8828\n",
            "Epoch 1204/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1936 - acc: 0.9251 - val_loss: 0.3901 - val_acc: 0.8812\n",
            "Epoch 1205/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1930 - acc: 0.9253 - val_loss: 0.3445 - val_acc: 0.8894\n",
            "Epoch 1206/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1926 - acc: 0.9256 - val_loss: 0.3034 - val_acc: 0.8966\n",
            "Epoch 1207/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1934 - acc: 0.9252 - val_loss: 0.2888 - val_acc: 0.9021\n",
            "Epoch 1208/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1932 - acc: 0.9255 - val_loss: 0.3446 - val_acc: 0.8899\n",
            "Epoch 1209/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1923 - acc: 0.9257 - val_loss: 0.3328 - val_acc: 0.8928\n",
            "Epoch 1210/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1929 - acc: 0.9256 - val_loss: 0.3288 - val_acc: 0.8886\n",
            "Epoch 1211/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1940 - acc: 0.9249 - val_loss: 0.3226 - val_acc: 0.8919\n",
            "Epoch 1212/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1932 - acc: 0.9257 - val_loss: 0.3293 - val_acc: 0.8925\n",
            "Epoch 1213/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1933 - acc: 0.9253 - val_loss: 0.3223 - val_acc: 0.8937\n",
            "Epoch 1214/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1931 - acc: 0.9252 - val_loss: 0.3139 - val_acc: 0.8951\n",
            "Epoch 1215/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1932 - acc: 0.9253 - val_loss: 0.3232 - val_acc: 0.8950\n",
            "Epoch 1216/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1932 - acc: 0.9254 - val_loss: 0.2894 - val_acc: 0.9007\n",
            "Epoch 1217/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1927 - acc: 0.9254 - val_loss: 0.3275 - val_acc: 0.8917\n",
            "Epoch 1218/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1934 - acc: 0.9253 - val_loss: 0.3467 - val_acc: 0.8876\n",
            "Epoch 1219/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1937 - acc: 0.9254 - val_loss: 0.3370 - val_acc: 0.8918\n",
            "Epoch 1220/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1932 - acc: 0.9255 - val_loss: 0.3701 - val_acc: 0.8838\n",
            "Epoch 1221/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1941 - acc: 0.9251 - val_loss: 0.3270 - val_acc: 0.8926\n",
            "Epoch 1222/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1925 - acc: 0.9258 - val_loss: 0.3226 - val_acc: 0.8928\n",
            "Epoch 1223/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1934 - acc: 0.9250 - val_loss: 0.3466 - val_acc: 0.8898\n",
            "Epoch 1224/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1925 - acc: 0.9254 - val_loss: 0.2904 - val_acc: 0.8944\n",
            "Epoch 1225/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1932 - acc: 0.9253 - val_loss: 0.3637 - val_acc: 0.8866\n",
            "Epoch 1226/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1935 - acc: 0.9256 - val_loss: 0.3220 - val_acc: 0.8956\n",
            "Epoch 1227/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1931 - acc: 0.9255 - val_loss: 0.3258 - val_acc: 0.8924\n",
            "Epoch 1228/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1927 - acc: 0.9257 - val_loss: 0.3016 - val_acc: 0.8951\n",
            "Epoch 1229/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1929 - acc: 0.9254 - val_loss: 0.3192 - val_acc: 0.8941\n",
            "Epoch 1230/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1930 - acc: 0.9252 - val_loss: 0.3121 - val_acc: 0.8958\n",
            "Epoch 1231/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1940 - acc: 0.9249 - val_loss: 0.3469 - val_acc: 0.8906\n",
            "Epoch 1232/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1930 - acc: 0.9254 - val_loss: 0.3103 - val_acc: 0.8944\n",
            "Epoch 1233/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1927 - acc: 0.9257 - val_loss: 0.3374 - val_acc: 0.8935\n",
            "Epoch 1234/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1937 - acc: 0.9253 - val_loss: 0.2911 - val_acc: 0.8993\n",
            "Epoch 1235/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1923 - acc: 0.9255 - val_loss: 0.3408 - val_acc: 0.8905\n",
            "Epoch 1236/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1932 - acc: 0.9252 - val_loss: 0.4071 - val_acc: 0.8798\n",
            "Epoch 1237/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1928 - acc: 0.9252 - val_loss: 0.2877 - val_acc: 0.8958\n",
            "Epoch 1238/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1931 - acc: 0.9252 - val_loss: 0.2784 - val_acc: 0.9004\n",
            "Epoch 1239/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1937 - acc: 0.9253 - val_loss: 0.3965 - val_acc: 0.8818\n",
            "Epoch 1240/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1933 - acc: 0.9253 - val_loss: 0.3161 - val_acc: 0.8934\n",
            "Epoch 1241/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1928 - acc: 0.9254 - val_loss: 0.2645 - val_acc: 0.9044\n",
            "Epoch 1242/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1925 - acc: 0.9258 - val_loss: 0.3091 - val_acc: 0.8924\n",
            "Epoch 1243/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1931 - acc: 0.9252 - val_loss: 0.3829 - val_acc: 0.8851\n",
            "Epoch 1244/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1932 - acc: 0.9255 - val_loss: 0.3409 - val_acc: 0.8892\n",
            "Epoch 1245/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1922 - acc: 0.9256 - val_loss: 0.3234 - val_acc: 0.8911\n",
            "Epoch 1246/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1929 - acc: 0.9257 - val_loss: 0.3573 - val_acc: 0.8856\n",
            "Epoch 1247/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1929 - acc: 0.9256 - val_loss: 0.2937 - val_acc: 0.8951\n",
            "Epoch 1248/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1928 - acc: 0.9256 - val_loss: 0.3551 - val_acc: 0.8876\n",
            "Epoch 1249/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1927 - acc: 0.9256 - val_loss: 0.3517 - val_acc: 0.8910\n",
            "Epoch 1250/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1928 - acc: 0.9256 - val_loss: 0.3309 - val_acc: 0.8930\n",
            "Epoch 1251/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1930 - acc: 0.9254 - val_loss: 0.2986 - val_acc: 0.8950\n",
            "Epoch 1252/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1923 - acc: 0.9257 - val_loss: 0.3620 - val_acc: 0.8887\n",
            "Epoch 1253/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1929 - acc: 0.9251 - val_loss: 0.3411 - val_acc: 0.8911\n",
            "Epoch 1254/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1924 - acc: 0.9255 - val_loss: 0.3035 - val_acc: 0.8987\n",
            "Epoch 1255/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1924 - acc: 0.9259 - val_loss: 0.3299 - val_acc: 0.8878\n",
            "Epoch 1256/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1930 - acc: 0.9253 - val_loss: 0.2831 - val_acc: 0.8969\n",
            "Epoch 1257/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1929 - acc: 0.9254 - val_loss: 0.3453 - val_acc: 0.8880\n",
            "Epoch 1258/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1925 - acc: 0.9258 - val_loss: 0.2959 - val_acc: 0.8962\n",
            "Epoch 1259/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1926 - acc: 0.9255 - val_loss: 0.3324 - val_acc: 0.8915\n",
            "Epoch 1260/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1933 - acc: 0.9254 - val_loss: 0.3191 - val_acc: 0.8954\n",
            "Epoch 1261/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1932 - acc: 0.9253 - val_loss: 0.3330 - val_acc: 0.8914\n",
            "Epoch 1262/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1920 - acc: 0.9259 - val_loss: 0.3253 - val_acc: 0.8938\n",
            "Epoch 1263/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1925 - acc: 0.9257 - val_loss: 0.3144 - val_acc: 0.8954\n",
            "Epoch 1264/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1928 - acc: 0.9260 - val_loss: 0.3203 - val_acc: 0.8934\n",
            "Epoch 1265/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1922 - acc: 0.9259 - val_loss: 0.3164 - val_acc: 0.8953\n",
            "Epoch 1266/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1929 - acc: 0.9256 - val_loss: 0.2978 - val_acc: 0.8963\n",
            "Epoch 1267/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1919 - acc: 0.9258 - val_loss: 0.3836 - val_acc: 0.8835\n",
            "Epoch 1268/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1926 - acc: 0.9259 - val_loss: 0.3127 - val_acc: 0.8919\n",
            "Epoch 1269/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1925 - acc: 0.9255 - val_loss: 0.3353 - val_acc: 0.8893\n",
            "Epoch 1270/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1929 - acc: 0.9254 - val_loss: 0.3119 - val_acc: 0.8950\n",
            "Epoch 1271/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1924 - acc: 0.9259 - val_loss: 0.3312 - val_acc: 0.8939\n",
            "Epoch 1272/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1929 - acc: 0.9255 - val_loss: 0.3099 - val_acc: 0.8938\n",
            "Epoch 1273/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1931 - acc: 0.9253 - val_loss: 0.3390 - val_acc: 0.8914\n",
            "Epoch 1274/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1925 - acc: 0.9255 - val_loss: 0.3047 - val_acc: 0.8970\n",
            "Epoch 1275/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1926 - acc: 0.9258 - val_loss: 0.2867 - val_acc: 0.8957\n",
            "Epoch 1276/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1925 - acc: 0.9255 - val_loss: 0.3079 - val_acc: 0.8958\n",
            "Epoch 1277/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1930 - acc: 0.9253 - val_loss: 0.3077 - val_acc: 0.8976\n",
            "Epoch 1278/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1924 - acc: 0.9256 - val_loss: 0.3309 - val_acc: 0.8901\n",
            "Epoch 1279/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1927 - acc: 0.9256 - val_loss: 0.3973 - val_acc: 0.8814\n",
            "Epoch 1280/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1930 - acc: 0.9254 - val_loss: 0.3002 - val_acc: 0.8993\n",
            "Epoch 1281/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1923 - acc: 0.9259 - val_loss: 0.3041 - val_acc: 0.8953\n",
            "Epoch 1282/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1927 - acc: 0.9258 - val_loss: 0.3468 - val_acc: 0.8880\n",
            "Epoch 1283/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1923 - acc: 0.9257 - val_loss: 0.3674 - val_acc: 0.8874\n",
            "Epoch 1284/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1928 - acc: 0.9256 - val_loss: 0.3607 - val_acc: 0.8907\n",
            "Epoch 1285/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1918 - acc: 0.9261 - val_loss: 0.3062 - val_acc: 0.8968\n",
            "Epoch 1286/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1932 - acc: 0.9253 - val_loss: 0.3337 - val_acc: 0.8946\n",
            "Epoch 1287/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1923 - acc: 0.9258 - val_loss: 0.3357 - val_acc: 0.8908\n",
            "Epoch 1288/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1925 - acc: 0.9256 - val_loss: 0.3484 - val_acc: 0.8913\n",
            "Epoch 1289/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1930 - acc: 0.9253 - val_loss: 0.3713 - val_acc: 0.8889\n",
            "Epoch 1290/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1923 - acc: 0.9256 - val_loss: 0.3491 - val_acc: 0.8913\n",
            "Epoch 1291/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1923 - acc: 0.9261 - val_loss: 0.3324 - val_acc: 0.8921\n",
            "Epoch 1292/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1930 - acc: 0.9255 - val_loss: 0.3455 - val_acc: 0.8891\n",
            "Epoch 1293/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1927 - acc: 0.9254 - val_loss: 0.3833 - val_acc: 0.8834\n",
            "Epoch 1294/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1920 - acc: 0.9260 - val_loss: 0.3444 - val_acc: 0.8901\n",
            "Epoch 1295/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1929 - acc: 0.9254 - val_loss: 0.3808 - val_acc: 0.8828\n",
            "Epoch 1296/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1935 - acc: 0.9253 - val_loss: 0.3621 - val_acc: 0.8849\n",
            "Epoch 1297/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1926 - acc: 0.9252 - val_loss: 0.3326 - val_acc: 0.8905\n",
            "Epoch 1298/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1936 - acc: 0.9253 - val_loss: 0.3225 - val_acc: 0.8942\n",
            "Epoch 1299/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1930 - acc: 0.9257 - val_loss: 0.3235 - val_acc: 0.8909\n",
            "Epoch 1300/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1925 - acc: 0.9258 - val_loss: 0.3487 - val_acc: 0.8861\n",
            "Epoch 1301/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1928 - acc: 0.9254 - val_loss: 0.3590 - val_acc: 0.8882\n",
            "Epoch 1302/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1922 - acc: 0.9257 - val_loss: 0.3000 - val_acc: 0.8933\n",
            "Epoch 1303/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1922 - acc: 0.9259 - val_loss: 0.3382 - val_acc: 0.8912\n",
            "Epoch 1304/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1931 - acc: 0.9252 - val_loss: 0.3150 - val_acc: 0.8955\n",
            "Epoch 1305/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1924 - acc: 0.9258 - val_loss: 0.3568 - val_acc: 0.8901\n",
            "Epoch 1306/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1923 - acc: 0.9258 - val_loss: 0.3138 - val_acc: 0.8930\n",
            "Epoch 1307/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1930 - acc: 0.9252 - val_loss: 0.3498 - val_acc: 0.8886\n",
            "Epoch 1308/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1924 - acc: 0.9255 - val_loss: 0.3332 - val_acc: 0.8925\n",
            "Epoch 1309/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1922 - acc: 0.9257 - val_loss: 0.3454 - val_acc: 0.8899\n",
            "Epoch 1310/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1932 - acc: 0.9251 - val_loss: 0.3145 - val_acc: 0.8951\n",
            "Epoch 1311/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1924 - acc: 0.9255 - val_loss: 0.3298 - val_acc: 0.8927\n",
            "Epoch 1312/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1934 - acc: 0.9253 - val_loss: 0.3600 - val_acc: 0.8892\n",
            "Epoch 1313/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1927 - acc: 0.9257 - val_loss: 0.3121 - val_acc: 0.8951\n",
            "Epoch 1314/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1922 - acc: 0.9258 - val_loss: 0.3426 - val_acc: 0.8889\n",
            "Epoch 1315/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1923 - acc: 0.9259 - val_loss: 0.3075 - val_acc: 0.8947\n",
            "Epoch 1316/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1933 - acc: 0.9255 - val_loss: 0.2772 - val_acc: 0.9038\n",
            "Epoch 1317/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1922 - acc: 0.9258 - val_loss: 0.3430 - val_acc: 0.8924\n",
            "Epoch 1318/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1928 - acc: 0.9254 - val_loss: 0.2963 - val_acc: 0.8979\n",
            "Epoch 1319/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1923 - acc: 0.9259 - val_loss: 0.3539 - val_acc: 0.8902\n",
            "Epoch 1320/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1924 - acc: 0.9257 - val_loss: 0.3326 - val_acc: 0.8936\n",
            "Epoch 1321/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1929 - acc: 0.9254 - val_loss: 0.3592 - val_acc: 0.8877\n",
            "Epoch 1322/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1926 - acc: 0.9258 - val_loss: 0.3088 - val_acc: 0.8959\n",
            "Epoch 1323/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1925 - acc: 0.9255 - val_loss: 0.3509 - val_acc: 0.8891\n",
            "Epoch 1324/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1923 - acc: 0.9256 - val_loss: 0.3447 - val_acc: 0.8880\n",
            "Epoch 1325/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1922 - acc: 0.9258 - val_loss: 0.2968 - val_acc: 0.8967\n",
            "Epoch 1326/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1929 - acc: 0.9255 - val_loss: 0.3570 - val_acc: 0.8874\n",
            "Epoch 1327/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1925 - acc: 0.9256 - val_loss: 0.3507 - val_acc: 0.8893\n",
            "Epoch 1328/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1931 - acc: 0.9254 - val_loss: 0.3483 - val_acc: 0.8900\n",
            "Epoch 1329/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1932 - acc: 0.9253 - val_loss: 0.3130 - val_acc: 0.8970\n",
            "Epoch 1330/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1929 - acc: 0.9252 - val_loss: 0.3518 - val_acc: 0.8900\n",
            "Epoch 1331/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1925 - acc: 0.9257 - val_loss: 0.3374 - val_acc: 0.8920\n",
            "Epoch 1332/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1924 - acc: 0.9256 - val_loss: 0.3637 - val_acc: 0.8863\n",
            "Epoch 1333/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1924 - acc: 0.9257 - val_loss: 0.3352 - val_acc: 0.8915\n",
            "Epoch 1334/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1919 - acc: 0.9259 - val_loss: 0.3077 - val_acc: 0.8966\n",
            "Epoch 1335/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1923 - acc: 0.9256 - val_loss: 0.3437 - val_acc: 0.8899\n",
            "Epoch 1336/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1929 - acc: 0.9253 - val_loss: 0.3200 - val_acc: 0.8935\n",
            "Epoch 1337/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1922 - acc: 0.9255 - val_loss: 0.3074 - val_acc: 0.8963\n",
            "Epoch 1338/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1925 - acc: 0.9254 - val_loss: 0.3324 - val_acc: 0.8924\n",
            "Epoch 1339/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1926 - acc: 0.9258 - val_loss: 0.2840 - val_acc: 0.9008\n",
            "Epoch 1340/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1922 - acc: 0.9256 - val_loss: 0.3940 - val_acc: 0.8834\n",
            "Epoch 1341/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1923 - acc: 0.9256 - val_loss: 0.2833 - val_acc: 0.8991\n",
            "Epoch 1342/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1928 - acc: 0.9258 - val_loss: 0.3966 - val_acc: 0.8831\n",
            "Epoch 1343/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1926 - acc: 0.9257 - val_loss: 0.3206 - val_acc: 0.8941\n",
            "Epoch 1344/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1924 - acc: 0.9256 - val_loss: 0.3287 - val_acc: 0.8929\n",
            "Epoch 1345/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1925 - acc: 0.9258 - val_loss: 0.3191 - val_acc: 0.8949\n",
            "Epoch 1346/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1919 - acc: 0.9258 - val_loss: 0.3368 - val_acc: 0.8917\n",
            "Epoch 1347/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1920 - acc: 0.9260 - val_loss: 0.3049 - val_acc: 0.8976\n",
            "Epoch 1348/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1929 - acc: 0.9251 - val_loss: 0.3221 - val_acc: 0.8930\n",
            "Epoch 1349/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1929 - acc: 0.9256 - val_loss: 0.2882 - val_acc: 0.8985\n",
            "Epoch 1350/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1926 - acc: 0.9255 - val_loss: 0.3013 - val_acc: 0.8955\n",
            "Epoch 1351/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1925 - acc: 0.9260 - val_loss: 0.3678 - val_acc: 0.8845\n",
            "Epoch 1352/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1923 - acc: 0.9258 - val_loss: 0.3063 - val_acc: 0.8981\n",
            "Epoch 1353/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1920 - acc: 0.9261 - val_loss: 0.3239 - val_acc: 0.8928\n",
            "Epoch 1354/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1926 - acc: 0.9254 - val_loss: 0.3350 - val_acc: 0.8924\n",
            "Epoch 1355/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1925 - acc: 0.9256 - val_loss: 0.3207 - val_acc: 0.8942\n",
            "Epoch 1356/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1923 - acc: 0.9259 - val_loss: 0.3520 - val_acc: 0.8876\n",
            "Epoch 1357/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1924 - acc: 0.9255 - val_loss: 0.3689 - val_acc: 0.8835\n",
            "Epoch 1358/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1918 - acc: 0.9259 - val_loss: 0.3465 - val_acc: 0.8908\n",
            "Epoch 1359/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1927 - acc: 0.9256 - val_loss: 0.3181 - val_acc: 0.8948\n",
            "Epoch 1360/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1918 - acc: 0.9258 - val_loss: 0.3441 - val_acc: 0.8912\n",
            "Epoch 1361/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1924 - acc: 0.9254 - val_loss: 0.3233 - val_acc: 0.8931\n",
            "Epoch 1362/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1920 - acc: 0.9256 - val_loss: 0.3530 - val_acc: 0.8889\n",
            "Epoch 1363/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1923 - acc: 0.9257 - val_loss: 0.3076 - val_acc: 0.8959\n",
            "Epoch 1364/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1922 - acc: 0.9258 - val_loss: 0.3356 - val_acc: 0.8888\n",
            "Epoch 1365/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1925 - acc: 0.9256 - val_loss: 0.3471 - val_acc: 0.8895\n",
            "Epoch 1366/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1919 - acc: 0.9259 - val_loss: 0.3535 - val_acc: 0.8891\n",
            "Epoch 1367/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1921 - acc: 0.9256 - val_loss: 0.3290 - val_acc: 0.8915\n",
            "Epoch 1368/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1922 - acc: 0.9258 - val_loss: 0.3126 - val_acc: 0.8956\n",
            "Epoch 1369/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1920 - acc: 0.9261 - val_loss: 0.3033 - val_acc: 0.8951\n",
            "Epoch 1370/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1918 - acc: 0.9260 - val_loss: 0.3181 - val_acc: 0.8930\n",
            "Epoch 1371/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1920 - acc: 0.9260 - val_loss: 0.3543 - val_acc: 0.8876\n",
            "Epoch 1372/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1924 - acc: 0.9261 - val_loss: 0.3609 - val_acc: 0.8870\n",
            "Epoch 1373/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1919 - acc: 0.9261 - val_loss: 0.3237 - val_acc: 0.8917\n",
            "Epoch 1374/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1922 - acc: 0.9256 - val_loss: 0.3758 - val_acc: 0.8836\n",
            "Epoch 1375/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1919 - acc: 0.9259 - val_loss: 0.3766 - val_acc: 0.8850\n",
            "Epoch 1376/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1922 - acc: 0.9257 - val_loss: 0.3326 - val_acc: 0.8918\n",
            "Epoch 1377/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1920 - acc: 0.9259 - val_loss: 0.3051 - val_acc: 0.8969\n",
            "Epoch 1378/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1922 - acc: 0.9257 - val_loss: 0.3372 - val_acc: 0.8896\n",
            "Epoch 1379/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1928 - acc: 0.9258 - val_loss: 0.3199 - val_acc: 0.8937\n",
            "Epoch 1380/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1914 - acc: 0.9262 - val_loss: 0.3615 - val_acc: 0.8848\n",
            "Epoch 1381/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1916 - acc: 0.9258 - val_loss: 0.3183 - val_acc: 0.8952\n",
            "Epoch 1382/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1923 - acc: 0.9256 - val_loss: 0.3101 - val_acc: 0.8942\n",
            "Epoch 1383/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1934 - acc: 0.9253 - val_loss: 0.3409 - val_acc: 0.8902\n",
            "Epoch 1384/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1912 - acc: 0.9264 - val_loss: 0.3296 - val_acc: 0.8928\n",
            "Epoch 1385/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1917 - acc: 0.9258 - val_loss: 0.3474 - val_acc: 0.8880\n",
            "Epoch 1386/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1917 - acc: 0.9257 - val_loss: 0.3683 - val_acc: 0.8857\n",
            "Epoch 1387/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1919 - acc: 0.9258 - val_loss: 0.3443 - val_acc: 0.8885\n",
            "Epoch 1388/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1927 - acc: 0.9257 - val_loss: 0.3230 - val_acc: 0.8968\n",
            "Epoch 1389/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1922 - acc: 0.9258 - val_loss: 0.3205 - val_acc: 0.8925\n",
            "Epoch 1390/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1922 - acc: 0.9256 - val_loss: 0.3343 - val_acc: 0.8903\n",
            "Epoch 1391/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1922 - acc: 0.9257 - val_loss: 0.3321 - val_acc: 0.8915\n",
            "Epoch 1392/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1924 - acc: 0.9258 - val_loss: 0.3228 - val_acc: 0.8949\n",
            "Epoch 1393/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1923 - acc: 0.9255 - val_loss: 0.3447 - val_acc: 0.8909\n",
            "Epoch 1394/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1921 - acc: 0.9257 - val_loss: 0.2844 - val_acc: 0.8986\n",
            "Epoch 1395/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1919 - acc: 0.9257 - val_loss: 0.3312 - val_acc: 0.8870\n",
            "Epoch 1396/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1920 - acc: 0.9258 - val_loss: 0.3471 - val_acc: 0.8872\n",
            "Epoch 1397/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1926 - acc: 0.9256 - val_loss: 0.3834 - val_acc: 0.8832\n",
            "Epoch 1398/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1922 - acc: 0.9260 - val_loss: 0.3454 - val_acc: 0.8882\n",
            "Epoch 1399/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1922 - acc: 0.9257 - val_loss: 0.3203 - val_acc: 0.8917\n",
            "Epoch 1400/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1915 - acc: 0.9260 - val_loss: 0.3348 - val_acc: 0.8924\n",
            "Epoch 1401/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1914 - acc: 0.9259 - val_loss: 0.3104 - val_acc: 0.8983\n",
            "Epoch 1402/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1921 - acc: 0.9259 - val_loss: 0.3194 - val_acc: 0.8937\n",
            "Epoch 1403/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1925 - acc: 0.9256 - val_loss: 0.2861 - val_acc: 0.9024\n",
            "Epoch 1404/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1920 - acc: 0.9257 - val_loss: 0.3376 - val_acc: 0.8912\n",
            "Epoch 1405/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1922 - acc: 0.9258 - val_loss: 0.3474 - val_acc: 0.8899\n",
            "Epoch 1406/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1922 - acc: 0.9258 - val_loss: 0.3040 - val_acc: 0.9007\n",
            "Epoch 1407/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1915 - acc: 0.9256 - val_loss: 0.3503 - val_acc: 0.8886\n",
            "Epoch 1408/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1915 - acc: 0.9260 - val_loss: 0.3657 - val_acc: 0.8890\n",
            "Epoch 1409/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1914 - acc: 0.9260 - val_loss: 0.3341 - val_acc: 0.8887\n",
            "Epoch 1410/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1923 - acc: 0.9254 - val_loss: 0.3036 - val_acc: 0.8979\n",
            "Epoch 1411/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1920 - acc: 0.9257 - val_loss: 0.3130 - val_acc: 0.8958\n",
            "Epoch 1412/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1915 - acc: 0.9258 - val_loss: 0.3552 - val_acc: 0.8906\n",
            "Epoch 1413/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1914 - acc: 0.9263 - val_loss: 0.3501 - val_acc: 0.8894\n",
            "Epoch 1414/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1923 - acc: 0.9256 - val_loss: 0.3220 - val_acc: 0.8950\n",
            "Epoch 1415/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1921 - acc: 0.9256 - val_loss: 0.3655 - val_acc: 0.8860\n",
            "Epoch 1416/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1920 - acc: 0.9257 - val_loss: 0.2991 - val_acc: 0.8967\n",
            "Epoch 1417/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1920 - acc: 0.9256 - val_loss: 0.2850 - val_acc: 0.8969\n",
            "Epoch 1418/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1922 - acc: 0.9255 - val_loss: 0.3001 - val_acc: 0.8970\n",
            "Epoch 1419/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1921 - acc: 0.9258 - val_loss: 0.3328 - val_acc: 0.8896\n",
            "Epoch 1420/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1921 - acc: 0.9256 - val_loss: 0.3428 - val_acc: 0.8921\n",
            "Epoch 1421/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1921 - acc: 0.9258 - val_loss: 0.3148 - val_acc: 0.8932\n",
            "Epoch 1422/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1919 - acc: 0.9259 - val_loss: 0.3083 - val_acc: 0.8949\n",
            "Epoch 1423/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1924 - acc: 0.9257 - val_loss: 0.3164 - val_acc: 0.8929\n",
            "Epoch 1424/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1924 - acc: 0.9257 - val_loss: 0.3213 - val_acc: 0.8928\n",
            "Epoch 1425/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1921 - acc: 0.9258 - val_loss: 0.3211 - val_acc: 0.8961\n",
            "Epoch 1426/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1920 - acc: 0.9260 - val_loss: 0.3236 - val_acc: 0.8954\n",
            "Epoch 1427/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1921 - acc: 0.9256 - val_loss: 0.2979 - val_acc: 0.8982\n",
            "Epoch 1428/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1917 - acc: 0.9259 - val_loss: 0.3399 - val_acc: 0.8930\n",
            "Epoch 1429/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1924 - acc: 0.9256 - val_loss: 0.3370 - val_acc: 0.8907\n",
            "Epoch 1430/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1926 - acc: 0.9257 - val_loss: 0.3481 - val_acc: 0.8908\n",
            "Epoch 1431/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1926 - acc: 0.9257 - val_loss: 0.3101 - val_acc: 0.8962\n",
            "Epoch 1432/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1927 - acc: 0.9255 - val_loss: 0.3113 - val_acc: 0.8958\n",
            "Epoch 1433/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1920 - acc: 0.9255 - val_loss: 0.3079 - val_acc: 0.8962\n",
            "Epoch 1434/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1919 - acc: 0.9257 - val_loss: 0.3135 - val_acc: 0.8943\n",
            "Epoch 1435/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1916 - acc: 0.9257 - val_loss: 0.3548 - val_acc: 0.8908\n",
            "Epoch 1436/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1913 - acc: 0.9264 - val_loss: 0.3180 - val_acc: 0.8936\n",
            "Epoch 1437/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1917 - acc: 0.9262 - val_loss: 0.3471 - val_acc: 0.8899\n",
            "Epoch 1438/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1920 - acc: 0.9257 - val_loss: 0.3461 - val_acc: 0.8856\n",
            "Epoch 1439/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1918 - acc: 0.9257 - val_loss: 0.3801 - val_acc: 0.8834\n",
            "Epoch 1440/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1926 - acc: 0.9257 - val_loss: 0.3089 - val_acc: 0.8960\n",
            "Epoch 1441/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1920 - acc: 0.9257 - val_loss: 0.3525 - val_acc: 0.8912\n",
            "Epoch 1442/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1929 - acc: 0.9256 - val_loss: 0.3797 - val_acc: 0.8862\n",
            "Epoch 1443/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1921 - acc: 0.9258 - val_loss: 0.3645 - val_acc: 0.8890\n",
            "Epoch 1444/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1912 - acc: 0.9260 - val_loss: 0.3317 - val_acc: 0.8939\n",
            "Epoch 1445/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1918 - acc: 0.9258 - val_loss: 0.2938 - val_acc: 0.8994\n",
            "Epoch 1446/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1921 - acc: 0.9258 - val_loss: 0.3188 - val_acc: 0.8944\n",
            "Epoch 1447/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1925 - acc: 0.9256 - val_loss: 0.3427 - val_acc: 0.8905\n",
            "Epoch 1448/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1918 - acc: 0.9262 - val_loss: 0.3695 - val_acc: 0.8864\n",
            "Epoch 1449/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1923 - acc: 0.9259 - val_loss: 0.3266 - val_acc: 0.8907\n",
            "Epoch 1450/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1917 - acc: 0.9262 - val_loss: 0.3032 - val_acc: 0.8944\n",
            "Epoch 1451/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1915 - acc: 0.9260 - val_loss: 0.3130 - val_acc: 0.8951\n",
            "Epoch 1452/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1917 - acc: 0.9256 - val_loss: 0.3219 - val_acc: 0.8954\n",
            "Epoch 1453/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1915 - acc: 0.9260 - val_loss: 0.3383 - val_acc: 0.8901\n",
            "Epoch 1454/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1917 - acc: 0.9261 - val_loss: 0.3161 - val_acc: 0.8937\n",
            "Epoch 1455/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1916 - acc: 0.9259 - val_loss: 0.3067 - val_acc: 0.8954\n",
            "Epoch 1456/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1915 - acc: 0.9263 - val_loss: 0.3469 - val_acc: 0.8910\n",
            "Epoch 1457/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1925 - acc: 0.9258 - val_loss: 0.3241 - val_acc: 0.8918\n",
            "Epoch 1458/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1912 - acc: 0.9262 - val_loss: 0.3156 - val_acc: 0.8976\n",
            "Epoch 1459/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1914 - acc: 0.9259 - val_loss: 0.3041 - val_acc: 0.8967\n",
            "Epoch 1460/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1918 - acc: 0.9255 - val_loss: 0.2949 - val_acc: 0.9000\n",
            "Epoch 1461/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1916 - acc: 0.9262 - val_loss: 0.3908 - val_acc: 0.8823\n",
            "Epoch 1462/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1907 - acc: 0.9261 - val_loss: 0.3535 - val_acc: 0.8911\n",
            "Epoch 1463/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1916 - acc: 0.9257 - val_loss: 0.4133 - val_acc: 0.8790\n",
            "Epoch 1464/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1916 - acc: 0.9262 - val_loss: 0.3413 - val_acc: 0.8903\n",
            "Epoch 1465/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1919 - acc: 0.9256 - val_loss: 0.3959 - val_acc: 0.8832\n",
            "Epoch 1466/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1919 - acc: 0.9258 - val_loss: 0.3482 - val_acc: 0.8907\n",
            "Epoch 1467/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1921 - acc: 0.9259 - val_loss: 0.3092 - val_acc: 0.8970\n",
            "Epoch 1468/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1921 - acc: 0.9258 - val_loss: 0.3250 - val_acc: 0.8948\n",
            "Epoch 1469/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1917 - acc: 0.9259 - val_loss: 0.3593 - val_acc: 0.8887\n",
            "Epoch 1470/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1918 - acc: 0.9261 - val_loss: 0.3222 - val_acc: 0.8958\n",
            "Epoch 1471/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1917 - acc: 0.9260 - val_loss: 0.3564 - val_acc: 0.8893\n",
            "Epoch 1472/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9262 - val_loss: 0.3450 - val_acc: 0.8908\n",
            "Epoch 1473/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1923 - acc: 0.9257 - val_loss: 0.3322 - val_acc: 0.8918\n",
            "Epoch 1474/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1918 - acc: 0.9259 - val_loss: 0.3980 - val_acc: 0.8839\n",
            "Epoch 1475/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1911 - acc: 0.9264 - val_loss: 0.3335 - val_acc: 0.8904\n",
            "Epoch 1476/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1921 - acc: 0.9255 - val_loss: 0.3051 - val_acc: 0.8975\n",
            "Epoch 1477/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1915 - acc: 0.9260 - val_loss: 0.3165 - val_acc: 0.8926\n",
            "Epoch 1478/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1911 - acc: 0.9259 - val_loss: 0.3383 - val_acc: 0.8899\n",
            "Epoch 1479/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1920 - acc: 0.9257 - val_loss: 0.3085 - val_acc: 0.8964\n",
            "Epoch 1480/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1917 - acc: 0.9260 - val_loss: 0.3981 - val_acc: 0.8801\n",
            "Epoch 1481/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1921 - acc: 0.9256 - val_loss: 0.3673 - val_acc: 0.8855\n",
            "Epoch 1482/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1916 - acc: 0.9258 - val_loss: 0.2898 - val_acc: 0.8981\n",
            "Epoch 1483/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1910 - acc: 0.9261 - val_loss: 0.3046 - val_acc: 0.8970\n",
            "Epoch 1484/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1912 - acc: 0.9259 - val_loss: 0.3572 - val_acc: 0.8885\n",
            "Epoch 1485/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1922 - acc: 0.9259 - val_loss: 0.3121 - val_acc: 0.8954\n",
            "Epoch 1486/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1920 - acc: 0.9256 - val_loss: 0.3697 - val_acc: 0.8856\n",
            "Epoch 1487/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9263 - val_loss: 0.3366 - val_acc: 0.8928\n",
            "Epoch 1488/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1915 - acc: 0.9261 - val_loss: 0.3374 - val_acc: 0.8908\n",
            "Epoch 1489/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1918 - acc: 0.9257 - val_loss: 0.3274 - val_acc: 0.8921\n",
            "Epoch 1490/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1916 - acc: 0.9260 - val_loss: 0.3272 - val_acc: 0.8918\n",
            "Epoch 1491/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1922 - acc: 0.9258 - val_loss: 0.3600 - val_acc: 0.8903\n",
            "Epoch 1492/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1919 - acc: 0.9257 - val_loss: 0.3485 - val_acc: 0.8892\n",
            "Epoch 1493/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1910 - acc: 0.9263 - val_loss: 0.3502 - val_acc: 0.8862\n",
            "Epoch 1494/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1926 - acc: 0.9255 - val_loss: 0.3159 - val_acc: 0.8947\n",
            "Epoch 1495/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1916 - acc: 0.9259 - val_loss: 0.2693 - val_acc: 0.9024\n",
            "Epoch 1496/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1916 - acc: 0.9260 - val_loss: 0.3713 - val_acc: 0.8887\n",
            "Epoch 1497/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1919 - acc: 0.9259 - val_loss: 0.3272 - val_acc: 0.8921\n",
            "Epoch 1498/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1913 - acc: 0.9261 - val_loss: 0.3564 - val_acc: 0.8889\n",
            "Epoch 1499/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1915 - acc: 0.9260 - val_loss: 0.3254 - val_acc: 0.8933\n",
            "Epoch 1500/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1918 - acc: 0.9262 - val_loss: 0.3458 - val_acc: 0.8876\n",
            "Epoch 1501/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1919 - acc: 0.9260 - val_loss: 0.3233 - val_acc: 0.8950\n",
            "Epoch 1502/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1916 - acc: 0.9262 - val_loss: 0.3255 - val_acc: 0.8921\n",
            "Epoch 1503/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1919 - acc: 0.9258 - val_loss: 0.3312 - val_acc: 0.8917\n",
            "Epoch 1504/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1917 - acc: 0.9260 - val_loss: 0.3007 - val_acc: 0.8962\n",
            "Epoch 1505/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1912 - acc: 0.9261 - val_loss: 0.3696 - val_acc: 0.8836\n",
            "Epoch 1506/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9263 - val_loss: 0.3264 - val_acc: 0.8905\n",
            "Epoch 1507/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1912 - acc: 0.9259 - val_loss: 0.3674 - val_acc: 0.8877\n",
            "Epoch 1508/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9263 - val_loss: 0.3072 - val_acc: 0.8978\n",
            "Epoch 1509/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1916 - acc: 0.9262 - val_loss: 0.3150 - val_acc: 0.8925\n",
            "Epoch 1510/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1918 - acc: 0.9260 - val_loss: 0.3143 - val_acc: 0.8932\n",
            "Epoch 1511/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1919 - acc: 0.9258 - val_loss: 0.3611 - val_acc: 0.8865\n",
            "Epoch 1512/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1922 - acc: 0.9259 - val_loss: 0.3512 - val_acc: 0.8893\n",
            "Epoch 1513/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1917 - acc: 0.9260 - val_loss: 0.3489 - val_acc: 0.8903\n",
            "Epoch 1514/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1919 - acc: 0.9260 - val_loss: 0.3469 - val_acc: 0.8875\n",
            "Epoch 1515/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1914 - acc: 0.9261 - val_loss: 0.3118 - val_acc: 0.8970\n",
            "Epoch 1516/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1917 - acc: 0.9257 - val_loss: 0.3364 - val_acc: 0.8909\n",
            "Epoch 1517/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9261 - val_loss: 0.3186 - val_acc: 0.8959\n",
            "Epoch 1518/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1918 - acc: 0.9261 - val_loss: 0.3728 - val_acc: 0.8884\n",
            "Epoch 1519/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1920 - acc: 0.9259 - val_loss: 0.3581 - val_acc: 0.8887\n",
            "Epoch 1520/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1916 - acc: 0.9262 - val_loss: 0.3987 - val_acc: 0.8833\n",
            "Epoch 1521/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9263 - val_loss: 0.3272 - val_acc: 0.8924\n",
            "Epoch 1522/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1917 - acc: 0.9262 - val_loss: 0.3560 - val_acc: 0.8871\n",
            "Epoch 1523/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1910 - acc: 0.9264 - val_loss: 0.3849 - val_acc: 0.8818\n",
            "Epoch 1524/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1903 - acc: 0.9263 - val_loss: 0.3278 - val_acc: 0.8933\n",
            "Epoch 1525/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1914 - acc: 0.9258 - val_loss: 0.3175 - val_acc: 0.8949\n",
            "Epoch 1526/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1921 - acc: 0.9261 - val_loss: 0.3304 - val_acc: 0.8939\n",
            "Epoch 1527/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1911 - acc: 0.9263 - val_loss: 0.3191 - val_acc: 0.8966\n",
            "Epoch 1528/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1912 - acc: 0.9262 - val_loss: 0.3256 - val_acc: 0.8922\n",
            "Epoch 1529/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9263 - val_loss: 0.3748 - val_acc: 0.8896\n",
            "Epoch 1530/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1910 - acc: 0.9260 - val_loss: 0.2992 - val_acc: 0.8959\n",
            "Epoch 1531/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1915 - acc: 0.9260 - val_loss: 0.3697 - val_acc: 0.8845\n",
            "Epoch 1532/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1917 - acc: 0.9259 - val_loss: 0.3281 - val_acc: 0.8953\n",
            "Epoch 1533/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1917 - acc: 0.9261 - val_loss: 0.3352 - val_acc: 0.8923\n",
            "Epoch 1534/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1915 - acc: 0.9261 - val_loss: 0.3774 - val_acc: 0.8848\n",
            "Epoch 1535/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1917 - acc: 0.9261 - val_loss: 0.3525 - val_acc: 0.8904\n",
            "Epoch 1536/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1908 - acc: 0.9262 - val_loss: 0.3350 - val_acc: 0.8900\n",
            "Epoch 1537/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1916 - acc: 0.9262 - val_loss: 0.3265 - val_acc: 0.8939\n",
            "Epoch 1538/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1918 - acc: 0.9260 - val_loss: 0.3150 - val_acc: 0.8941\n",
            "Epoch 1539/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1916 - acc: 0.9259 - val_loss: 0.2906 - val_acc: 0.9019\n",
            "Epoch 1540/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1914 - acc: 0.9261 - val_loss: 0.3257 - val_acc: 0.8957\n",
            "Epoch 1541/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1916 - acc: 0.9260 - val_loss: 0.3423 - val_acc: 0.8915\n",
            "Epoch 1542/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1915 - acc: 0.9260 - val_loss: 0.3272 - val_acc: 0.8932\n",
            "Epoch 1543/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1911 - acc: 0.9262 - val_loss: 0.3115 - val_acc: 0.8977\n",
            "Epoch 1544/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1916 - acc: 0.9259 - val_loss: 0.3846 - val_acc: 0.8839\n",
            "Epoch 1545/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1910 - acc: 0.9264 - val_loss: 0.3382 - val_acc: 0.8917\n",
            "Epoch 1546/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1920 - acc: 0.9260 - val_loss: 0.3902 - val_acc: 0.8854\n",
            "Epoch 1547/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1915 - acc: 0.9260 - val_loss: 0.3104 - val_acc: 0.8977\n",
            "Epoch 1548/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1920 - acc: 0.9261 - val_loss: 0.3048 - val_acc: 0.8959\n",
            "Epoch 1549/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1912 - acc: 0.9262 - val_loss: 0.3224 - val_acc: 0.8938\n",
            "Epoch 1550/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1916 - acc: 0.9260 - val_loss: 0.3870 - val_acc: 0.8822\n",
            "Epoch 1551/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1916 - acc: 0.9260 - val_loss: 0.3370 - val_acc: 0.8919\n",
            "Epoch 1552/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1914 - acc: 0.9260 - val_loss: 0.3449 - val_acc: 0.8905\n",
            "Epoch 1553/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1915 - acc: 0.9262 - val_loss: 0.3172 - val_acc: 0.8967\n",
            "Epoch 1554/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1915 - acc: 0.9262 - val_loss: 0.3110 - val_acc: 0.8943\n",
            "Epoch 1555/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1920 - acc: 0.9255 - val_loss: 0.3505 - val_acc: 0.8886\n",
            "Epoch 1556/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1924 - acc: 0.9256 - val_loss: 0.3481 - val_acc: 0.8893\n",
            "Epoch 1557/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1908 - acc: 0.9262 - val_loss: 0.3380 - val_acc: 0.8916\n",
            "Epoch 1558/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1921 - acc: 0.9258 - val_loss: 0.3469 - val_acc: 0.8898\n",
            "Epoch 1559/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1918 - acc: 0.9261 - val_loss: 0.3292 - val_acc: 0.8917\n",
            "Epoch 1560/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1908 - acc: 0.9260 - val_loss: 0.3627 - val_acc: 0.8870\n",
            "Epoch 1561/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1919 - acc: 0.9258 - val_loss: 0.3316 - val_acc: 0.8939\n",
            "Epoch 1562/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1913 - acc: 0.9261 - val_loss: 0.3727 - val_acc: 0.8885\n",
            "Epoch 1563/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1920 - acc: 0.9256 - val_loss: 0.3263 - val_acc: 0.8939\n",
            "Epoch 1564/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1919 - acc: 0.9256 - val_loss: 0.3020 - val_acc: 0.8973\n",
            "Epoch 1565/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1913 - acc: 0.9263 - val_loss: 0.3588 - val_acc: 0.8874\n",
            "Epoch 1566/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1908 - acc: 0.9263 - val_loss: 0.2959 - val_acc: 0.9001\n",
            "Epoch 1567/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1911 - acc: 0.9263 - val_loss: 0.3048 - val_acc: 0.8978\n",
            "Epoch 1568/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1917 - acc: 0.9260 - val_loss: 0.3158 - val_acc: 0.8967\n",
            "Epoch 1569/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1913 - acc: 0.9260 - val_loss: 0.3342 - val_acc: 0.8918\n",
            "Epoch 1570/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1914 - acc: 0.9261 - val_loss: 0.3802 - val_acc: 0.8847\n",
            "Epoch 1571/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1914 - acc: 0.9262 - val_loss: 0.3149 - val_acc: 0.8971\n",
            "Epoch 1572/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1923 - acc: 0.9256 - val_loss: 0.3263 - val_acc: 0.8925\n",
            "Epoch 1573/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9264 - val_loss: 0.3271 - val_acc: 0.8927\n",
            "Epoch 1574/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1917 - acc: 0.9259 - val_loss: 0.3340 - val_acc: 0.8912\n",
            "Epoch 1575/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1914 - acc: 0.9258 - val_loss: 0.3228 - val_acc: 0.8938\n",
            "Epoch 1576/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9260 - val_loss: 0.3159 - val_acc: 0.8956\n",
            "Epoch 1577/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1915 - acc: 0.9264 - val_loss: 0.3837 - val_acc: 0.8877\n",
            "Epoch 1578/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1915 - acc: 0.9261 - val_loss: 0.3484 - val_acc: 0.8919\n",
            "Epoch 1579/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1906 - acc: 0.9262 - val_loss: 0.3801 - val_acc: 0.8837\n",
            "Epoch 1580/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1911 - acc: 0.9260 - val_loss: 0.3603 - val_acc: 0.8831\n",
            "Epoch 1581/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1907 - acc: 0.9263 - val_loss: 0.3005 - val_acc: 0.8975\n",
            "Epoch 1582/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1916 - acc: 0.9261 - val_loss: 0.3079 - val_acc: 0.8960\n",
            "Epoch 1583/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1911 - acc: 0.9262 - val_loss: 0.3365 - val_acc: 0.8903\n",
            "Epoch 1584/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1913 - acc: 0.9262 - val_loss: 0.3599 - val_acc: 0.8858\n",
            "Epoch 1585/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1922 - acc: 0.9254 - val_loss: 0.3710 - val_acc: 0.8859\n",
            "Epoch 1586/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1913 - acc: 0.9259 - val_loss: 0.3428 - val_acc: 0.8893\n",
            "Epoch 1587/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1916 - acc: 0.9259 - val_loss: 0.3238 - val_acc: 0.8950\n",
            "Epoch 1588/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1919 - acc: 0.9261 - val_loss: 0.3568 - val_acc: 0.8915\n",
            "Epoch 1589/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1914 - acc: 0.9262 - val_loss: 0.3390 - val_acc: 0.8898\n",
            "Epoch 1590/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9261 - val_loss: 0.3047 - val_acc: 0.8992\n",
            "Epoch 1591/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1911 - acc: 0.9264 - val_loss: 0.3599 - val_acc: 0.8871\n",
            "Epoch 1592/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1915 - acc: 0.9261 - val_loss: 0.3093 - val_acc: 0.8958\n",
            "Epoch 1593/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1916 - acc: 0.9258 - val_loss: 0.3436 - val_acc: 0.8914\n",
            "Epoch 1594/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1915 - acc: 0.9261 - val_loss: 0.3326 - val_acc: 0.8936\n",
            "Epoch 1595/6000\n",
            "584288/584288 [==============================] - 20s 33us/step - loss: 0.1916 - acc: 0.9256 - val_loss: 0.3601 - val_acc: 0.8850\n",
            "Epoch 1596/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1916 - acc: 0.9261 - val_loss: 0.3034 - val_acc: 0.8979\n",
            "Epoch 1597/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1920 - acc: 0.9256 - val_loss: 0.3406 - val_acc: 0.8907\n",
            "Epoch 1598/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1912 - acc: 0.9262 - val_loss: 0.3242 - val_acc: 0.8961\n",
            "Epoch 1599/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1915 - acc: 0.9260 - val_loss: 0.3230 - val_acc: 0.8939\n",
            "Epoch 1600/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9262 - val_loss: 0.2918 - val_acc: 0.9001\n",
            "Epoch 1601/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1917 - acc: 0.9261 - val_loss: 0.3282 - val_acc: 0.8927\n",
            "Epoch 1602/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1911 - acc: 0.9261 - val_loss: 0.3511 - val_acc: 0.8873\n",
            "Epoch 1603/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1911 - acc: 0.9260 - val_loss: 0.3523 - val_acc: 0.8861\n",
            "Epoch 1604/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9263 - val_loss: 0.3276 - val_acc: 0.8948\n",
            "Epoch 1605/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1913 - acc: 0.9264 - val_loss: 0.3640 - val_acc: 0.8866\n",
            "Epoch 1606/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9260 - val_loss: 0.3392 - val_acc: 0.8909\n",
            "Epoch 1607/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1903 - acc: 0.9265 - val_loss: 0.3525 - val_acc: 0.8903\n",
            "Epoch 1608/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9262 - val_loss: 0.3346 - val_acc: 0.8926\n",
            "Epoch 1609/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1912 - acc: 0.9262 - val_loss: 0.2923 - val_acc: 0.8996\n",
            "Epoch 1610/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1918 - acc: 0.9260 - val_loss: 0.3338 - val_acc: 0.8907\n",
            "Epoch 1611/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1912 - acc: 0.9261 - val_loss: 0.3241 - val_acc: 0.8932\n",
            "Epoch 1612/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1917 - acc: 0.9262 - val_loss: 0.3373 - val_acc: 0.8912\n",
            "Epoch 1613/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1916 - acc: 0.9258 - val_loss: 0.3135 - val_acc: 0.8972\n",
            "Epoch 1614/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1905 - acc: 0.9267 - val_loss: 0.3303 - val_acc: 0.8942\n",
            "Epoch 1615/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1915 - acc: 0.9261 - val_loss: 0.3245 - val_acc: 0.8926\n",
            "Epoch 1616/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1915 - acc: 0.9257 - val_loss: 0.2910 - val_acc: 0.8980\n",
            "Epoch 1617/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1913 - acc: 0.9260 - val_loss: 0.3237 - val_acc: 0.8933\n",
            "Epoch 1618/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1919 - acc: 0.9259 - val_loss: 0.3141 - val_acc: 0.8953\n",
            "Epoch 1619/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1912 - acc: 0.9261 - val_loss: 0.3122 - val_acc: 0.8966\n",
            "Epoch 1620/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9261 - val_loss: 0.3705 - val_acc: 0.8852\n",
            "Epoch 1621/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1912 - acc: 0.9261 - val_loss: 0.3156 - val_acc: 0.8937\n",
            "Epoch 1622/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1912 - acc: 0.9261 - val_loss: 0.3436 - val_acc: 0.8932\n",
            "Epoch 1623/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1914 - acc: 0.9261 - val_loss: 0.3359 - val_acc: 0.8907\n",
            "Epoch 1624/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1904 - acc: 0.9263 - val_loss: 0.3029 - val_acc: 0.8991\n",
            "Epoch 1625/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1904 - acc: 0.9263 - val_loss: 0.3206 - val_acc: 0.8928\n",
            "Epoch 1626/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1911 - acc: 0.9265 - val_loss: 0.3698 - val_acc: 0.8893\n",
            "Epoch 1627/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1913 - acc: 0.9263 - val_loss: 0.3227 - val_acc: 0.8945\n",
            "Epoch 1628/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1922 - acc: 0.9259 - val_loss: 0.3465 - val_acc: 0.8901\n",
            "Epoch 1629/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1905 - acc: 0.9263 - val_loss: 0.3427 - val_acc: 0.8919\n",
            "Epoch 1630/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1914 - acc: 0.9261 - val_loss: 0.3019 - val_acc: 0.8985\n",
            "Epoch 1631/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1911 - acc: 0.9264 - val_loss: 0.3792 - val_acc: 0.8866\n",
            "Epoch 1632/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1914 - acc: 0.9261 - val_loss: 0.3564 - val_acc: 0.8803\n",
            "Epoch 1633/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9264 - val_loss: 0.2958 - val_acc: 0.9009\n",
            "Epoch 1634/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1916 - acc: 0.9263 - val_loss: 0.3685 - val_acc: 0.8868\n",
            "Epoch 1635/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1908 - acc: 0.9263 - val_loss: 0.3203 - val_acc: 0.8894\n",
            "Epoch 1636/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1911 - acc: 0.9262 - val_loss: 0.3397 - val_acc: 0.8924\n",
            "Epoch 1637/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1913 - acc: 0.9262 - val_loss: 0.3426 - val_acc: 0.8876\n",
            "Epoch 1638/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9264 - val_loss: 0.3609 - val_acc: 0.8871\n",
            "Epoch 1639/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1907 - acc: 0.9263 - val_loss: 0.3631 - val_acc: 0.8879\n",
            "Epoch 1640/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1913 - acc: 0.9263 - val_loss: 0.3435 - val_acc: 0.8898\n",
            "Epoch 1641/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9262 - val_loss: 0.3249 - val_acc: 0.8936\n",
            "Epoch 1642/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1908 - acc: 0.9264 - val_loss: 0.3283 - val_acc: 0.8930\n",
            "Epoch 1643/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9260 - val_loss: 0.3461 - val_acc: 0.8893\n",
            "Epoch 1644/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9262 - val_loss: 0.3218 - val_acc: 0.8957\n",
            "Epoch 1645/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9261 - val_loss: 0.3164 - val_acc: 0.8971\n",
            "Epoch 1646/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9264 - val_loss: 0.2991 - val_acc: 0.9001\n",
            "Epoch 1647/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1911 - acc: 0.9258 - val_loss: 0.3228 - val_acc: 0.8928\n",
            "Epoch 1648/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1911 - acc: 0.9261 - val_loss: 0.3167 - val_acc: 0.8965\n",
            "Epoch 1649/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1914 - acc: 0.9261 - val_loss: 0.3370 - val_acc: 0.8924\n",
            "Epoch 1650/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1908 - acc: 0.9262 - val_loss: 0.3558 - val_acc: 0.8904\n",
            "Epoch 1651/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1910 - acc: 0.9263 - val_loss: 0.2998 - val_acc: 0.8988\n",
            "Epoch 1652/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1904 - acc: 0.9266 - val_loss: 0.3301 - val_acc: 0.8917\n",
            "Epoch 1653/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9259 - val_loss: 0.3438 - val_acc: 0.8895\n",
            "Epoch 1654/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1919 - acc: 0.9258 - val_loss: 0.3244 - val_acc: 0.8942\n",
            "Epoch 1655/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1913 - acc: 0.9261 - val_loss: 0.3245 - val_acc: 0.8934\n",
            "Epoch 1656/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1912 - acc: 0.9261 - val_loss: 0.3253 - val_acc: 0.8944\n",
            "Epoch 1657/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1917 - acc: 0.9259 - val_loss: 0.3296 - val_acc: 0.8937\n",
            "Epoch 1658/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9262 - val_loss: 0.3523 - val_acc: 0.8919\n",
            "Epoch 1659/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1913 - acc: 0.9262 - val_loss: 0.3601 - val_acc: 0.8910\n",
            "Epoch 1660/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1906 - acc: 0.9266 - val_loss: 0.3249 - val_acc: 0.8936\n",
            "Epoch 1661/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1911 - acc: 0.9261 - val_loss: 0.3645 - val_acc: 0.8869\n",
            "Epoch 1662/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1904 - acc: 0.9264 - val_loss: 0.3196 - val_acc: 0.8958\n",
            "Epoch 1663/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1907 - acc: 0.9263 - val_loss: 0.3204 - val_acc: 0.8929\n",
            "Epoch 1664/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1905 - acc: 0.9265 - val_loss: 0.3078 - val_acc: 0.8924\n",
            "Epoch 1665/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1908 - acc: 0.9259 - val_loss: 0.3273 - val_acc: 0.8934\n",
            "Epoch 1666/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1913 - acc: 0.9258 - val_loss: 0.3352 - val_acc: 0.8916\n",
            "Epoch 1667/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1916 - acc: 0.9260 - val_loss: 0.3215 - val_acc: 0.8951\n",
            "Epoch 1668/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1915 - acc: 0.9264 - val_loss: 0.3660 - val_acc: 0.8872\n",
            "Epoch 1669/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1905 - acc: 0.9264 - val_loss: 0.3102 - val_acc: 0.8938\n",
            "Epoch 1670/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1906 - acc: 0.9262 - val_loss: 0.3951 - val_acc: 0.8802\n",
            "Epoch 1671/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1907 - acc: 0.9262 - val_loss: 0.3623 - val_acc: 0.8837\n",
            "Epoch 1672/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9263 - val_loss: 0.3532 - val_acc: 0.8907\n",
            "Epoch 1673/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1912 - acc: 0.9262 - val_loss: 0.3354 - val_acc: 0.8888\n",
            "Epoch 1674/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9265 - val_loss: 0.2954 - val_acc: 0.8991\n",
            "Epoch 1675/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1914 - acc: 0.9259 - val_loss: 0.3466 - val_acc: 0.8913\n",
            "Epoch 1676/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9263 - val_loss: 0.3132 - val_acc: 0.8955\n",
            "Epoch 1677/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9259 - val_loss: 0.3608 - val_acc: 0.8876\n",
            "Epoch 1678/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9261 - val_loss: 0.3425 - val_acc: 0.8889\n",
            "Epoch 1679/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9262 - val_loss: 0.3431 - val_acc: 0.8897\n",
            "Epoch 1680/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1913 - acc: 0.9261 - val_loss: 0.2898 - val_acc: 0.9019\n",
            "Epoch 1681/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1914 - acc: 0.9261 - val_loss: 0.3345 - val_acc: 0.8903\n",
            "Epoch 1682/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1905 - acc: 0.9265 - val_loss: 0.3443 - val_acc: 0.8891\n",
            "Epoch 1683/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1903 - acc: 0.9264 - val_loss: 0.3216 - val_acc: 0.8959\n",
            "Epoch 1684/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1914 - acc: 0.9262 - val_loss: 0.3134 - val_acc: 0.8963\n",
            "Epoch 1685/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1914 - acc: 0.9262 - val_loss: 0.3286 - val_acc: 0.8917\n",
            "Epoch 1686/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9266 - val_loss: 0.3002 - val_acc: 0.8970\n",
            "Epoch 1687/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9264 - val_loss: 0.3756 - val_acc: 0.8858\n",
            "Epoch 1688/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9263 - val_loss: 0.3814 - val_acc: 0.8834\n",
            "Epoch 1689/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1907 - acc: 0.9262 - val_loss: 0.3475 - val_acc: 0.8906\n",
            "Epoch 1690/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9264 - val_loss: 0.3208 - val_acc: 0.8930\n",
            "Epoch 1691/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1915 - acc: 0.9261 - val_loss: 0.3362 - val_acc: 0.8877\n",
            "Epoch 1692/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9265 - val_loss: 0.3413 - val_acc: 0.8912\n",
            "Epoch 1693/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1903 - acc: 0.9265 - val_loss: 0.3336 - val_acc: 0.8918\n",
            "Epoch 1694/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1903 - acc: 0.9265 - val_loss: 0.3772 - val_acc: 0.8829\n",
            "Epoch 1695/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1910 - acc: 0.9263 - val_loss: 0.2729 - val_acc: 0.9031\n",
            "Epoch 1696/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1911 - acc: 0.9264 - val_loss: 0.3354 - val_acc: 0.8924\n",
            "Epoch 1697/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1914 - acc: 0.9261 - val_loss: 0.3416 - val_acc: 0.8904\n",
            "Epoch 1698/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1908 - acc: 0.9261 - val_loss: 0.3121 - val_acc: 0.8981\n",
            "Epoch 1699/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1907 - acc: 0.9266 - val_loss: 0.3537 - val_acc: 0.8864\n",
            "Epoch 1700/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1913 - acc: 0.9262 - val_loss: 0.3881 - val_acc: 0.8826\n",
            "Epoch 1701/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9262 - val_loss: 0.3713 - val_acc: 0.8868\n",
            "Epoch 1702/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1908 - acc: 0.9262 - val_loss: 0.3327 - val_acc: 0.8950\n",
            "Epoch 1703/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1904 - acc: 0.9266 - val_loss: 0.3514 - val_acc: 0.8908\n",
            "Epoch 1704/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1915 - acc: 0.9262 - val_loss: 0.3548 - val_acc: 0.8878\n",
            "Epoch 1705/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1908 - acc: 0.9259 - val_loss: 0.3193 - val_acc: 0.8940\n",
            "Epoch 1706/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1908 - acc: 0.9264 - val_loss: 0.3148 - val_acc: 0.8954\n",
            "Epoch 1707/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1913 - acc: 0.9260 - val_loss: 0.3376 - val_acc: 0.8927\n",
            "Epoch 1708/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1902 - acc: 0.9264 - val_loss: 0.3478 - val_acc: 0.8908\n",
            "Epoch 1709/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1912 - acc: 0.9261 - val_loss: 0.3352 - val_acc: 0.8920\n",
            "Epoch 1710/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1916 - acc: 0.9260 - val_loss: 0.3573 - val_acc: 0.8890\n",
            "Epoch 1711/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1907 - acc: 0.9263 - val_loss: 0.3449 - val_acc: 0.8908\n",
            "Epoch 1712/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1907 - acc: 0.9267 - val_loss: 0.3415 - val_acc: 0.8910\n",
            "Epoch 1713/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1907 - acc: 0.9265 - val_loss: 0.3943 - val_acc: 0.8811\n",
            "Epoch 1714/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9262 - val_loss: 0.3295 - val_acc: 0.8906\n",
            "Epoch 1715/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1909 - acc: 0.9263 - val_loss: 0.3444 - val_acc: 0.8899\n",
            "Epoch 1716/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1906 - acc: 0.9264 - val_loss: 0.3457 - val_acc: 0.8912\n",
            "Epoch 1717/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1904 - acc: 0.9263 - val_loss: 0.3539 - val_acc: 0.8897\n",
            "Epoch 1718/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1902 - acc: 0.9267 - val_loss: 0.3109 - val_acc: 0.8963\n",
            "Epoch 1719/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9262 - val_loss: 0.3018 - val_acc: 0.8969\n",
            "Epoch 1720/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9266 - val_loss: 0.3785 - val_acc: 0.8862\n",
            "Epoch 1721/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9265 - val_loss: 0.3091 - val_acc: 0.8991\n",
            "Epoch 1722/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1904 - acc: 0.9263 - val_loss: 0.3401 - val_acc: 0.8916\n",
            "Epoch 1723/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1899 - acc: 0.9264 - val_loss: 0.2907 - val_acc: 0.8978\n",
            "Epoch 1724/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1914 - acc: 0.9261 - val_loss: 0.3535 - val_acc: 0.8875\n",
            "Epoch 1725/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1903 - acc: 0.9262 - val_loss: 0.3393 - val_acc: 0.8903\n",
            "Epoch 1726/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9265 - val_loss: 0.3232 - val_acc: 0.8949\n",
            "Epoch 1727/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9262 - val_loss: 0.3214 - val_acc: 0.8951\n",
            "Epoch 1728/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9262 - val_loss: 0.2982 - val_acc: 0.9023\n",
            "Epoch 1729/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1908 - acc: 0.9263 - val_loss: 0.3242 - val_acc: 0.8896\n",
            "Epoch 1730/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1913 - acc: 0.9262 - val_loss: 0.3509 - val_acc: 0.8872\n",
            "Epoch 1731/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9261 - val_loss: 0.3344 - val_acc: 0.8916\n",
            "Epoch 1732/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1908 - acc: 0.9262 - val_loss: 0.3269 - val_acc: 0.8945\n",
            "Epoch 1733/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1907 - acc: 0.9265 - val_loss: 0.3192 - val_acc: 0.8947\n",
            "Epoch 1734/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1904 - acc: 0.9264 - val_loss: 0.3215 - val_acc: 0.8943\n",
            "Epoch 1735/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9265 - val_loss: 0.3215 - val_acc: 0.8937\n",
            "Epoch 1736/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1905 - acc: 0.9263 - val_loss: 0.3018 - val_acc: 0.8994\n",
            "Epoch 1737/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1907 - acc: 0.9263 - val_loss: 0.3354 - val_acc: 0.8891\n",
            "Epoch 1738/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1908 - acc: 0.9263 - val_loss: 0.3308 - val_acc: 0.8910\n",
            "Epoch 1739/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9265 - val_loss: 0.3318 - val_acc: 0.8910\n",
            "Epoch 1740/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1913 - acc: 0.9261 - val_loss: 0.3244 - val_acc: 0.8930\n",
            "Epoch 1741/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1911 - acc: 0.9263 - val_loss: 0.3323 - val_acc: 0.8941\n",
            "Epoch 1742/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9263 - val_loss: 0.3203 - val_acc: 0.8953\n",
            "Epoch 1743/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1903 - acc: 0.9263 - val_loss: 0.3145 - val_acc: 0.8941\n",
            "Epoch 1744/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1908 - acc: 0.9263 - val_loss: 0.2991 - val_acc: 0.8981\n",
            "Epoch 1745/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1904 - acc: 0.9268 - val_loss: 0.3484 - val_acc: 0.8852\n",
            "Epoch 1746/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1912 - acc: 0.9263 - val_loss: 0.3318 - val_acc: 0.8936\n",
            "Epoch 1747/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9262 - val_loss: 0.3954 - val_acc: 0.8831\n",
            "Epoch 1748/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1917 - acc: 0.9259 - val_loss: 0.3200 - val_acc: 0.8922\n",
            "Epoch 1749/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1913 - acc: 0.9258 - val_loss: 0.3168 - val_acc: 0.8952\n",
            "Epoch 1750/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1903 - acc: 0.9263 - val_loss: 0.3202 - val_acc: 0.8937\n",
            "Epoch 1751/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1901 - acc: 0.9264 - val_loss: 0.3322 - val_acc: 0.8917\n",
            "Epoch 1752/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1914 - acc: 0.9260 - val_loss: 0.3824 - val_acc: 0.8831\n",
            "Epoch 1753/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9265 - val_loss: 0.3282 - val_acc: 0.8950\n",
            "Epoch 1754/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9265 - val_loss: 0.3070 - val_acc: 0.8908\n",
            "Epoch 1755/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1908 - acc: 0.9261 - val_loss: 0.3304 - val_acc: 0.8929\n",
            "Epoch 1756/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1907 - acc: 0.9265 - val_loss: 0.2886 - val_acc: 0.9016\n",
            "Epoch 1757/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9267 - val_loss: 0.3010 - val_acc: 0.9017\n",
            "Epoch 1758/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9267 - val_loss: 0.3063 - val_acc: 0.8976\n",
            "Epoch 1759/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1903 - acc: 0.9266 - val_loss: 0.3186 - val_acc: 0.8936\n",
            "Epoch 1760/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1901 - acc: 0.9266 - val_loss: 0.2943 - val_acc: 0.9002\n",
            "Epoch 1761/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1900 - acc: 0.9267 - val_loss: 0.3223 - val_acc: 0.8946\n",
            "Epoch 1762/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1915 - acc: 0.9260 - val_loss: 0.3819 - val_acc: 0.8878\n",
            "Epoch 1763/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1907 - acc: 0.9263 - val_loss: 0.3398 - val_acc: 0.8869\n",
            "Epoch 1764/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9264 - val_loss: 0.3566 - val_acc: 0.8835\n",
            "Epoch 1765/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9264 - val_loss: 0.3275 - val_acc: 0.8940\n",
            "Epoch 1766/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1914 - acc: 0.9261 - val_loss: 0.3173 - val_acc: 0.8953\n",
            "Epoch 1767/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1902 - acc: 0.9267 - val_loss: 0.3380 - val_acc: 0.8918\n",
            "Epoch 1768/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1907 - acc: 0.9262 - val_loss: 0.3533 - val_acc: 0.8931\n",
            "Epoch 1769/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9262 - val_loss: 0.3141 - val_acc: 0.8951\n",
            "Epoch 1770/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1901 - acc: 0.9266 - val_loss: 0.3026 - val_acc: 0.8960\n",
            "Epoch 1771/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1901 - acc: 0.9265 - val_loss: 0.3158 - val_acc: 0.8964\n",
            "Epoch 1772/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1908 - acc: 0.9262 - val_loss: 0.4002 - val_acc: 0.8813\n",
            "Epoch 1773/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9262 - val_loss: 0.3525 - val_acc: 0.8893\n",
            "Epoch 1774/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1908 - acc: 0.9263 - val_loss: 0.3223 - val_acc: 0.8956\n",
            "Epoch 1775/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1904 - acc: 0.9265 - val_loss: 0.3841 - val_acc: 0.8837\n",
            "Epoch 1776/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9261 - val_loss: 0.3086 - val_acc: 0.8981\n",
            "Epoch 1777/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1915 - acc: 0.9260 - val_loss: 0.3746 - val_acc: 0.8864\n",
            "Epoch 1778/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9266 - val_loss: 0.3215 - val_acc: 0.8959\n",
            "Epoch 1779/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9265 - val_loss: 0.3262 - val_acc: 0.8929\n",
            "Epoch 1780/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1908 - acc: 0.9265 - val_loss: 0.3309 - val_acc: 0.8922\n",
            "Epoch 1781/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1901 - acc: 0.9267 - val_loss: 0.2928 - val_acc: 0.9021\n",
            "Epoch 1782/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9267 - val_loss: 0.3481 - val_acc: 0.8921\n",
            "Epoch 1783/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9264 - val_loss: 0.3319 - val_acc: 0.8920\n",
            "Epoch 1784/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1911 - acc: 0.9262 - val_loss: 0.2930 - val_acc: 0.8968\n",
            "Epoch 1785/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1904 - acc: 0.9266 - val_loss: 0.3284 - val_acc: 0.8934\n",
            "Epoch 1786/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9265 - val_loss: 0.3109 - val_acc: 0.8986\n",
            "Epoch 1787/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9265 - val_loss: 0.3389 - val_acc: 0.8905\n",
            "Epoch 1788/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1914 - acc: 0.9259 - val_loss: 0.3452 - val_acc: 0.8889\n",
            "Epoch 1789/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9264 - val_loss: 0.3312 - val_acc: 0.8934\n",
            "Epoch 1790/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9261 - val_loss: 0.3535 - val_acc: 0.8876\n",
            "Epoch 1791/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9264 - val_loss: 0.3356 - val_acc: 0.8909\n",
            "Epoch 1792/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1907 - acc: 0.9262 - val_loss: 0.3390 - val_acc: 0.8895\n",
            "Epoch 1793/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1904 - acc: 0.9263 - val_loss: 0.3149 - val_acc: 0.8968\n",
            "Epoch 1794/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9262 - val_loss: 0.3362 - val_acc: 0.8913\n",
            "Epoch 1795/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9264 - val_loss: 0.3067 - val_acc: 0.8956\n",
            "Epoch 1796/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1907 - acc: 0.9264 - val_loss: 0.3689 - val_acc: 0.8840\n",
            "Epoch 1797/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1907 - acc: 0.9266 - val_loss: 0.3723 - val_acc: 0.8831\n",
            "Epoch 1798/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1904 - acc: 0.9266 - val_loss: 0.3107 - val_acc: 0.8972\n",
            "Epoch 1799/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9265 - val_loss: 0.3120 - val_acc: 0.8966\n",
            "Epoch 1800/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1906 - acc: 0.9265 - val_loss: 0.3675 - val_acc: 0.8842\n",
            "Epoch 1801/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9261 - val_loss: 0.2862 - val_acc: 0.9027\n",
            "Epoch 1802/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1904 - acc: 0.9265 - val_loss: 0.4127 - val_acc: 0.8833\n",
            "Epoch 1803/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1901 - acc: 0.9265 - val_loss: 0.3508 - val_acc: 0.8880\n",
            "Epoch 1804/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1902 - acc: 0.9268 - val_loss: 0.3731 - val_acc: 0.8830\n",
            "Epoch 1805/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1900 - acc: 0.9266 - val_loss: 0.3342 - val_acc: 0.8902\n",
            "Epoch 1806/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9266 - val_loss: 0.3476 - val_acc: 0.8907\n",
            "Epoch 1807/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9268 - val_loss: 0.3131 - val_acc: 0.8940\n",
            "Epoch 1808/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1910 - acc: 0.9262 - val_loss: 0.3318 - val_acc: 0.8931\n",
            "Epoch 1809/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9262 - val_loss: 0.3115 - val_acc: 0.8954\n",
            "Epoch 1810/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1906 - acc: 0.9266 - val_loss: 0.3245 - val_acc: 0.8923\n",
            "Epoch 1811/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1904 - acc: 0.9267 - val_loss: 0.3284 - val_acc: 0.8922\n",
            "Epoch 1812/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1904 - acc: 0.9266 - val_loss: 0.3533 - val_acc: 0.8868\n",
            "Epoch 1813/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1898 - acc: 0.9268 - val_loss: 0.3379 - val_acc: 0.8942\n",
            "Epoch 1814/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9264 - val_loss: 0.3273 - val_acc: 0.8938\n",
            "Epoch 1815/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1908 - acc: 0.9266 - val_loss: 0.2963 - val_acc: 0.8982\n",
            "Epoch 1816/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9264 - val_loss: 0.3314 - val_acc: 0.8916\n",
            "Epoch 1817/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1907 - acc: 0.9266 - val_loss: 0.3111 - val_acc: 0.8954\n",
            "Epoch 1818/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1904 - acc: 0.9266 - val_loss: 0.2948 - val_acc: 0.8986\n",
            "Epoch 1819/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1904 - acc: 0.9266 - val_loss: 0.3722 - val_acc: 0.8875\n",
            "Epoch 1820/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1905 - acc: 0.9264 - val_loss: 0.3674 - val_acc: 0.8864\n",
            "Epoch 1821/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9262 - val_loss: 0.3467 - val_acc: 0.8905\n",
            "Epoch 1822/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1908 - acc: 0.9265 - val_loss: 0.3609 - val_acc: 0.8878\n",
            "Epoch 1823/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1906 - acc: 0.9262 - val_loss: 0.3124 - val_acc: 0.8927\n",
            "Epoch 1824/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1912 - acc: 0.9265 - val_loss: 0.3312 - val_acc: 0.8910\n",
            "Epoch 1825/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9263 - val_loss: 0.3628 - val_acc: 0.8863\n",
            "Epoch 1826/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1907 - acc: 0.9262 - val_loss: 0.3588 - val_acc: 0.8888\n",
            "Epoch 1827/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1905 - acc: 0.9262 - val_loss: 0.3170 - val_acc: 0.8959\n",
            "Epoch 1828/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1908 - acc: 0.9267 - val_loss: 0.3089 - val_acc: 0.8963\n",
            "Epoch 1829/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1903 - acc: 0.9266 - val_loss: 0.3426 - val_acc: 0.8899\n",
            "Epoch 1830/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1914 - acc: 0.9261 - val_loss: 0.3133 - val_acc: 0.8937\n",
            "Epoch 1831/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1904 - acc: 0.9267 - val_loss: 0.3507 - val_acc: 0.8901\n",
            "Epoch 1832/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9265 - val_loss: 0.3104 - val_acc: 0.8985\n",
            "Epoch 1833/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1903 - acc: 0.9264 - val_loss: 0.3706 - val_acc: 0.8853\n",
            "Epoch 1834/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1907 - acc: 0.9263 - val_loss: 0.3434 - val_acc: 0.8916\n",
            "Epoch 1835/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1909 - acc: 0.9264 - val_loss: 0.3538 - val_acc: 0.8883\n",
            "Epoch 1836/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9267 - val_loss: 0.3057 - val_acc: 0.8968\n",
            "Epoch 1837/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1901 - acc: 0.9264 - val_loss: 0.3160 - val_acc: 0.8943\n",
            "Epoch 1838/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9261 - val_loss: 0.3620 - val_acc: 0.8900\n",
            "Epoch 1839/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9265 - val_loss: 0.3565 - val_acc: 0.8858\n",
            "Epoch 1840/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1905 - acc: 0.9265 - val_loss: 0.3533 - val_acc: 0.8888\n",
            "Epoch 1841/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1900 - acc: 0.9267 - val_loss: 0.3310 - val_acc: 0.8928\n",
            "Epoch 1842/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1897 - acc: 0.9266 - val_loss: 0.3021 - val_acc: 0.8983\n",
            "Epoch 1843/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1898 - acc: 0.9271 - val_loss: 0.3378 - val_acc: 0.8908\n",
            "Epoch 1844/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1906 - acc: 0.9265 - val_loss: 0.3030 - val_acc: 0.8984\n",
            "Epoch 1845/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1902 - acc: 0.9265 - val_loss: 0.3131 - val_acc: 0.8967\n",
            "Epoch 1846/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1909 - acc: 0.9262 - val_loss: 0.3107 - val_acc: 0.8987\n",
            "Epoch 1847/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1904 - acc: 0.9263 - val_loss: 0.3464 - val_acc: 0.8909\n",
            "Epoch 1848/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1912 - acc: 0.9258 - val_loss: 0.3279 - val_acc: 0.8939\n",
            "Epoch 1849/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1909 - acc: 0.9261 - val_loss: 0.3425 - val_acc: 0.8940\n",
            "Epoch 1850/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1904 - acc: 0.9266 - val_loss: 0.2994 - val_acc: 0.8985\n",
            "Epoch 1851/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1901 - acc: 0.9264 - val_loss: 0.3177 - val_acc: 0.8953\n",
            "Epoch 1852/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1900 - acc: 0.9269 - val_loss: 0.3740 - val_acc: 0.8837\n",
            "Epoch 1853/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9268 - val_loss: 0.3522 - val_acc: 0.8914\n",
            "Epoch 1854/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1898 - acc: 0.9266 - val_loss: 0.3808 - val_acc: 0.8840\n",
            "Epoch 1855/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1904 - acc: 0.9266 - val_loss: 0.3146 - val_acc: 0.8949\n",
            "Epoch 1856/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1898 - acc: 0.9270 - val_loss: 0.3773 - val_acc: 0.8859\n",
            "Epoch 1857/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1899 - acc: 0.9268 - val_loss: 0.3379 - val_acc: 0.8897\n",
            "Epoch 1858/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1895 - acc: 0.9269 - val_loss: 0.3254 - val_acc: 0.8936\n",
            "Epoch 1859/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1909 - acc: 0.9266 - val_loss: 0.3100 - val_acc: 0.8971\n",
            "Epoch 1860/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1902 - acc: 0.9267 - val_loss: 0.3359 - val_acc: 0.8928\n",
            "Epoch 1861/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1905 - acc: 0.9264 - val_loss: 0.3324 - val_acc: 0.8930\n",
            "Epoch 1862/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1905 - acc: 0.9264 - val_loss: 0.3335 - val_acc: 0.8916\n",
            "Epoch 1863/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1904 - acc: 0.9262 - val_loss: 0.3215 - val_acc: 0.8938\n",
            "Epoch 1864/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1908 - acc: 0.9261 - val_loss: 0.3341 - val_acc: 0.8943\n",
            "Epoch 1865/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1899 - acc: 0.9266 - val_loss: 0.3309 - val_acc: 0.8882\n",
            "Epoch 1866/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1905 - acc: 0.9263 - val_loss: 0.3593 - val_acc: 0.8888\n",
            "Epoch 1867/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1907 - acc: 0.9263 - val_loss: 0.2954 - val_acc: 0.9003\n",
            "Epoch 1868/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1904 - acc: 0.9267 - val_loss: 0.3625 - val_acc: 0.8890\n",
            "Epoch 1869/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1902 - acc: 0.9267 - val_loss: 0.2986 - val_acc: 0.9017\n",
            "Epoch 1870/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1910 - acc: 0.9262 - val_loss: 0.3353 - val_acc: 0.8913\n",
            "Epoch 1871/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1903 - acc: 0.9264 - val_loss: 0.3509 - val_acc: 0.8881\n",
            "Epoch 1872/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1909 - acc: 0.9266 - val_loss: 0.3309 - val_acc: 0.8908\n",
            "Epoch 1873/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1902 - acc: 0.9264 - val_loss: 0.3453 - val_acc: 0.8886\n",
            "Epoch 1874/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1899 - acc: 0.9267 - val_loss: 0.3100 - val_acc: 0.8937\n",
            "Epoch 1875/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1907 - acc: 0.9266 - val_loss: 0.3354 - val_acc: 0.8920\n",
            "Epoch 1876/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1900 - acc: 0.9267 - val_loss: 0.3503 - val_acc: 0.8855\n",
            "Epoch 1877/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9266 - val_loss: 0.3227 - val_acc: 0.8945\n",
            "Epoch 1878/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1904 - acc: 0.9263 - val_loss: 0.3797 - val_acc: 0.8851\n",
            "Epoch 1879/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9266 - val_loss: 0.3096 - val_acc: 0.8987\n",
            "Epoch 1880/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1895 - acc: 0.9266 - val_loss: 0.4111 - val_acc: 0.8796\n",
            "Epoch 1881/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1908 - acc: 0.9264 - val_loss: 0.3694 - val_acc: 0.8893\n",
            "Epoch 1882/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1900 - acc: 0.9268 - val_loss: 0.3607 - val_acc: 0.8853\n",
            "Epoch 1883/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1908 - acc: 0.9263 - val_loss: 0.3531 - val_acc: 0.8888\n",
            "Epoch 1884/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1906 - acc: 0.9266 - val_loss: 0.3327 - val_acc: 0.8941\n",
            "Epoch 1885/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9261 - val_loss: 0.3500 - val_acc: 0.8880\n",
            "Epoch 1886/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1902 - acc: 0.9265 - val_loss: 0.3959 - val_acc: 0.8833\n",
            "Epoch 1887/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1907 - acc: 0.9263 - val_loss: 0.3765 - val_acc: 0.8861\n",
            "Epoch 1888/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1906 - acc: 0.9266 - val_loss: 0.3406 - val_acc: 0.8918\n",
            "Epoch 1889/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1909 - acc: 0.9262 - val_loss: 0.3444 - val_acc: 0.8895\n",
            "Epoch 1890/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1907 - acc: 0.9263 - val_loss: 0.3570 - val_acc: 0.8879\n",
            "Epoch 1891/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1907 - acc: 0.9263 - val_loss: 0.3345 - val_acc: 0.8935\n",
            "Epoch 1892/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1898 - acc: 0.9267 - val_loss: 0.3414 - val_acc: 0.8874\n",
            "Epoch 1893/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1905 - acc: 0.9265 - val_loss: 0.3092 - val_acc: 0.8987\n",
            "Epoch 1894/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9268 - val_loss: 0.3104 - val_acc: 0.8974\n",
            "Epoch 1895/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1908 - acc: 0.9262 - val_loss: 0.3276 - val_acc: 0.8927\n",
            "Epoch 1896/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1908 - acc: 0.9265 - val_loss: 0.3519 - val_acc: 0.8892\n",
            "Epoch 1897/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9265 - val_loss: 0.3902 - val_acc: 0.8801\n",
            "Epoch 1898/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1900 - acc: 0.9266 - val_loss: 0.3333 - val_acc: 0.8895\n",
            "Epoch 1899/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1905 - acc: 0.9262 - val_loss: 0.3790 - val_acc: 0.8854\n",
            "Epoch 1900/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1901 - acc: 0.9267 - val_loss: 0.3629 - val_acc: 0.8878\n",
            "Epoch 1901/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1904 - acc: 0.9266 - val_loss: 0.3332 - val_acc: 0.8961\n",
            "Epoch 1902/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9264 - val_loss: 0.3417 - val_acc: 0.8921\n",
            "Epoch 1903/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1905 - acc: 0.9266 - val_loss: 0.3595 - val_acc: 0.8891\n",
            "Epoch 1904/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9266 - val_loss: 0.3215 - val_acc: 0.8959\n",
            "Epoch 1905/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9262 - val_loss: 0.3178 - val_acc: 0.8935\n",
            "Epoch 1906/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9264 - val_loss: 0.3024 - val_acc: 0.8979\n",
            "Epoch 1907/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1899 - acc: 0.9267 - val_loss: 0.3082 - val_acc: 0.8974\n",
            "Epoch 1908/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9263 - val_loss: 0.2959 - val_acc: 0.9016\n",
            "Epoch 1909/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1904 - acc: 0.9268 - val_loss: 0.3315 - val_acc: 0.8941\n",
            "Epoch 1910/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1899 - acc: 0.9266 - val_loss: 0.3414 - val_acc: 0.8931\n",
            "Epoch 1911/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1902 - acc: 0.9267 - val_loss: 0.3480 - val_acc: 0.8899\n",
            "Epoch 1912/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1899 - acc: 0.9268 - val_loss: 0.3968 - val_acc: 0.8835\n",
            "Epoch 1913/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1898 - acc: 0.9265 - val_loss: 0.3381 - val_acc: 0.8910\n",
            "Epoch 1914/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1902 - acc: 0.9265 - val_loss: 0.3085 - val_acc: 0.8962\n",
            "Epoch 1915/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1907 - acc: 0.9263 - val_loss: 0.3305 - val_acc: 0.8912\n",
            "Epoch 1916/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1906 - acc: 0.9263 - val_loss: 0.3572 - val_acc: 0.8874\n",
            "Epoch 1917/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1899 - acc: 0.9268 - val_loss: 0.3689 - val_acc: 0.8869\n",
            "Epoch 1918/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1903 - acc: 0.9265 - val_loss: 0.3491 - val_acc: 0.8901\n",
            "Epoch 1919/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9266 - val_loss: 0.3419 - val_acc: 0.8933\n",
            "Epoch 1920/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1902 - acc: 0.9265 - val_loss: 0.2970 - val_acc: 0.8991\n",
            "Epoch 1921/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1906 - acc: 0.9264 - val_loss: 0.3176 - val_acc: 0.8972\n",
            "Epoch 1922/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9264 - val_loss: 0.3863 - val_acc: 0.8841\n",
            "Epoch 1923/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1899 - acc: 0.9268 - val_loss: 0.2860 - val_acc: 0.9003\n",
            "Epoch 1924/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1901 - acc: 0.9270 - val_loss: 0.3047 - val_acc: 0.8958\n",
            "Epoch 1925/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1903 - acc: 0.9266 - val_loss: 0.3672 - val_acc: 0.8843\n",
            "Epoch 1926/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1901 - acc: 0.9265 - val_loss: 0.3232 - val_acc: 0.8957\n",
            "Epoch 1927/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1898 - acc: 0.9269 - val_loss: 0.3338 - val_acc: 0.8910\n",
            "Epoch 1928/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1904 - acc: 0.9264 - val_loss: 0.3313 - val_acc: 0.8917\n",
            "Epoch 1929/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1903 - acc: 0.9266 - val_loss: 0.3356 - val_acc: 0.8916\n",
            "Epoch 1930/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1900 - acc: 0.9266 - val_loss: 0.3602 - val_acc: 0.8853\n",
            "Epoch 1931/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1900 - acc: 0.9267 - val_loss: 0.3597 - val_acc: 0.8873\n",
            "Epoch 1932/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1904 - acc: 0.9263 - val_loss: 0.3910 - val_acc: 0.8828\n",
            "Epoch 1933/6000\n",
            "584288/584288 [==============================] - 17s 29us/step - loss: 0.1897 - acc: 0.9266 - val_loss: 0.3106 - val_acc: 0.8978\n",
            "Epoch 1934/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1906 - acc: 0.9264 - val_loss: 0.3139 - val_acc: 0.8961\n",
            "Epoch 1935/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1894 - acc: 0.9268 - val_loss: 0.3623 - val_acc: 0.8848\n",
            "Epoch 1936/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9261 - val_loss: 0.3150 - val_acc: 0.8976\n",
            "Epoch 1937/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1896 - acc: 0.9267 - val_loss: 0.3309 - val_acc: 0.8937\n",
            "Epoch 1938/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1901 - acc: 0.9268 - val_loss: 0.3309 - val_acc: 0.8963\n",
            "Epoch 1939/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1897 - acc: 0.9268 - val_loss: 0.3491 - val_acc: 0.8870\n",
            "Epoch 1940/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1904 - acc: 0.9262 - val_loss: 0.3313 - val_acc: 0.8913\n",
            "Epoch 1941/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1900 - acc: 0.9268 - val_loss: 0.3197 - val_acc: 0.8938\n",
            "Epoch 1942/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1903 - acc: 0.9264 - val_loss: 0.3452 - val_acc: 0.8878\n",
            "Epoch 1943/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1909 - acc: 0.9262 - val_loss: 0.3047 - val_acc: 0.8943\n",
            "Epoch 1944/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1899 - acc: 0.9267 - val_loss: 0.3838 - val_acc: 0.8837\n",
            "Epoch 1945/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1899 - acc: 0.9269 - val_loss: 0.2944 - val_acc: 0.8998\n",
            "Epoch 1946/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1909 - acc: 0.9265 - val_loss: 0.3473 - val_acc: 0.8874\n",
            "Epoch 1947/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1902 - acc: 0.9265 - val_loss: 0.4108 - val_acc: 0.8784\n",
            "Epoch 1948/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1893 - acc: 0.9267 - val_loss: 0.3197 - val_acc: 0.8948\n",
            "Epoch 1949/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1901 - acc: 0.9266 - val_loss: 0.3263 - val_acc: 0.8942\n",
            "Epoch 1950/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1893 - acc: 0.9271 - val_loss: 0.3736 - val_acc: 0.8847\n",
            "Epoch 1951/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1914 - acc: 0.9262 - val_loss: 0.4025 - val_acc: 0.8769\n",
            "Epoch 1952/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9265 - val_loss: 0.3166 - val_acc: 0.8903\n",
            "Epoch 1953/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1902 - acc: 0.9267 - val_loss: 0.2951 - val_acc: 0.8980\n",
            "Epoch 1954/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1902 - acc: 0.9265 - val_loss: 0.3423 - val_acc: 0.8917\n",
            "Epoch 1955/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9262 - val_loss: 0.3253 - val_acc: 0.8905\n",
            "Epoch 1956/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1898 - acc: 0.9267 - val_loss: 0.3557 - val_acc: 0.8869\n",
            "Epoch 1957/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1899 - acc: 0.9265 - val_loss: 0.3186 - val_acc: 0.8942\n",
            "Epoch 1958/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1903 - acc: 0.9262 - val_loss: 0.3266 - val_acc: 0.8914\n",
            "Epoch 1959/6000\n",
            "584288/584288 [==============================] - 19s 33us/step - loss: 0.1906 - acc: 0.9265 - val_loss: 0.3554 - val_acc: 0.8882\n",
            "Epoch 1960/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1895 - acc: 0.9271 - val_loss: 0.2977 - val_acc: 0.8939\n",
            "Epoch 1961/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9264 - val_loss: 0.2884 - val_acc: 0.8987\n",
            "Epoch 1962/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1908 - acc: 0.9265 - val_loss: 0.4040 - val_acc: 0.8784\n",
            "Epoch 1963/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1904 - acc: 0.9264 - val_loss: 0.3152 - val_acc: 0.8963\n",
            "Epoch 1964/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1901 - acc: 0.9265 - val_loss: 0.3013 - val_acc: 0.8999\n",
            "Epoch 1965/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9268 - val_loss: 0.3592 - val_acc: 0.8897\n",
            "Epoch 1966/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1900 - acc: 0.9265 - val_loss: 0.2974 - val_acc: 0.8984\n",
            "Epoch 1967/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9264 - val_loss: 0.3113 - val_acc: 0.8974\n",
            "Epoch 1968/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1904 - acc: 0.9264 - val_loss: 0.3980 - val_acc: 0.8836\n",
            "Epoch 1969/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1899 - acc: 0.9267 - val_loss: 0.3500 - val_acc: 0.8873\n",
            "Epoch 1970/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1904 - acc: 0.9267 - val_loss: 0.3175 - val_acc: 0.8964\n",
            "Epoch 1971/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9263 - val_loss: 0.3264 - val_acc: 0.8889\n",
            "Epoch 1972/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1907 - acc: 0.9261 - val_loss: 0.3311 - val_acc: 0.8934\n",
            "Epoch 1973/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1898 - acc: 0.9267 - val_loss: 0.3196 - val_acc: 0.8944\n",
            "Epoch 1974/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1906 - acc: 0.9264 - val_loss: 0.3290 - val_acc: 0.8935\n",
            "Epoch 1975/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1895 - acc: 0.9271 - val_loss: 0.3236 - val_acc: 0.8936\n",
            "Epoch 1976/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1904 - acc: 0.9267 - val_loss: 0.3174 - val_acc: 0.8952\n",
            "Epoch 1977/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1901 - acc: 0.9265 - val_loss: 0.3323 - val_acc: 0.8935\n",
            "Epoch 1978/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9266 - val_loss: 0.3237 - val_acc: 0.8937\n",
            "Epoch 1979/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9265 - val_loss: 0.3398 - val_acc: 0.8906\n",
            "Epoch 1980/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1904 - acc: 0.9267 - val_loss: 0.3121 - val_acc: 0.8970\n",
            "Epoch 1981/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1902 - acc: 0.9267 - val_loss: 0.3237 - val_acc: 0.8956\n",
            "Epoch 1982/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1899 - acc: 0.9267 - val_loss: 0.2928 - val_acc: 0.8975\n",
            "Epoch 1983/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1895 - acc: 0.9272 - val_loss: 0.2980 - val_acc: 0.9003\n",
            "Epoch 1984/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1899 - acc: 0.9264 - val_loss: 0.3176 - val_acc: 0.8956\n",
            "Epoch 1985/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1907 - acc: 0.9263 - val_loss: 0.3710 - val_acc: 0.8859\n",
            "Epoch 1986/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1908 - acc: 0.9263 - val_loss: 0.3152 - val_acc: 0.8957\n",
            "Epoch 1987/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1898 - acc: 0.9269 - val_loss: 0.3050 - val_acc: 0.8987\n",
            "Epoch 1988/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1896 - acc: 0.9268 - val_loss: 0.3469 - val_acc: 0.8888\n",
            "Epoch 1989/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9265 - val_loss: 0.3201 - val_acc: 0.8953\n",
            "Epoch 1990/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9264 - val_loss: 0.3010 - val_acc: 0.8988\n",
            "Epoch 1991/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1902 - acc: 0.9267 - val_loss: 0.3569 - val_acc: 0.8884\n",
            "Epoch 1992/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1898 - acc: 0.9266 - val_loss: 0.3765 - val_acc: 0.8827\n",
            "Epoch 1993/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1900 - acc: 0.9264 - val_loss: 0.3422 - val_acc: 0.8888\n",
            "Epoch 1994/6000\n",
            "584288/584288 [==============================] - 18s 32us/step - loss: 0.1898 - acc: 0.9266 - val_loss: 0.3366 - val_acc: 0.8959\n",
            "Epoch 1995/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1906 - acc: 0.9262 - val_loss: 0.3683 - val_acc: 0.8864\n",
            "Epoch 1996/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1904 - acc: 0.9261 - val_loss: 0.3342 - val_acc: 0.8927\n",
            "Epoch 1997/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1898 - acc: 0.9266 - val_loss: 0.4117 - val_acc: 0.8778\n",
            "Epoch 1998/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1895 - acc: 0.9266 - val_loss: 0.3533 - val_acc: 0.8886\n",
            "Epoch 1999/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9268 - val_loss: 0.3340 - val_acc: 0.8920\n",
            "Epoch 2000/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1902 - acc: 0.9265 - val_loss: 0.3593 - val_acc: 0.8863\n",
            "Epoch 2001/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1897 - acc: 0.9265 - val_loss: 0.3540 - val_acc: 0.8882\n",
            "Epoch 2002/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9266 - val_loss: 0.3267 - val_acc: 0.8932\n",
            "Epoch 2003/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1907 - acc: 0.9266 - val_loss: 0.3197 - val_acc: 0.8949\n",
            "Epoch 2004/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9267 - val_loss: 0.3558 - val_acc: 0.8884\n",
            "Epoch 2005/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1906 - acc: 0.9264 - val_loss: 0.3841 - val_acc: 0.8868\n",
            "Epoch 2006/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9269 - val_loss: 0.3182 - val_acc: 0.8947\n",
            "Epoch 2007/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1896 - acc: 0.9267 - val_loss: 0.3301 - val_acc: 0.8906\n",
            "Epoch 2008/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1898 - acc: 0.9268 - val_loss: 0.3377 - val_acc: 0.8939\n",
            "Epoch 2009/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1899 - acc: 0.9267 - val_loss: 0.3317 - val_acc: 0.8931\n",
            "Epoch 2010/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1895 - acc: 0.9268 - val_loss: 0.3584 - val_acc: 0.8881\n",
            "Epoch 2011/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9267 - val_loss: 0.3394 - val_acc: 0.8930\n",
            "Epoch 2012/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1895 - acc: 0.9268 - val_loss: 0.3674 - val_acc: 0.8866\n",
            "Epoch 2013/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9266 - val_loss: 0.3758 - val_acc: 0.8872\n",
            "Epoch 2014/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1898 - acc: 0.9268 - val_loss: 0.3052 - val_acc: 0.9009\n",
            "Epoch 2015/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1899 - acc: 0.9268 - val_loss: 0.3678 - val_acc: 0.8871\n",
            "Epoch 2016/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1897 - acc: 0.9269 - val_loss: 0.3323 - val_acc: 0.8943\n",
            "Epoch 2017/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1902 - acc: 0.9266 - val_loss: 0.3251 - val_acc: 0.8886\n",
            "Epoch 2018/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1897 - acc: 0.9265 - val_loss: 0.3413 - val_acc: 0.8931\n",
            "Epoch 2019/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1894 - acc: 0.9268 - val_loss: 0.3301 - val_acc: 0.8930\n",
            "Epoch 2020/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1903 - acc: 0.9264 - val_loss: 0.3182 - val_acc: 0.8977\n",
            "Epoch 2021/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1900 - acc: 0.9266 - val_loss: 0.3417 - val_acc: 0.8909\n",
            "Epoch 2022/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1897 - acc: 0.9268 - val_loss: 0.3317 - val_acc: 0.8917\n",
            "Epoch 2023/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9267 - val_loss: 0.3253 - val_acc: 0.8957\n",
            "Epoch 2024/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1900 - acc: 0.9268 - val_loss: 0.3354 - val_acc: 0.8931\n",
            "Epoch 2025/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1902 - acc: 0.9266 - val_loss: 0.3630 - val_acc: 0.8856\n",
            "Epoch 2026/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9267 - val_loss: 0.3387 - val_acc: 0.8918\n",
            "Epoch 2027/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1899 - acc: 0.9270 - val_loss: 0.4039 - val_acc: 0.8817\n",
            "Epoch 2028/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1894 - acc: 0.9268 - val_loss: 0.3159 - val_acc: 0.8949\n",
            "Epoch 2029/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1905 - acc: 0.9263 - val_loss: 0.3123 - val_acc: 0.8935\n",
            "Epoch 2030/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1899 - acc: 0.9264 - val_loss: 0.3355 - val_acc: 0.8919\n",
            "Epoch 2031/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1890 - acc: 0.9268 - val_loss: 0.3092 - val_acc: 0.8982\n",
            "Epoch 2032/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1896 - acc: 0.9269 - val_loss: 0.3633 - val_acc: 0.8850\n",
            "Epoch 2033/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1900 - acc: 0.9266 - val_loss: 0.3597 - val_acc: 0.8902\n",
            "Epoch 2034/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9267 - val_loss: 0.2999 - val_acc: 0.8981\n",
            "Epoch 2035/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1896 - acc: 0.9266 - val_loss: 0.3040 - val_acc: 0.8999\n",
            "Epoch 2036/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1899 - acc: 0.9266 - val_loss: 0.3571 - val_acc: 0.8873\n",
            "Epoch 2037/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1899 - acc: 0.9265 - val_loss: 0.3219 - val_acc: 0.8966\n",
            "Epoch 2038/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1899 - acc: 0.9264 - val_loss: 0.3102 - val_acc: 0.8947\n",
            "Epoch 2039/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1905 - acc: 0.9263 - val_loss: 0.3018 - val_acc: 0.8979\n",
            "Epoch 2040/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1896 - acc: 0.9267 - val_loss: 0.3105 - val_acc: 0.8964\n",
            "Epoch 2041/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1896 - acc: 0.9267 - val_loss: 0.3353 - val_acc: 0.8924\n",
            "Epoch 2042/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1902 - acc: 0.9262 - val_loss: 0.3198 - val_acc: 0.8967\n",
            "Epoch 2043/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1899 - acc: 0.9266 - val_loss: 0.3235 - val_acc: 0.8904\n",
            "Epoch 2044/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1903 - acc: 0.9268 - val_loss: 0.3483 - val_acc: 0.8907\n",
            "Epoch 2045/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1899 - acc: 0.9266 - val_loss: 0.3433 - val_acc: 0.8912\n",
            "Epoch 2046/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9266 - val_loss: 0.3753 - val_acc: 0.8881\n",
            "Epoch 2047/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1902 - acc: 0.9263 - val_loss: 0.3730 - val_acc: 0.8860\n",
            "Epoch 2048/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1901 - acc: 0.9264 - val_loss: 0.3118 - val_acc: 0.8974\n",
            "Epoch 2049/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9266 - val_loss: 0.3366 - val_acc: 0.8927\n",
            "Epoch 2050/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1898 - acc: 0.9266 - val_loss: 0.3114 - val_acc: 0.8961\n",
            "Epoch 2051/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1891 - acc: 0.9269 - val_loss: 0.3552 - val_acc: 0.8866\n",
            "Epoch 2052/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1903 - acc: 0.9267 - val_loss: 0.3603 - val_acc: 0.8882\n",
            "Epoch 2053/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1902 - acc: 0.9266 - val_loss: 0.3111 - val_acc: 0.8971\n",
            "Epoch 2054/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1905 - acc: 0.9267 - val_loss: 0.3344 - val_acc: 0.8915\n",
            "Epoch 2055/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1907 - acc: 0.9263 - val_loss: 0.3803 - val_acc: 0.8870\n",
            "Epoch 2056/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1896 - acc: 0.9268 - val_loss: 0.3455 - val_acc: 0.8874\n",
            "Epoch 2057/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1895 - acc: 0.9268 - val_loss: 0.3378 - val_acc: 0.8947\n",
            "Epoch 2058/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1904 - acc: 0.9264 - val_loss: 0.3205 - val_acc: 0.8900\n",
            "Epoch 2059/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1902 - acc: 0.9264 - val_loss: 0.3330 - val_acc: 0.8936\n",
            "Epoch 2060/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1895 - acc: 0.9268 - val_loss: 0.3655 - val_acc: 0.8866\n",
            "Epoch 2061/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1893 - acc: 0.9267 - val_loss: 0.3384 - val_acc: 0.8903\n",
            "Epoch 2062/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9265 - val_loss: 0.3341 - val_acc: 0.8925\n",
            "Epoch 2063/6000\n",
            "584288/584288 [==============================] - 17s 30us/step - loss: 0.1902 - acc: 0.9263 - val_loss: 0.3528 - val_acc: 0.8912\n",
            "Epoch 2064/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1899 - acc: 0.9264 - val_loss: 0.3220 - val_acc: 0.8947\n",
            "Epoch 2065/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9268 - val_loss: 0.2911 - val_acc: 0.8980\n",
            "Epoch 2066/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1899 - acc: 0.9265 - val_loss: 0.3463 - val_acc: 0.8893\n",
            "Epoch 2067/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1898 - acc: 0.9266 - val_loss: 0.3135 - val_acc: 0.8967\n",
            "Epoch 2068/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1895 - acc: 0.9272 - val_loss: 0.3380 - val_acc: 0.8932\n",
            "Epoch 2069/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1897 - acc: 0.9266 - val_loss: 0.3405 - val_acc: 0.8915\n",
            "Epoch 2070/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9265 - val_loss: 0.3291 - val_acc: 0.8923\n",
            "Epoch 2071/6000\n",
            "584288/584288 [==============================] - 20s 34us/step - loss: 0.1904 - acc: 0.9266 - val_loss: 0.3236 - val_acc: 0.8932\n",
            "Epoch 2072/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1903 - acc: 0.9263 - val_loss: 0.4093 - val_acc: 0.8783\n",
            "Epoch 2073/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1898 - acc: 0.9263 - val_loss: 0.3405 - val_acc: 0.8908\n",
            "Epoch 2074/6000\n",
            "584288/584288 [==============================] - 24s 41us/step - loss: 0.1897 - acc: 0.9268 - val_loss: 0.3923 - val_acc: 0.8821\n",
            "Epoch 2075/6000\n",
            "584288/584288 [==============================] - 20s 34us/step - loss: 0.1897 - acc: 0.9268 - val_loss: 0.3735 - val_acc: 0.8892\n",
            "Epoch 2076/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9267 - val_loss: 0.3140 - val_acc: 0.8969\n",
            "Epoch 2077/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1898 - acc: 0.9266 - val_loss: 0.3272 - val_acc: 0.8931\n",
            "Epoch 2078/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1895 - acc: 0.9270 - val_loss: 0.3375 - val_acc: 0.8906\n",
            "Epoch 2079/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1899 - acc: 0.9267 - val_loss: 0.3053 - val_acc: 0.8988\n",
            "Epoch 2080/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1896 - acc: 0.9267 - val_loss: 0.3180 - val_acc: 0.8970\n",
            "Epoch 2081/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1899 - acc: 0.9266 - val_loss: 0.3006 - val_acc: 0.8990\n",
            "Epoch 2082/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1898 - acc: 0.9270 - val_loss: 0.3579 - val_acc: 0.8872\n",
            "Epoch 2083/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1900 - acc: 0.9267 - val_loss: 0.3176 - val_acc: 0.8966\n",
            "Epoch 2084/6000\n",
            "584288/584288 [==============================] - 22s 38us/step - loss: 0.1895 - acc: 0.9270 - val_loss: 0.3088 - val_acc: 0.8985\n",
            "Epoch 2085/6000\n",
            "584288/584288 [==============================] - 28s 47us/step - loss: 0.1902 - acc: 0.9266 - val_loss: 0.3362 - val_acc: 0.8926\n",
            "Epoch 2086/6000\n",
            "584288/584288 [==============================] - 28s 47us/step - loss: 0.1895 - acc: 0.9267 - val_loss: 0.3390 - val_acc: 0.8938\n",
            "Epoch 2087/6000\n",
            "584288/584288 [==============================] - 29s 49us/step - loss: 0.1895 - acc: 0.9266 - val_loss: 0.3604 - val_acc: 0.8858\n",
            "Epoch 2088/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1893 - acc: 0.9271 - val_loss: 0.3261 - val_acc: 0.8944\n",
            "Epoch 2089/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1894 - acc: 0.9270 - val_loss: 0.3435 - val_acc: 0.8933\n",
            "Epoch 2090/6000\n",
            "584288/584288 [==============================] - 28s 49us/step - loss: 0.1901 - acc: 0.9266 - val_loss: 0.3236 - val_acc: 0.8939\n",
            "Epoch 2091/6000\n",
            "584288/584288 [==============================] - 29s 49us/step - loss: 0.1894 - acc: 0.9266 - val_loss: 0.3484 - val_acc: 0.8921\n",
            "Epoch 2092/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1897 - acc: 0.9268 - val_loss: 0.3263 - val_acc: 0.8923\n",
            "Epoch 2093/6000\n",
            "584288/584288 [==============================] - 29s 49us/step - loss: 0.1893 - acc: 0.9271 - val_loss: 0.3409 - val_acc: 0.8933\n",
            "Epoch 2094/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1905 - acc: 0.9265 - val_loss: 0.3482 - val_acc: 0.8918\n",
            "Epoch 2095/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1896 - acc: 0.9270 - val_loss: 0.3248 - val_acc: 0.8920\n",
            "Epoch 2096/6000\n",
            "584288/584288 [==============================] - 28s 47us/step - loss: 0.1899 - acc: 0.9265 - val_loss: 0.3144 - val_acc: 0.8962\n",
            "Epoch 2097/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1895 - acc: 0.9267 - val_loss: 0.3571 - val_acc: 0.8893\n",
            "Epoch 2098/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1897 - acc: 0.9269 - val_loss: 0.3124 - val_acc: 0.8966\n",
            "Epoch 2099/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1899 - acc: 0.9268 - val_loss: 0.3933 - val_acc: 0.8825\n",
            "Epoch 2100/6000\n",
            "584288/584288 [==============================] - 28s 47us/step - loss: 0.1902 - acc: 0.9268 - val_loss: 0.3665 - val_acc: 0.8836\n",
            "Epoch 2101/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1898 - acc: 0.9267 - val_loss: 0.3830 - val_acc: 0.8830\n",
            "Epoch 2102/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1898 - acc: 0.9267 - val_loss: 0.3515 - val_acc: 0.8895\n",
            "Epoch 2103/6000\n",
            "584288/584288 [==============================] - 28s 47us/step - loss: 0.1899 - acc: 0.9267 - val_loss: 0.3124 - val_acc: 0.8950\n",
            "Epoch 2104/6000\n",
            "584288/584288 [==============================] - 29s 49us/step - loss: 0.1898 - acc: 0.9268 - val_loss: 0.3111 - val_acc: 0.8946\n",
            "Epoch 2105/6000\n",
            "584288/584288 [==============================] - 28s 47us/step - loss: 0.1901 - acc: 0.9266 - val_loss: 0.3855 - val_acc: 0.8820\n",
            "Epoch 2106/6000\n",
            "584288/584288 [==============================] - 28s 49us/step - loss: 0.1898 - acc: 0.9267 - val_loss: 0.3502 - val_acc: 0.8870\n",
            "Epoch 2107/6000\n",
            "584288/584288 [==============================] - 28s 47us/step - loss: 0.1900 - acc: 0.9265 - val_loss: 0.3333 - val_acc: 0.8927\n",
            "Epoch 2108/6000\n",
            "584288/584288 [==============================] - 28s 47us/step - loss: 0.1904 - acc: 0.9265 - val_loss: 0.3995 - val_acc: 0.8810\n",
            "Epoch 2109/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1891 - acc: 0.9269 - val_loss: 0.3668 - val_acc: 0.8862\n",
            "Epoch 2110/6000\n",
            "584288/584288 [==============================] - 27s 46us/step - loss: 0.1900 - acc: 0.9266 - val_loss: 0.3216 - val_acc: 0.8927\n",
            "Epoch 2111/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1898 - acc: 0.9266 - val_loss: 0.3562 - val_acc: 0.8888\n",
            "Epoch 2112/6000\n",
            "584288/584288 [==============================] - 28s 47us/step - loss: 0.1894 - acc: 0.9268 - val_loss: 0.3606 - val_acc: 0.8878\n",
            "Epoch 2113/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1897 - acc: 0.9267 - val_loss: 0.2901 - val_acc: 0.9010\n",
            "Epoch 2114/6000\n",
            "584288/584288 [==============================] - 29s 49us/step - loss: 0.1889 - acc: 0.9268 - val_loss: 0.3193 - val_acc: 0.8977\n",
            "Epoch 2115/6000\n",
            "584288/584288 [==============================] - 30s 52us/step - loss: 0.1896 - acc: 0.9267 - val_loss: 0.3242 - val_acc: 0.8927\n",
            "Epoch 2116/6000\n",
            "584288/584288 [==============================] - 30s 51us/step - loss: 0.1893 - acc: 0.9269 - val_loss: 0.3067 - val_acc: 0.8977\n",
            "Epoch 2117/6000\n",
            "584288/584288 [==============================] - 30s 51us/step - loss: 0.1896 - acc: 0.9266 - val_loss: 0.3208 - val_acc: 0.8922\n",
            "Epoch 2118/6000\n",
            "584288/584288 [==============================] - 30s 51us/step - loss: 0.1901 - acc: 0.9265 - val_loss: 0.3291 - val_acc: 0.8909\n",
            "Epoch 2119/6000\n",
            "584288/584288 [==============================] - 29s 49us/step - loss: 0.1897 - acc: 0.9264 - val_loss: 0.3563 - val_acc: 0.8887\n",
            "Epoch 2120/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1895 - acc: 0.9267 - val_loss: 0.3469 - val_acc: 0.8925\n",
            "Epoch 2121/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1896 - acc: 0.9268 - val_loss: 0.3163 - val_acc: 0.8967\n",
            "Epoch 2122/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1910 - acc: 0.9264 - val_loss: 0.3000 - val_acc: 0.8992\n",
            "Epoch 2123/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1893 - acc: 0.9268 - val_loss: 0.3005 - val_acc: 0.8997\n",
            "Epoch 2124/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1900 - acc: 0.9268 - val_loss: 0.3619 - val_acc: 0.8892\n",
            "Epoch 2125/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1902 - acc: 0.9263 - val_loss: 0.3218 - val_acc: 0.8936\n",
            "Epoch 2126/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1898 - acc: 0.9267 - val_loss: 0.3741 - val_acc: 0.8852\n",
            "Epoch 2127/6000\n",
            "584288/584288 [==============================] - 23s 40us/step - loss: 0.1900 - acc: 0.9265 - val_loss: 0.3008 - val_acc: 0.9000\n",
            "Epoch 2128/6000\n",
            "584288/584288 [==============================] - 24s 40us/step - loss: 0.1893 - acc: 0.9268 - val_loss: 0.3956 - val_acc: 0.8845\n",
            "Epoch 2129/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1897 - acc: 0.9265 - val_loss: 0.3489 - val_acc: 0.8902\n",
            "Epoch 2130/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1895 - acc: 0.9268 - val_loss: 0.2856 - val_acc: 0.9024\n",
            "Epoch 2131/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1897 - acc: 0.9269 - val_loss: 0.3530 - val_acc: 0.8876\n",
            "Epoch 2132/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1896 - acc: 0.9268 - val_loss: 0.3456 - val_acc: 0.8906\n",
            "Epoch 2133/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1897 - acc: 0.9267 - val_loss: 0.2940 - val_acc: 0.8987\n",
            "Epoch 2134/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1894 - acc: 0.9268 - val_loss: 0.3165 - val_acc: 0.8950\n",
            "Epoch 2135/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1895 - acc: 0.9270 - val_loss: 0.3230 - val_acc: 0.8940\n",
            "Epoch 2136/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1895 - acc: 0.9269 - val_loss: 0.3078 - val_acc: 0.8974\n",
            "Epoch 2137/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1898 - acc: 0.9267 - val_loss: 0.3235 - val_acc: 0.8934\n",
            "Epoch 2138/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1894 - acc: 0.9268 - val_loss: 0.3089 - val_acc: 0.8926\n",
            "Epoch 2139/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1900 - acc: 0.9265 - val_loss: 0.2893 - val_acc: 0.9021\n",
            "Epoch 2140/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1895 - acc: 0.9269 - val_loss: 0.3371 - val_acc: 0.8925\n",
            "Epoch 2141/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1903 - acc: 0.9267 - val_loss: 0.3354 - val_acc: 0.8943\n",
            "Epoch 2142/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1891 - acc: 0.9269 - val_loss: 0.3703 - val_acc: 0.8896\n",
            "Epoch 2143/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1899 - acc: 0.9266 - val_loss: 0.3509 - val_acc: 0.8902\n",
            "Epoch 2144/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1897 - acc: 0.9268 - val_loss: 0.3179 - val_acc: 0.8968\n",
            "Epoch 2145/6000\n",
            "584288/584288 [==============================] - 22s 38us/step - loss: 0.1900 - acc: 0.9267 - val_loss: 0.3306 - val_acc: 0.8943\n",
            "Epoch 2146/6000\n",
            "584288/584288 [==============================] - 28s 49us/step - loss: 0.1896 - acc: 0.9267 - val_loss: 0.2962 - val_acc: 0.8966\n",
            "Epoch 2147/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1894 - acc: 0.9268 - val_loss: 0.4002 - val_acc: 0.8818\n",
            "Epoch 2148/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1894 - acc: 0.9268 - val_loss: 0.3368 - val_acc: 0.8909\n",
            "Epoch 2149/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1895 - acc: 0.9268 - val_loss: 0.3672 - val_acc: 0.8867\n",
            "Epoch 2150/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1889 - acc: 0.9273 - val_loss: 0.3310 - val_acc: 0.8916\n",
            "Epoch 2151/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1900 - acc: 0.9266 - val_loss: 0.2973 - val_acc: 0.9002\n",
            "Epoch 2152/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1901 - acc: 0.9265 - val_loss: 0.3389 - val_acc: 0.8930\n",
            "Epoch 2153/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1901 - acc: 0.9268 - val_loss: 0.3237 - val_acc: 0.8926\n",
            "Epoch 2154/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1896 - acc: 0.9268 - val_loss: 0.3425 - val_acc: 0.8914\n",
            "Epoch 2155/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1895 - acc: 0.9268 - val_loss: 0.3447 - val_acc: 0.8922\n",
            "Epoch 2156/6000\n",
            "584288/584288 [==============================] - 27s 46us/step - loss: 0.1894 - acc: 0.9268 - val_loss: 0.3213 - val_acc: 0.8966\n",
            "Epoch 2157/6000\n",
            "584288/584288 [==============================] - 29s 50us/step - loss: 0.1893 - acc: 0.9269 - val_loss: 0.3049 - val_acc: 0.8956\n",
            "Epoch 2158/6000\n",
            "584288/584288 [==============================] - 27s 46us/step - loss: 0.1889 - acc: 0.9269 - val_loss: 0.3749 - val_acc: 0.8869\n",
            "Epoch 2159/6000\n",
            "584288/584288 [==============================] - 28s 47us/step - loss: 0.1895 - acc: 0.9270 - val_loss: 0.3313 - val_acc: 0.8934\n",
            "Epoch 2160/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1902 - acc: 0.9264 - val_loss: 0.3655 - val_acc: 0.8876\n",
            "Epoch 2161/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1895 - acc: 0.9272 - val_loss: 0.3495 - val_acc: 0.8880\n",
            "Epoch 2162/6000\n",
            "584288/584288 [==============================] - 27s 46us/step - loss: 0.1902 - acc: 0.9266 - val_loss: 0.2989 - val_acc: 0.8995\n",
            "Epoch 2163/6000\n",
            "584288/584288 [==============================] - 28s 47us/step - loss: 0.1903 - acc: 0.9265 - val_loss: 0.3413 - val_acc: 0.8904\n",
            "Epoch 2164/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1899 - acc: 0.9267 - val_loss: 0.2950 - val_acc: 0.9023\n",
            "Epoch 2165/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1893 - acc: 0.9269 - val_loss: 0.2978 - val_acc: 0.9016\n",
            "Epoch 2166/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1898 - acc: 0.9268 - val_loss: 0.3160 - val_acc: 0.8983\n",
            "Epoch 2167/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1893 - acc: 0.9268 - val_loss: 0.3452 - val_acc: 0.8926\n",
            "Epoch 2168/6000\n",
            "584288/584288 [==============================] - 29s 49us/step - loss: 0.1902 - acc: 0.9267 - val_loss: 0.3418 - val_acc: 0.8922\n",
            "Epoch 2169/6000\n",
            "584288/584288 [==============================] - 27s 46us/step - loss: 0.1895 - acc: 0.9270 - val_loss: 0.3520 - val_acc: 0.8879\n",
            "Epoch 2170/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1897 - acc: 0.9265 - val_loss: 0.2962 - val_acc: 0.8966\n",
            "Epoch 2171/6000\n",
            "584288/584288 [==============================] - 27s 46us/step - loss: 0.1893 - acc: 0.9271 - val_loss: 0.3557 - val_acc: 0.8896\n",
            "Epoch 2172/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1899 - acc: 0.9266 - val_loss: 0.3712 - val_acc: 0.8863\n",
            "Epoch 2173/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1889 - acc: 0.9270 - val_loss: 0.4065 - val_acc: 0.8770\n",
            "Epoch 2174/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1888 - acc: 0.9273 - val_loss: 0.3701 - val_acc: 0.8856\n",
            "Epoch 2175/6000\n",
            "584288/584288 [==============================] - 28s 47us/step - loss: 0.1900 - acc: 0.9265 - val_loss: 0.3480 - val_acc: 0.8910\n",
            "Epoch 2176/6000\n",
            "584288/584288 [==============================] - 27s 46us/step - loss: 0.1895 - acc: 0.9269 - val_loss: 0.3426 - val_acc: 0.8898\n",
            "Epoch 2177/6000\n",
            "584288/584288 [==============================] - 27s 46us/step - loss: 0.1891 - acc: 0.9269 - val_loss: 0.3324 - val_acc: 0.8938\n",
            "Epoch 2178/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1893 - acc: 0.9268 - val_loss: 0.3346 - val_acc: 0.8920\n",
            "Epoch 2179/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1893 - acc: 0.9270 - val_loss: 0.3448 - val_acc: 0.8896\n",
            "Epoch 2180/6000\n",
            "584288/584288 [==============================] - 28s 49us/step - loss: 0.1892 - acc: 0.9267 - val_loss: 0.3559 - val_acc: 0.8864\n",
            "Epoch 2181/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1899 - acc: 0.9267 - val_loss: 0.3550 - val_acc: 0.8885\n",
            "Epoch 2182/6000\n",
            "584288/584288 [==============================] - 27s 46us/step - loss: 0.1894 - acc: 0.9270 - val_loss: 0.3305 - val_acc: 0.8912\n",
            "Epoch 2183/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1895 - acc: 0.9266 - val_loss: 0.3192 - val_acc: 0.8958\n",
            "Epoch 2184/6000\n",
            "584288/584288 [==============================] - 28s 48us/step - loss: 0.1894 - acc: 0.9270 - val_loss: 0.3834 - val_acc: 0.8846\n",
            "Epoch 2185/6000\n",
            "584288/584288 [==============================] - 28s 47us/step - loss: 0.1895 - acc: 0.9267 - val_loss: 0.3643 - val_acc: 0.8880\n",
            "Epoch 2186/6000\n",
            "584288/584288 [==============================] - 27s 47us/step - loss: 0.1898 - acc: 0.9270 - val_loss: 0.3222 - val_acc: 0.8923\n",
            "Epoch 2187/6000\n",
            "584288/584288 [==============================] - 24s 41us/step - loss: 0.1894 - acc: 0.9269 - val_loss: 0.3313 - val_acc: 0.8934\n",
            "Epoch 2188/6000\n",
            "584288/584288 [==============================] - 18s 31us/step - loss: 0.1898 - acc: 0.9264 - val_loss: 0.3846 - val_acc: 0.8848\n",
            "Epoch 2189/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1901 - acc: 0.9268 - val_loss: 0.3616 - val_acc: 0.8899\n",
            "Epoch 2190/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1891 - acc: 0.9272 - val_loss: 0.3302 - val_acc: 0.8944\n",
            "Epoch 2191/6000\n",
            "584288/584288 [==============================] - 18s 30us/step - loss: 0.1893 - acc: 0.9269 - val_loss: 0.3580 - val_acc: 0.8887\n",
            "Epoch 2192/6000\n",
            "584288/584288 [==============================] - 19s 32us/step - loss: 0.1900 - acc: 0.9267 - val_loss: 0.3831 - val_acc: 0.8838\n",
            "Epoch 2193/6000\n",
            "584288/584288 [==============================] - 26s 45us/step - loss: 0.1892 - acc: 0.9269 - val_loss: 0.3844 - val_acc: 0.8856\n",
            "Epoch 2194/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1893 - acc: 0.9266 - val_loss: 0.3235 - val_acc: 0.8950\n",
            "Epoch 2195/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1899 - acc: 0.9264 - val_loss: 0.3407 - val_acc: 0.8906\n",
            "Epoch 2196/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1890 - acc: 0.9270 - val_loss: 0.3340 - val_acc: 0.8909\n",
            "Epoch 2197/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1899 - acc: 0.9270 - val_loss: 0.3279 - val_acc: 0.8942\n",
            "Epoch 2198/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1897 - acc: 0.9267 - val_loss: 0.3822 - val_acc: 0.8835\n",
            "Epoch 2199/6000\n",
            "584288/584288 [==============================] - 25s 44us/step - loss: 0.1898 - acc: 0.9268 - val_loss: 0.2986 - val_acc: 0.8991\n",
            "Epoch 2200/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1891 - acc: 0.9273 - val_loss: 0.2938 - val_acc: 0.9003\n",
            "Epoch 2201/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1895 - acc: 0.9270 - val_loss: 0.3706 - val_acc: 0.8860\n",
            "Epoch 2202/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1896 - acc: 0.9269 - val_loss: 0.2937 - val_acc: 0.9010\n",
            "Epoch 2203/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1895 - acc: 0.9268 - val_loss: 0.3092 - val_acc: 0.8978\n",
            "Epoch 2204/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1896 - acc: 0.9267 - val_loss: 0.3393 - val_acc: 0.8921\n",
            "Epoch 2205/6000\n",
            "584288/584288 [==============================] - 26s 44us/step - loss: 0.1889 - acc: 0.9270 - val_loss: 0.3047 - val_acc: 0.8972\n",
            "Epoch 2206/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1897 - acc: 0.9266 - val_loss: 0.3993 - val_acc: 0.8835\n",
            "Epoch 2207/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1896 - acc: 0.9268 - val_loss: 0.3199 - val_acc: 0.8972\n",
            "Epoch 2208/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1893 - acc: 0.9270 - val_loss: 0.3068 - val_acc: 0.8972\n",
            "Epoch 2209/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1893 - acc: 0.9268 - val_loss: 0.3750 - val_acc: 0.8830\n",
            "Epoch 2210/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1889 - acc: 0.9272 - val_loss: 0.3270 - val_acc: 0.8940\n",
            "Epoch 2211/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1895 - acc: 0.9270 - val_loss: 0.3234 - val_acc: 0.8931\n",
            "Epoch 2212/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1901 - acc: 0.9267 - val_loss: 0.3786 - val_acc: 0.8820\n",
            "Epoch 2213/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1896 - acc: 0.9268 - val_loss: 0.3592 - val_acc: 0.8870\n",
            "Epoch 2214/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1898 - acc: 0.9267 - val_loss: 0.2950 - val_acc: 0.8993\n",
            "Epoch 2215/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1896 - acc: 0.9268 - val_loss: 0.2888 - val_acc: 0.9027\n",
            "Epoch 2216/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1894 - acc: 0.9268 - val_loss: 0.3009 - val_acc: 0.9006\n",
            "Epoch 2217/6000\n",
            "584288/584288 [==============================] - 26s 44us/step - loss: 0.1893 - acc: 0.9267 - val_loss: 0.3235 - val_acc: 0.8941\n",
            "Epoch 2218/6000\n",
            "584288/584288 [==============================] - 26s 44us/step - loss: 0.1891 - acc: 0.9269 - val_loss: 0.3086 - val_acc: 0.8990\n",
            "Epoch 2219/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1903 - acc: 0.9266 - val_loss: 0.3618 - val_acc: 0.8866\n",
            "Epoch 2220/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1894 - acc: 0.9270 - val_loss: 0.3475 - val_acc: 0.8897\n",
            "Epoch 2221/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1888 - acc: 0.9270 - val_loss: 0.3376 - val_acc: 0.8902\n",
            "Epoch 2222/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1895 - acc: 0.9269 - val_loss: 0.2979 - val_acc: 0.8990\n",
            "Epoch 2223/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1898 - acc: 0.9267 - val_loss: 0.3523 - val_acc: 0.8849\n",
            "Epoch 2224/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1896 - acc: 0.9268 - val_loss: 0.3175 - val_acc: 0.8968\n",
            "Epoch 2225/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1903 - acc: 0.9265 - val_loss: 0.3273 - val_acc: 0.8940\n",
            "Epoch 2226/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1896 - acc: 0.9269 - val_loss: 0.3286 - val_acc: 0.8944\n",
            "Epoch 2227/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1897 - acc: 0.9266 - val_loss: 0.3577 - val_acc: 0.8867\n",
            "Epoch 2228/6000\n",
            "584288/584288 [==============================] - 24s 41us/step - loss: 0.1898 - acc: 0.9265 - val_loss: 0.3410 - val_acc: 0.8901\n",
            "Epoch 2229/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1894 - acc: 0.9267 - val_loss: 0.3123 - val_acc: 0.8978\n",
            "Epoch 2230/6000\n",
            "584288/584288 [==============================] - 26s 45us/step - loss: 0.1891 - acc: 0.9269 - val_loss: 0.3193 - val_acc: 0.8971\n",
            "Epoch 2231/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1901 - acc: 0.9266 - val_loss: 0.3340 - val_acc: 0.8891\n",
            "Epoch 2232/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1895 - acc: 0.9270 - val_loss: 0.3991 - val_acc: 0.8839\n",
            "Epoch 2233/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1893 - acc: 0.9267 - val_loss: 0.3254 - val_acc: 0.8929\n",
            "Epoch 2234/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1893 - acc: 0.9270 - val_loss: 0.3225 - val_acc: 0.8954\n",
            "Epoch 2235/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1894 - acc: 0.9271 - val_loss: 0.3257 - val_acc: 0.8949\n",
            "Epoch 2236/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1903 - acc: 0.9266 - val_loss: 0.3370 - val_acc: 0.8901\n",
            "Epoch 2237/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1898 - acc: 0.9265 - val_loss: 0.3563 - val_acc: 0.8894\n",
            "Epoch 2238/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1895 - acc: 0.9268 - val_loss: 0.4026 - val_acc: 0.8809\n",
            "Epoch 2239/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1897 - acc: 0.9269 - val_loss: 0.3762 - val_acc: 0.8856\n",
            "Epoch 2240/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1893 - acc: 0.9268 - val_loss: 0.3666 - val_acc: 0.8875\n",
            "Epoch 2241/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1885 - acc: 0.9273 - val_loss: 0.3091 - val_acc: 0.8981\n",
            "Epoch 2242/6000\n",
            "584288/584288 [==============================] - 26s 44us/step - loss: 0.1894 - acc: 0.9269 - val_loss: 0.3293 - val_acc: 0.8951\n",
            "Epoch 2243/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1892 - acc: 0.9270 - val_loss: 0.3267 - val_acc: 0.8935\n",
            "Epoch 2244/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1896 - acc: 0.9268 - val_loss: 0.3848 - val_acc: 0.8827\n",
            "Epoch 2245/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1898 - acc: 0.9266 - val_loss: 0.3503 - val_acc: 0.8908\n",
            "Epoch 2246/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1893 - acc: 0.9266 - val_loss: 0.3538 - val_acc: 0.8847\n",
            "Epoch 2247/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1895 - acc: 0.9268 - val_loss: 0.3411 - val_acc: 0.8910\n",
            "Epoch 2248/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1894 - acc: 0.9268 - val_loss: 0.3185 - val_acc: 0.8941\n",
            "Epoch 2249/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1899 - acc: 0.9267 - val_loss: 0.3821 - val_acc: 0.8827\n",
            "Epoch 2250/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1887 - acc: 0.9270 - val_loss: 0.4157 - val_acc: 0.8752\n",
            "Epoch 2251/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1895 - acc: 0.9266 - val_loss: 0.3098 - val_acc: 0.8971\n",
            "Epoch 2252/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1893 - acc: 0.9272 - val_loss: 0.3189 - val_acc: 0.8953\n",
            "Epoch 2253/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1901 - acc: 0.9265 - val_loss: 0.3152 - val_acc: 0.8929\n",
            "Epoch 2254/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1889 - acc: 0.9274 - val_loss: 0.3105 - val_acc: 0.8950\n",
            "Epoch 2255/6000\n",
            "584288/584288 [==============================] - 26s 44us/step - loss: 0.1898 - acc: 0.9270 - val_loss: 0.3675 - val_acc: 0.8876\n",
            "Epoch 2256/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1893 - acc: 0.9268 - val_loss: 0.3726 - val_acc: 0.8840\n",
            "Epoch 2257/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1892 - acc: 0.9270 - val_loss: 0.3236 - val_acc: 0.8926\n",
            "Epoch 2258/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1890 - acc: 0.9272 - val_loss: 0.3304 - val_acc: 0.8935\n",
            "Epoch 2259/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1885 - acc: 0.9272 - val_loss: 0.3375 - val_acc: 0.8922\n",
            "Epoch 2260/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1892 - acc: 0.9265 - val_loss: 0.3772 - val_acc: 0.8829\n",
            "Epoch 2261/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1889 - acc: 0.9272 - val_loss: 0.3497 - val_acc: 0.8884\n",
            "Epoch 2262/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1899 - acc: 0.9270 - val_loss: 0.3515 - val_acc: 0.8897\n",
            "Epoch 2263/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1889 - acc: 0.9273 - val_loss: 0.3163 - val_acc: 0.8964\n",
            "Epoch 2264/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1894 - acc: 0.9267 - val_loss: 0.3164 - val_acc: 0.8948\n",
            "Epoch 2265/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1894 - acc: 0.9269 - val_loss: 0.3648 - val_acc: 0.8866\n",
            "Epoch 2266/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1900 - acc: 0.9265 - val_loss: 0.3293 - val_acc: 0.8911\n",
            "Epoch 2267/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1897 - acc: 0.9268 - val_loss: 0.3009 - val_acc: 0.8934\n",
            "Epoch 2268/6000\n",
            "584288/584288 [==============================] - 26s 44us/step - loss: 0.1891 - acc: 0.9268 - val_loss: 0.3347 - val_acc: 0.8922\n",
            "Epoch 2269/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1887 - acc: 0.9269 - val_loss: 0.3422 - val_acc: 0.8875\n",
            "Epoch 2270/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1894 - acc: 0.9269 - val_loss: 0.3414 - val_acc: 0.8896\n",
            "Epoch 2271/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1893 - acc: 0.9271 - val_loss: 0.3316 - val_acc: 0.8942\n",
            "Epoch 2272/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1894 - acc: 0.9270 - val_loss: 0.3671 - val_acc: 0.8855\n",
            "Epoch 2273/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1891 - acc: 0.9269 - val_loss: 0.3236 - val_acc: 0.8959\n",
            "Epoch 2274/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1896 - acc: 0.9266 - val_loss: 0.3567 - val_acc: 0.8893\n",
            "Epoch 2275/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1895 - acc: 0.9268 - val_loss: 0.3157 - val_acc: 0.8944\n",
            "Epoch 2276/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1890 - acc: 0.9270 - val_loss: 0.3877 - val_acc: 0.8842\n",
            "Epoch 2277/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1893 - acc: 0.9268 - val_loss: 0.3349 - val_acc: 0.8926\n",
            "Epoch 2278/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1895 - acc: 0.9267 - val_loss: 0.3049 - val_acc: 0.8967\n",
            "Epoch 2279/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1898 - acc: 0.9270 - val_loss: 0.3482 - val_acc: 0.8859\n",
            "Epoch 2280/6000\n",
            "584288/584288 [==============================] - 26s 44us/step - loss: 0.1891 - acc: 0.9271 - val_loss: 0.3672 - val_acc: 0.8878\n",
            "Epoch 2281/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1898 - acc: 0.9269 - val_loss: 0.3121 - val_acc: 0.8963\n",
            "Epoch 2282/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1891 - acc: 0.9271 - val_loss: 0.3007 - val_acc: 0.8991\n",
            "Epoch 2283/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1895 - acc: 0.9269 - val_loss: 0.3551 - val_acc: 0.8872\n",
            "Epoch 2284/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1889 - acc: 0.9269 - val_loss: 0.3667 - val_acc: 0.8860\n",
            "Epoch 2285/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1890 - acc: 0.9274 - val_loss: 0.3359 - val_acc: 0.8914\n",
            "Epoch 2286/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1889 - acc: 0.9269 - val_loss: 0.3288 - val_acc: 0.8927\n",
            "Epoch 2287/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1892 - acc: 0.9270 - val_loss: 0.3049 - val_acc: 0.9002\n",
            "Epoch 2288/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1893 - acc: 0.9270 - val_loss: 0.3507 - val_acc: 0.8893\n",
            "Epoch 2289/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1897 - acc: 0.9267 - val_loss: 0.3112 - val_acc: 0.8959\n",
            "Epoch 2290/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1894 - acc: 0.9269 - val_loss: 0.2887 - val_acc: 0.9025\n",
            "Epoch 2291/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1894 - acc: 0.9266 - val_loss: 0.3587 - val_acc: 0.8804\n",
            "Epoch 2292/6000\n",
            "584288/584288 [==============================] - 26s 44us/step - loss: 0.1896 - acc: 0.9270 - val_loss: 0.3437 - val_acc: 0.8930\n",
            "Epoch 2293/6000\n",
            "584288/584288 [==============================] - 26s 44us/step - loss: 0.1900 - acc: 0.9265 - val_loss: 0.3397 - val_acc: 0.8904\n",
            "Epoch 2294/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1891 - acc: 0.9269 - val_loss: 0.3241 - val_acc: 0.8946\n",
            "Epoch 2295/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1890 - acc: 0.9272 - val_loss: 0.3285 - val_acc: 0.8920\n",
            "Epoch 2296/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1891 - acc: 0.9268 - val_loss: 0.3295 - val_acc: 0.8938\n",
            "Epoch 2297/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1886 - acc: 0.9273 - val_loss: 0.3554 - val_acc: 0.8833\n",
            "Epoch 2298/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1890 - acc: 0.9267 - val_loss: 0.3456 - val_acc: 0.8865\n",
            "Epoch 2299/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1890 - acc: 0.9270 - val_loss: 0.3220 - val_acc: 0.8949\n",
            "Epoch 2300/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1899 - acc: 0.9266 - val_loss: 0.2950 - val_acc: 0.9002\n",
            "Epoch 2301/6000\n",
            "584288/584288 [==============================] - 24s 42us/step - loss: 0.1887 - acc: 0.9269 - val_loss: 0.3374 - val_acc: 0.8912\n",
            "Epoch 2302/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1899 - acc: 0.9268 - val_loss: 0.2867 - val_acc: 0.8998\n",
            "Epoch 2303/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1886 - acc: 0.9270 - val_loss: 0.2848 - val_acc: 0.9018\n",
            "Epoch 2304/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1894 - acc: 0.9270 - val_loss: 0.3025 - val_acc: 0.8976\n",
            "Epoch 2305/6000\n",
            "584288/584288 [==============================] - 26s 44us/step - loss: 0.1891 - acc: 0.9272 - val_loss: 0.3333 - val_acc: 0.8922\n",
            "Epoch 2306/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1894 - acc: 0.9269 - val_loss: 0.3647 - val_acc: 0.8869\n",
            "Epoch 2307/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1895 - acc: 0.9267 - val_loss: 0.3537 - val_acc: 0.8893\n",
            "Epoch 2308/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1892 - acc: 0.9268 - val_loss: 0.3537 - val_acc: 0.8891\n",
            "Epoch 2309/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1888 - acc: 0.9269 - val_loss: 0.3165 - val_acc: 0.8928\n",
            "Epoch 2310/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1897 - acc: 0.9266 - val_loss: 0.3858 - val_acc: 0.8878\n",
            "Epoch 2311/6000\n",
            "584288/584288 [==============================] - 25s 43us/step - loss: 0.1888 - acc: 0.9270 - val_loss: 0.3458 - val_acc: 0.8893\n",
            "Epoch 2312/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1893 - acc: 0.9270 - val_loss: 0.3132 - val_acc: 0.8973\n",
            "Epoch 2313/6000\n",
            "584288/584288 [==============================] - 25s 42us/step - loss: 0.1893 - acc: 0.9270 - val_loss: 0.3075 - val_acc: 0.8972\n",
            "Epoch 2314/6000\n",
            "431104/584288 [=====================>........] - ETA: 6s - loss: 0.1883 - acc: 0.9269"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ENRbzDapI52V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ]
    },
    {
      "metadata": {
        "id": "mzC0cXcoJAky",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "保存模型参考链接：https://blog.csdn.net/LuohenYJ/article/details/81096886"
      ]
    },
    {
      "metadata": {
        "id": "ltoPseCxI9LF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2cd18589-17be-4463-8e62-dc2f15f3d9ce"
      },
      "cell_type": "code",
      "source": [
        "model.save('model_embedding.h5')\n",
        "model = tf.keras.models.load_model('model_embedding.h5')\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#results = new_model.evaluate(split_features(test_data), test_labels)\n",
        "#print(results)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8NFLt2ncJ1km",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9EEGuDVuzb5r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model\n",
        "\n",
        "And let's see how the model performs. Two values will be returned. Loss (a number which represents our error, lower values are better), and accuracy."
      ]
    },
    {
      "metadata": {
        "id": "zOMKywn4zReN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "99e877db-f491-416a-a5e6-112db076ba7f"
      },
      "cell_type": "code",
      "source": [
        "#test_data = pd.read_csv(\"validation_data_modify.csv\")\n",
        "#test_data,test_labels = test_data.drop(['user_id','current_service'], axis=1).as_matrix(),test_data.loc[:,'current_service'].as_matrix() \n",
        "#test_labels = class_label.fit_transform(test_labels)\n",
        "\n",
        "results = model.evaluate(split_features(test_data), test_labels)\n",
        "\n",
        "print(results)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19998/19998 [==============================] - 1s 25us/step\n",
            "[0.1853188443386873, 0.9262426242624262]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z1iEXVTR0Z2t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This fairly naive approach achieves an accuracy of about 87%. With more advanced approaches, the model should get closer to 95%."
      ]
    },
    {
      "metadata": {
        "id": "5KggXVeL-llZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create a graph of accuracy and loss over time\n",
        "\n",
        "`model.fit()` returns a `History` object that contains a dictionary with everything that happened during training:"
      ]
    },
    {
      "metadata": {
        "id": "VcvSXvhp-llb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e562bc5a-6557-4f35-fbaa-17cb866c644a"
      },
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "nRKsqL40-lle",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There are four entries: one for each monitored metric during training and validation. We can use these to plot the training and validation loss for comparison, as well as the training and validation accuracy:"
      ]
    },
    {
      "metadata": {
        "id": "nGoYf2Js-lle",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "a370c54f-44f2-4f51-9340-6bcd0182807b"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xl4TNf/B/D3nTUrgsS+RIglGkqr\n2hQVSSWWaqwpFVtLlZLShfykUWu1VUtXWvW1lVBB7VtKW9TSqNqJvdYECVlnu78/bmcYM5NMIpNl\nvF/P06fmzr13jmPmfu4593POEURRFEFERERlnqykC0BERERFg0GdiIjISTCoExEROQkGdSIiIifB\noE5EROQkGNSJiIicBIM6kRVxcXEICwtDWFgYAgIC0L59e9PrjIyMAp0rLCwMqampee4zc+ZMLF++\n/HGKXOQGDhyIhISEIjlXw4YNcePGDWzfvh3jx49/rM9buXKl6c/21K29xo0bh2+++aZIzkVUUhQl\nXQCi0ujjjz82/Tk4OBiffvopnnnmmUKda8uWLfnuM3bs2EKdu6wJDQ1FaGhooY9PSUnBDz/8gN69\newOwr26JniRsqRMVQv/+/TFr1iyEh4cjKSkJqampGDJkCMLCwhAcHIyFCxea9jW2Uvfv348+ffpg\n5syZCA8PR3BwMA4cOADAvJUYHByMFStWoGfPnnjxxRfxySefmM713Xff4fnnn0ePHj2wbNkyBAcH\nWy3fqlWrEB4ejpdffhn9+vXD1atXAQAJCQkYNWoUYmJi0LFjR3Tq1Alnz54FAFy5cgW9evVCSEgI\nxo4dC71eb3He3bt3o2vXrmbbunXrht9++y3POjBKSEjAwIED8/28nTt3omvXrujYsSO6d++OkydP\nAgAiIyNx7do1hIWFQaPRmOoWABYvXoxOnTohLCwMw4cPx507d0x1O3fuXAwaNAjt27fHoEGDkJ2d\nbeufFgBw6tQpREZGIiwsDN26dcPvv/8OAMjMzMSIESMQHh6ODh06YMKECdBqtTa3ExU3BnWiQjp2\n7Bg2btyIFi1a4Ntvv0XNmjWxZcsWLFq0CDNnzsT169ctjjlx4gSaNWuGzZs3o2/fvvj222+tnvvg\nwYOIj4/H6tWrsXTpUty4cQNnz57FDz/8gHXr1uGnn36y2Uq9ffs2Jk2ahIULF2Lbtm2oXbu2Wbfy\nb7/9hr59+2Lr1q147rnnsGjRIgDA559/jueffx47duzAgAEDkJSUZHHu559/Hjdu3MCVK1cASIH5\nxo0beOGFF+yuAyNbn6fT6TBu3DhMnjwZW7duRXBwMGbMmAEAmDZtGqpVq4YtW7ZApVKZzvX3339j\nwYIFWLJkCbZs2YLq1atj5syZpve3bNmCWbNmYfv27bhz5w62b99us1wGgwFjxozB66+/ji1btmDK\nlCkYO3YsMjIysHbtWpQrVw6bN2/G1q1bIZfLkZycbHM7UXFjUCcqpHbt2kEmk35CEyZMQGxsLACg\nVq1a8Pb2xr///mtxjLu7O0JCQgAAAQEBuHbtmtVzd+3aFXK5HFWqVEGlSpVw/fp1HDx4EK1atYKP\njw/UajV69Ohh9dhKlSrhr7/+QtWqVQEAzzzzjCkIA4Cfnx+aNm0KAGjSpIkp8B46dAidOnUCAAQG\nBqJevXoW51apVGjfvj0SExMBADt27EBISAgUCoXddWBk6/MUCgX27t2L5s2bWy2/Nbt27ULHjh1R\nqVIlAECvXr2wZ88e0/vt2rVDhQoVoFAo4O/vn+fNxr///ovU1FR07twZAPDUU0+hevXqOHr0KCpW\nrIjDhw/jjz/+gMFgwMcff4zGjRvb3E5U3PhMnaiQypcvb/rz0aNHTS1TmUyGlJQUGAwGi2M8PT1N\nf5bJZFb3AQAPDw/Tn+VyOfR6Pe7du2f2mVWqVLF6rF6vx9y5c5GYmAi9Xo/MzEz4+vpaLYPx3ACQ\nnp5u9rnlypWzev6OHTti8eLFGDBgAHbs2IG33367QHVglNfnLVmyBGvWrIFGo4FGo4EgCDbPAwB3\n7tyBj4+P2blu376d79/Z1rk8PT3NPrNcuXK4c+cOOnfujPT0dMyZMwfnz5/HK6+8gvHjxyM8PNzq\n9od7E4iKA1vqREXg/fffR8eOHbF161Zs2bIFXl5eRf4ZHh4eyMrKMr2+deuW1f02bdqExMRELF26\nFFu3bsWoUaPsOn+5cuXMMvuNz6Qf1aZNG5w6dQoXL17ExYsX0bp1awAFrwNbn5eUlITvv/8e3377\nLbZu3YopU6bkW/bKlSsjLS3N9DotLQ2VK1fO9zhrKlWqhPT0dDy81lVaWpqpFyAyMhKrVq3Cpk2b\ncPz4caxduzbP7UTFiUGdqAjcvn0bTZs2hSAIWLNmDbKzs80CcFEIDAzE/v37cefOHWg0GptB4/bt\n26hRowYqVqyIu3fvYvPmzcjMzMz3/M2bNzc9a05KSsLly5et7qdSqfDiiy/is88+Q4cOHSCXy02f\nW5A6sPV5d+7cQaVKlVC9enVkZ2djzZo1yMrKgiiKUCgUyMrKgk6nMzvXSy+9hO3bt+Pu3bsAgBUr\nVqBdu3b5/p2tqVmzJqpWrYpNmzaZypaamorAwEB8/fXX+PnnnwFIPSU1a9aEIAg2txMVNwZ1oiIw\nevRojBgxAl27dkVWVhb69OmD2NhYm4GxMAIDAxEREYGIiAhERUWhffv2Vvfr0qUL0tLSEBoairFj\nxyI6Oho3btwwy6K35v3338evv/6KkJAQLFu2DC+88ILNfTt27IgdO3YgPDzctK2gdWDr89q0aQMf\nHx+EhIRg8ODBGDBgADw9PTFq1Cg0bNgQ5cuXR1BQkFk+QmBgIIYOHYp+/fohLCwM9+/fx7vvvpvn\n39cWQRDwxRdfYOnSpQgPD8eUKVMwZ84cuLm5oVu3bli3bh06duyIsLAwKJVKdOvWzeZ2ouImcD11\norJDFEVTC3DXrl2YPXs2u3mJyIQtdaIy4s6dO2jdujWuXr0KURSxefNmU4Y4ERHAljpRmbJ8+XL8\n+OOPEAQB9erVw9SpU00JXEREDOpEREROgt3vREREToJBnYiIyEmU+RnlUlLuF/gYLy833L1btGOI\nyzrWiSXWiSXWiTnWhyXWiaWirhNvb0+b7zk0qE+bNg1HjhyBIAiIiYlBYGCg6b3g4GBUrVrVNHHF\n559/jipVquR5TFFRKORFfs6yjnViiXViiXVijvVhiXViqTjrxGFB/cCBA7h06RLi4+Nx7tw5xMTE\nID4+3myf77//Hu7u7gU6hoiIiKxz2DP1ffv2mVaj8vPzQ3p6utk8z0V1DBEREUkc1lJPTU1FQECA\n6XXFihWRkpJitipTXFwcrl69ipYtW2Ls2LF2HfMoLy+3QnVt5PVM4knFOrHEOrHEOjHH+rDEOrFU\nXHVSbIlyjw6HHzVqFNq0aYPy5ctjxIgR2Lp1a77HWFOY5ANvb89CJdg5M9aJJdaJJdaJOdaHJdaJ\npaKukxJJlPPx8UFqaqrp9a1bt+Dt7W16/eqrr5r+3LZtW5w5cybfY4iIiMg2hz1TDwoKMrW+jx8/\nDh8fH1M3+v379zFkyBBoNBoAwMGDB9GgQYM8jyEiIqK8Oayl3qJFCwQEBCAyMhKCICAuLg4JCQnw\n9PREaGgo2rZtiz59+kCtVqNJkyYICwuDIAgWxxAREZF9yvzc74V5TsFnPpZYJ5ZYJ5ZYJ+ZYH5Ye\nt06+/HIWTp8+iTt3biMnJwfVq9dAuXLlMW3aZ/keu2nTeri7e6Bdu/ZW358zZyZ69YpE9eo1ClW2\nkSOHYsyYD1CvXv0CHecUz9TLmjVrFJg9W4UzZ2Tw9zcgOlqDiAhdSReLiKhUe/Ta+dFHQIcOhT/f\nO++8C0AK0OfPn8PIkdF2H9upU9c83x89emzhC1ZGMKhD+lIOG+Zqen3ypPy/19kM7ERENli7dr72\nGjBvnqLIr51JSYewYsVSZGVlYeTId3H48F/YtWsnDAYDnn8+CIMHD8WCBfNQoUIF+Pr6ISFhJQRB\nhkuXLuCllzpg8OChppb2r7/uRGZmBi5fvoSrV//FqFFj8fzzQVi69H/YsWMbqlevAZ1Oh8jIfmjR\n4hmLsmRkZGDq1InIyLgPnU6H6Oj30bBhI8ye/RlOnToJvV6PiIie6NSpK2bP/gznzp1BTo7GtM2R\nGNQBzJ6tsrp9zhwVgzoRkQ3Ffe08dy4Zy5cnQKVS4fDhv/DNNz9AJpOhd+9u6NOnr9m+J04cx08/\nrYbBYECvXl0xePBQs/dv3bqJzz+fiz//3It161YjIKApEhJWYfny1cjMzERkZHdERvazWo5Vq5Yj\nIKApXn99IE6dOoEvv/wC06Z9hr17/8DKleug0+mwadN63LuXjr17/8Cvvybi+vW72LRpfZHXyaMY\n1AGcOWN9EICt7UREVPzXzvr1G0Clkm4kXFxcMHLkUMjlcqSlpeHevXtm+zZs2AguLi42zxUY2ByA\nNPw6IyMD//57BfXq+UGtdoFa7YLGjQNsHnvq1AlERQ0BADRq1AT//nsF5cqVR61adTBu3Bi0bx+C\nsLDOUKlUqFWrDoYPH46goJcQFtb5casgX4xaAPz9DQXaTkRExX/tVCqVAIAbN64jPn4ZZs78El99\nNR9Vq1a12Ne4WJgtD78viiJEEZDJHoREQbB9rCAIZpOjGQzS33fmzLkYNGgozp49gw8/fNe0beTI\nkWbbHIlBHUB0tMbq9tGjrW8nIqKSu3ampaXBy8sLbm5uOH36FG7cuAGtVvtY56xWrRrOnz8HnU6H\nu3fv4tSpkzb3bdSoCQ4fPgQAOHbsKHx9/XD9+jWsWrUCDRs2wsiR0UhPTzdtCwgIMG1zNHa/A/89\n+8nGnDkPMjhHj2b2OxFRXqxdO2Nj5ejQwbHXzgYN/OHq6obhwwfjqaeao1u37pg5cwYCA5sV+pwV\nK1ZCaGgY3nwzCnXq+KJJkwCbrf3evV/DtGkfY9Sot2AwGDBmzIeoXNkbx44dwc6d26BUKtG58yum\nbZGRkQBk6Nz5lUKXz14cp04AWCfWsE4ssU7MsT4sleU62bRpPUJDwyCXyxEVFYkvvvgSPj5VHvu8\nHKdORERUzG7fvo2hQwdAqVTh5ZfDiiSgFzcGdSIiIgD9+w9E//4DS7oYj4WJckRERE6CQZ2IiMhJ\nMKgTERE5CQZ1IiIiJ8GgTkREpcawYYMsJn757ruvsHz5Uqv7JyUdwoQJHwAAxo0bY/H+6tXxWLBg\nns3PS04+i8uXLwEA4uLGIzc3p7BFR8+eXZGVlVXo44sCgzoREZUaoaEdkZi43Wzbrl2JCAl5Od9j\nP/nkiwJ/3u7dibhy5TIA4OOPp0Ottj1ffFnAIW1ERFRqdOjwMoYPH4K33x4FADh16iS8vb3h7e2D\ngwf344cfvoNSqYSnpycmTfrE7NjOnTtg48adOHToAObOnYmKFSuhUqXKpqVUp06diJSUW8jOzsbg\nwUNRtWo1rFuXgN27E+Hl5YWPPhqPxYvjkZFxH9OnT4JWq4VMJsO4cbEQBAFTp05E9eo1kJx8Fv7+\nDTFuXKzVv8OtWzfNjv/000+gUHhg0qRY3L6dCo1GgyFDhuGZZ1pZbGvd+oXHqj8GdSIismriRDXW\nry9YmJDJAIPB3eb7XbvqMHFirs33vbwqonr1Gjhx4hiaNGmKxMTtCA0NAwDcv38fcXFTUL16DUye\n/BH2798HNzc3i3PMm/cVYmMno0EDf7z33ihUr14D9+/fQ6tWrREe3gVXr/6L2Nhx+PHHpXjuuefx\n0ksd0KRJU9PxP/zwHbp06YYOHV7Gr7/uwI8/zseQIcNw+vRJfPzxNHh5VURERCfcv38fnp6Ws7s9\nevxXX32Frl17Ij09DV9//T3u37+Pffv24Ny5ZIttj4vd70REVKqEhoZh506pC37Pnt/w0ksdAAAV\nKlTAjBlTMHLkUBw+/Bfu3bO+QMr169fRoIE/AKB58xYAAE/Pcjh58jiGDx+MqVMn2jwWAE6fPomn\nn24JAGjR4hmcPXsaAFCjRi1UqlQZMpkMlSt7IzMzw67jT5w4gTp16iIrKxOTJ8ciKekgQkJetrrt\ncbGlTkREVk2cmJtnq9oaaZ7zzMf63Hbt2mPx4h8RGtoRtWrVRrly5QAA06dPxmefzUbdur744osZ\nNo9/eAlV4/Im27dvwb179/D11z/g3r17eOON/nmU4MHSqlqtDoIgne/RBV5sL51ifrxMJoOLiwvm\nzfsfjh79B5s3r8eePb8jJibO6rbHwZY6ERGVKm5u7vDza4DFixeaut4BIDMzA1WqVMX9+/eRlPSX\nzeVWK1f2xuXLFyGKIg4f/guAtFxrtWrVIZPJsHt3oulYQRCg1+vNjm/cuAmSkqSlVf/++y80atS4\nQOV/9PimTZvi9OlT2L59C5o1a4733huPixcvWN32uNhSJyKiUic0NAxTpsQhLm6yaVv37r0wfPgQ\n1KpVG/36ReHHH+dj6NC3LY4dOvRtTJjwIapWrWZalOWll4IxbtwYnDhxDJ07vwIfHx8sXPg9mjV7\nGrNnf2b2bP6NN97C9OmTsX79WigUSowfHwudzv7lZB89/vPPZyAjQ4d5877GunUJkMlk6Nu3P6pV\nq26x7XFx6VUCwDqxhnViiXVijvVhiXViqTiXXmX3OxERkZNgUCciInISDOpEREROgkGdiIjISTCo\nExEROQkGdSIiIifBoE5EROQkGNSJiIicBIM6ERGRk2BQJyIichIM6kRERE6CQZ2IiMhJMKgTERE5\nCQZ1IiIiJ8GgTkRE5CQY1ImIiJwEgzoREZGTYFAnIiJyEgzqREREToJBnYiIyEkoHHnyadOm4ciR\nIxAEATExMQgMDLTYZ+bMmfj777+xZMkS7N+/H6NHj0aDBg0AAP7+/oiNjXVkEYmIiJyGw4L6gQMH\ncOnSJcTHx+PcuXOIiYlBfHy82T7Jyck4ePAglEqlaVurVq0wd+5cRxWLiIjIaTms+33fvn0ICQkB\nAPj5+SE9PR0ZGRlm+3zyySd49913HVUEIiKiJ4rDgnpqaiq8vLxMrytWrIiUlBTT64SEBLRq1Qo1\natQwOy45ORlvvfUWXnvtNezZs8dRxSMiInI6Dn2m/jBRFE1/TktLQ0JCAhYuXIibN2+attetWxcj\nR45EeHg4rly5gqioKGzbtg0qlcrmeb283KBQyAtcHm9vzwIf4+xYJ5ZYJ5ZYJ+ZYH5ZYJ5aKq04c\nFtR9fHyQmppqen3r1i14e3sDAP7880/cuXMH/fr1g0ajweXLlzFt2jTExMSgU6dOAIDatWujcuXK\nuHnzJmrVqmXzc+7ezSpw2by9PZGScr/Axzkz1okl1okl1ok51ocl1omloq6TvG4QHNb9HhQUhK1b\ntwIAjh8/Dh8fH3h4eAAAwsLCsGnTJqxcuRJfffUVAgICEBMTg19++QULFiwAAKSkpOD27duoUqWK\no4pIRETkVBzWUm/RogUCAgIQGRkJQRAQFxeHhIQEeHp6IjQ01OoxwcHBeO+997Bz505otVpMnDgx\nz653IiIiekAQH37YXQYVpkuD3UOWWCeWWCeWWCfmWB+WWCeWnKL7nYiIiIoXgzoREZGTYFAnIiJy\nEgzqREREToJBnYiIyEkwqBMRETkJBnUiIiInwaBORETkJBjUiYiInASDOhERkZNgUCciInISDOpE\nREROgkGdiIjISTCoExEROQkGdSIiIifBoE5EROQkGNSJiIicBIM6ERGRk2BQJyIichIM6kRERE6C\nQZ2IiMhJMKgTERE5CQZ1IiIiJ8GgTkRE5CQY1ImIiJwEgzoREZGTYFAnIiJyEgzqREREToJBnYiI\nyEkwqBMRETkJBnUiIiInwaBORETkJBjUiYiInASDOhERkZNgUCciInISDOpEREROgkGdiIjISTCo\nExEROQkGdSIiIifBoE5EROQkGNSJiIicBIM6ERGRk2BQJyIichIM6kRERE7CoUF92rRp6NOnDyIj\nI/HPP/9Y3WfmzJno379/gY4hIiIiSw4L6gcOHMClS5cQHx+PqVOnYurUqRb7JCcn4+DBgwU6hoiI\niKxzWFDft28fQkJCAAB+fn5IT09HRkaG2T6ffPIJ3n333QIdQ0RERNY5LKinpqbCy8vL9LpixYpI\nSUkxvU5ISECrVq1Qo0YNu48hIiIi2xTF9UGiKJr+nJaWhoSEBCxcuBA3b9606xhbvLzcoFDIC1we\nb2/PAh/j7Fgnllgnllgn5lgfllgnloqrThwW1H18fJCammp6fevWLXh7ewMA/vzzT9y5cwf9+vWD\nRqPB5cuXMW3atDyPseXu3awCl83b2xMpKfcLfJwzY51YYp1YYp2YY31YYp1YKuo6yesGwWHd70FB\nQdi6dSsA4Pjx4/Dx8YGHhwcAICwsDJs2bcLKlSvx1VdfISAgADExMXkeQ0RERHlzWEu9RYsWCAgI\nQGRkJARBQFxcHBISEuDp6YnQ0FC7jyEiIiL7CKI9D65LscJ0abB7yBLrxBLrxBLrxBzrwxLrxJJT\ndL8TERFR8WJQJyIichIM6kRERE6CQZ2IiMhJMKgTERE5CQZ1IiIiJ8GgTkRE5CQY1ImIiJwEgzoR\nEZGTYFAnIiJyEgzqREREToJB/SE5OUBaWkmXgoiIqHAY1B8SHe2CNm3cYTCUdEmIiIgKjkH9ETdv\nynD1qlDSxSAiIiowBvWH1KsnNdHPnWO1EBFR2cPo9RA/P+tBfc0aBdq1c0O1ah5o184Na9YoSqJ4\nREREeWJ0eogxqJ8//yCor1mjwLBhrqbXJ0/K/3udjYgIXXEXkYiIyCa21B9iraU+e7bK6r5z5ljf\nTkREVFIY1B/i6Qn4+BiQnPygWs6csV5FtrYTERGVFEamR/j5GXDlioDcXOm1v7/18W22thMREZUU\nBvVH+PkZIIoCLl6UqiY6WmN1v9GjrW8nIiIqKQzqj3h0WFtEhA7z5mWjSRM9FAoRTZroMW8ek+SI\niKj0Yfb7I/z8RADmyXIREToGcSIiKvXYUn/Eg2FtnFWOiIjKFgb1R9Sta4BMJpplwBMREZUFdkWu\nY8eO4ddffwUAzJo1CwMGDMChQ4ccWrCSolIBtWuLnCqWiIjKHLsi15QpU+Dr64tDhw7h6NGjiI2N\nxdy5cx1dthLj52dAaqoM6eklXRIiIiL72RXU1Wo16tati507d6J3796oX78+ZDLnbclamy6WiIio\ntLMramVnZ2Pz5s3YsWMHXnzxRaSlpeHevXuOLluJ4WptRERUFtkVtcaMGYP169fj3XffhYeHB5Ys\nWYKBAwc6uGglx9hSZ7IcERGVJXaNU2/dujWaNm0KDw8PpKam4vnnn0eLFi0cXbYSU78+u9+JiKjs\nsStqTZ48GZs3b0ZaWhoiIyOxdOlSTJw40cFFKznVqolwdWUGPBERlS12Ra0TJ06gV69e2Lx5MyIi\nIjB79mxcunTJ0WUrMTIZ4OtrwLlzMohiSZeGiIjIPnYFdfG/yLZr1y4EBwcDADQa517QxM/PgKws\nATdvcmY5IiIqG+wK6r6+vujUqRMyMzPRuHFjrF27FuXLl3d02UqUMVmOXfBERFRW2JUoN2XKFJw5\ncwZ+fn4AgPr16+PTTz91aMFKmnFYW3KyDEFB+hIuDRERUf7sCuo5OTlITEzEnDlzIAgCmjdvjvr1\n6zu6bCXKmAHPljoREZUVdkWs2NhYZGRkIDIyEr1790ZqaiomTJjg6LKVKM4qR0REZY1dLfXU1FR8\n8cUXptft27dH//79HVao0sDLC6hY0cCWOhERlRl2TxObnZ1tep2VlYXc3FyHFaq0qFdPxKVLArTa\nki4JERFR/uxqqffp0wfh4eFo2rQpAOD48eMYPXq0QwtWGvj5GXDokBxXrgioV48D1omIqHSzK6j3\n7NkTQUFBOH78OARBQGxsLJYsWeLospW4h+eAr1ePGfBERFS62RXUAaBatWqoVq2a6fU///zjkAKV\nJuZj1RnUiYiodCt0Fpj4BMyfygloiIioLLG7pf4oQch/+tRp06bhyJEjEAQBMTExCAwMNL23cuVK\n/Pzzz5DJZGjUqBHi4uJw4MABjB49Gg0aNAAA+Pv7IzY2trBFfGy+vhzWRkREZUeeQb1du3ZWg7co\nirh7926eJz5w4AAuXbqE+Ph4nDt3DjExMYiPjwcgZdNv3LgRy5Ytg1KpRFRUFA4fPgwAaNWqFebO\nnVvYv0+RcnUFatbksDYiIiob8gzqP/30U6FPvG/fPoSEhAAA/Pz8kJ6ejoyMDHh4eMDV1RWLFi0C\nIAX4jIwMeHt749q1a4X+PEepV8+A335TICMD8PCwfH/NGgVmz1bhzBkZ/P0NiI7WICJCV/wFJSKi\nJ16eQb1GjRqFPnFqaioCAgJMrytWrIiUlBR4PBQZ58+fj8WLFyMqKgq1atXCtWvXkJycjLfeegvp\n6ekYOXIkgoKC8vwcLy83KBTyApfP29vTrv2eegr47TcgLc0Tvr7m761YAQwb9uD1yZNyDBvminLl\ngMjIAhepxNlbJ08S1okl1ok51ocl1oml4qqTQj9TLyhriXVDhw5FVFQU3nzzTbRs2RJ169bFyJEj\nER4ejitXriAqKgrbtm2DSqWyed67d7MKXBZvb0+kpNy3a9/q1ZUAXHDoUDZq1jRvgU+a5AbA8oZi\n8mQ9OnQoeLlKUkHq5EnBOrHEOjHH+rDEOrFU1HWS1w2Cwx4W+/j4IDU11fT61q1b8Pb2BgCkpaXh\n4MGDAAAXFxe0bdsWSUlJqFKlCjp16gRBEFC7dm1UrlwZN2/edFQR7ZJXBvyZM9arz9Z2IiIiR3JY\n9AkKCsLWrVsBSDPQ+fj4mLredTodxo0bh8zMTADA0aNH4evri19++QULFiwAAKSkpOD27duoUqWK\no4poF+MSrNaCur+/weoxtrYTERE5ksO631u0aIGAgABERkZCEATExcUhISEBnp6eCA0NxYgRIxAV\nFQWFQoGGDRuiQ4cOyMzMxHvvvYedO3dCq9Vi4sSJeXa9F4datUQolaLVYW3R0RoMG+ZqsX30aE1x\nFI2IiMiMIJbxWWQK85yioM83XnzRDTduyHD2bAYeHeG3Zo0Cc+Y8yH4fPbpsZr/zOZgl1okl1ok5\n1ocl1oml4nymXmyJcmWZn5/pNxbLAAAgAElEQVQBZ87IkZoqwNvb/B4oIkJXJoM4ERE5H2Z02YHT\nxRIRUVnAKGUHPz+pdX7+fP5T4xIREZUUBnU7sKVORERlAaOUHYzD2pKTWV1ERFR6MUrZwdtbhKen\niNOnCz4dLRERUXFhULeDIAAvvKDH+fMynD7NKiMiotKJEcpO3btrAUjj0omIiEojBnU7vfyyDm5u\nIlavVqJsT9dDRETOikHdTu7uQHi4DpcuyZCUxGojIqLSh9GpAHr0kLrgExKUJVwSIiIiSwzqBdCu\nnR4VKxqwdq0COjtmhl2zRoF27dxQrZoH2rVz4/N4IiJyKAb1AlAqgVde0SElRYY//sh7eNuaNQoM\nG+aKkyfl0OsFnDwpx7BhrgzsRETkMAzqBdS9u9REz68LfvZs60vGzplTskvJEhGR82JQL6BWrfSo\nWdOADRsUyM62vd+ZM9ar1tZ2IiKix8UIU0AyGRARoUVGhoAdO2x3pfv7Gwq0nYiI6HExqBfCgy54\n20E9Olpjdfvo0da3ExERPS4G9UJo0sSARo302LFDgfR06/tEROgwb142mjTRQ6EQ0aSJHvPmZSMi\nwo60eSIiokJgUC8EQZBa67m5AjZtst1aj4jQYdeuLFy7loFdu7IY0ImIyKEY1AspIkKaiGb1ak5E\nQ0REpQODeiHVqSPimWf0+OMPOW7eFEq6OERERAzqj6NHDy0MBgHr1nFCGSIiKnkM6o+ha1cd5HKR\nc8ETEVGpwKD+GHx8RLRtq0dSkhznz7MLnoiIShaD+mPq3r1wK7dxsRciIipqDOqPqVMnHdzdRXz5\npQr79uW9yIsRF3shIiJHYFB/TJ6ewPz52dDpgL59XfHXX/lXKRd7ISIiR2BQLwKhoXp8910OsrOB\nyEg3HD2ad7VysRciInIERpEi0rWrDl9+mYN794DevV1x+rTtquViL0RE5AgM6kWoVy8dPv88F7dv\ny9Czp6vNjHgu9kJERI7AoF7E+vfXYsqUHNy8KUPPnm64csUysHOxFyIicgSmWzvA0KFa5OQImDJF\njR493PDLL1moWlU02yciQscgTkRERYotdQcZNUqDMWNycfGiDF26uCE5mZPTEBGRYzGoO9CHH2rw\nwQe5uHxZhs6d3bF/v33j2ImIiAqDQd2BBAF47z0N5szJxv37QM+erli/Pv8nHpxtjoiICoNBvRi8\n9poOy5ZlQ6EA3njDBfPm2Z5SlrPNERFRYTGoF5P27fX45Zcs+PiIiI11QWysGgYrw9I52xwRERUW\ng3oxeuopAzZtyoK/vx7z5qnw5psuyM4234ezzRERUWExUhSzWrVEbNiQhRde0GH9eiUiItxw8+aD\nzHjONkdERIXFoF4CKlQA4uOz0bu3FklJcoSGuuHvv6V/Cs42R0REhcWgXkLUauDLL3MQF5eDmzcF\nvPKKGxISFJxtjoiICo0p1SVIEIARI7Ro2NCAYcNc8dZbrjh5Mhfjx2sYxImIqMDYUi8FQkL02Lw5\nC76+BsyZo8aAAa7IyLDcj+PXiYAlS5SIj+d3n8gah/4ypk2bhiNHjkAQBMTExCAwMND03sqVK/Hz\nzz9DJpOhUaNGiIuLgyAIeR7jzPz9DdiyJRNvvumKrVsV6NTJDatWZaNKFWnOeOP4dSPj+HWAXfP0\n5BBFIDZWDaUS6N07AwJnXyYy47CW+oEDB3Dp0iXEx8dj6tSpmDp1qum97OxsbNy4EcuWLcOKFStw\n/vx5HD58OM9jngReXsCKFdkYOFCDU6fk+OabB2PTOX6dCLh1S0BWloD0dAGXLjGiEz3KYUF93759\nCAkJAQD4+fkhPT0dGf/1Kbu6umLRokVQKpXIzs5GRkYGvL298zzmSaFQAJMn56JSJQNWrFAiJ0fa\nzvHrRMCFCw++7//8w7UUiB7lsIiQmpoKLy8v0+uKFSsiJSXFbJ/58+cjNDQUYWFhqFWrll3HPAnU\naiAyUoe7dwVs2CA9IeH4dSLg4sUHrfMjR3hDS/SoYss2EUXRYtvQoUMRFRWFN998Ey1btrTrmEd5\neblBoSj4Hbu3t2eBjylO0dHA118Dy5e7Yvhw4KOPgNdes9wvNlYOb29PrFgBTJsGnDgBNGkCxMQA\nkZEF+8zSXiclgXViqSTr5ObNB38+eVINb291iZXFiN8RS6wTS8VVJw4L6j4+PkhNTTW9vnXrFry9\nvQEAaWlpOHv2LJ599lm4uLigbdu2SEpKyvMYW+7ezSpw2by9PZGScr/AxxWn8uWBtm1d8dtvCvzx\nRyY6dDBg3jwF5sxR4cwZGfz9DRg9WoMOHXSYP988ie7oUekG4N49+5PoykKdFDfWiaWSrpMTJ1wA\nKOHhIeLQIeDWrZJNlivp+iiNWCeWirpO8rpBcFj/VVBQELZu3QoAOH78OHx8fODh4QEA0Ol0GDdu\nHDIzMwEAR48eha+vb57HPIkGDNACkIbwAEBEhA67dmXh2rUM7NqVZQrYTKKjJ8WFCzKo1SLat9ch\nLU3A5ctMliN6mMNa6i1atEBAQAAiIyMhCALi4uKQkJAAT09PhIaGYsSIEYiKioJCoUDDhg3RoUMH\nCIJgccyTLCxMB29vA+Ljlfi//8uFq6v1/ZhER0+KCxdkqFPHgObNDVi/XkqWq1OHQzqJjBz6TP29\n994ze92oUSPTn7t3747u3bvne8yTTKkE+vbVYs4cNdatUyAy0vrFy9/fgJMnLfMKmERHzuTuXSA9\nXUDr1iKaNdMDkJLlunYt4YIRlSJsypVyr7+uhSCIWLzYdld6fovAcCY6cgbG4Wx16xoQGGgM6hzW\nRvQwBvVSrk4dEe3b63HokBzHj1v/58prERjjTHQnT8qh1wummegY2KmseTioV6gA1KljwD//yGHH\nIBmiJwaDehkQFSUlzC1erLS5D5PoyNkZg7qvr/RYqVkzPe7eFXDlCpPliIwY1MuAl1/WoWpVA37+\nWYn/BgzYjUl05CwuXjQP6oGB0v/ZBU/0AK/sZYBCAfTrp8X9+wLWrrXdWreGM9GRs7hwQQa5XETN\nmlJ/uzFZ7p9/eBkjMuKvoYx4/XUtZDIxzy54a/JLonOUgwdlpnnriYrChQsCatUSofzvJ8BkOSJL\nDOplRI0aIkJC9Dh8WF6glkleSXSOcvCgDJ07uyM62sVhn0FPlowMIDVVZup6B6RVDWvXNuCff2RM\nliP6D4N6GTJggNS6XrSoYK11W0l0wIPhbgoFimy425Yt0jkSEpTYu5etKHp8D2e+P6xZMz3u3JHh\n33+ZLEcEFOOCLvT4goP1qFnTgNWrlTZnl6tTx4DBg7WQ2xFLjcPdjIzD3YDHa8knJiqgUIjQ64Hx\n49XYsSPL1GVKVBiPJskZNWsmzSx35IgctWpxZjkiBvUyRC4HBg3SYvJkNebPtz0k7fZtAePG5f/M\nPK/hbsYx7rNnP1hAJjpak2+wv3FDwPHjcrz0kg41axqwdKkKCxcqMXSoNt/yENny6HA2I+Nz9X/+\nkaFLl2IvFlGpw6BexowYoUFoqA5aKzFSpwPefNMVX3yhxjPP6BESos/zXHkNdytsKz4xUeoiCA7W\noWdPHdavV2LGDDW6ddOhShU++KTCMa6j7utr/h1ishyROT5TL2NkMqBRIwOeesryv6efNuDHH7Oh\nVot4+23XfFewymu4W2EnrUlMlO4TO3TQo3JlEePH5+L+fQFTppT8utdUdl24IIMgiKhd2/w7W7Ei\nk+WIHsag7mQCAw2YNi0XaWkC3njDFbm5tvfNa7hbYSat0emA3bsVqF3bgPr1pYvvgAFaNG2qR3y8\nEgcO8OtGhXPhggzVq4twsTKgIjBQj9u3Zbh6lclyRLzKOqHXX9eiTx8t/v5bjthY2y1k8+FuMBvu\nVphJaw4dkiM9XUBwsA7Cf9dXuRyYPl26sxg3zgX6vJ8IEFnIzgauXZNZPE83ataMM8sRGTGoOyFB\nAGbMyEGTJnr8738q/Pyz7dQJ43A3rRZmw90Ks/Lbr78+eJ7+sOee06N3by2OHZMXeDge0eXL1pPk\njB5OliN60vFX4KTc3IAff8yGp6eI995zwalTBfunLszKb6tXK6FSiXjxRcvmeGxsLjw9RUyfrkZq\nKrtJyX4XLkjflzp1rD80f7C2OlvqRAzqTqxePRFz5uQgK0vA4MEuyMgo2PEFXfnt8mUZnntOj+3b\nLVvxVaqI+OCDXKSnC5g2reArxK1fr0CvXq64d6/AhxaYXg+MG6fG6tWO/yzKn60x6kYVKwK1ajFZ\njghgUHd6XbroMHy4BsnJUmu6KJapzCtZzsdHtLl+++DBWjRqpMeyZUocPmz/V0+jAWJj1di9W4EV\nKxzffX/woBw//qjCkCHSmH8qWbbGqD8sMFCP1FQZrl1z3n+vWbNUWL+eo5ApbwzqT4AJE3Lxwgs6\nbN+uwLPPumPwYBf8+afcZqvGYAAOHJBh/Hg1AgPdMXKkecpxXslytoL1nDkqKJVAeLgOoiigY0c3\nu6elTUhQ4No16bz/+5/S4a2xDRukMqWnA59/znXnS5qtKWIf5uzJcidPyjB9uhqTJpXdoaGDB7ug\nRw9X9qY4GIP6E0CpBOLjs/Hll9kICDBgwwYlXnnFDaGhbli5UoHcXEAUgaNHZZg0SYVnnnFHly7u\nWLBAhRs3ZFi5UmlKggNsJ9F5eRlMXaWPMk5oM2uW8aJk3oq3xWAAvvxSBaVSRJs2OiQny/HHH467\ncIsisHGjAuXKiahfX5pnPznZeVt/ZcGFCzJ4exvg4WF7H2dPljP+Ri5dkuHGjbL3fUxOFrBhgxK/\n/67Azp3OeeNVWjjnL4AsqNVAnz467NiRhV9+yULnzlocOybDyJGuaNHCHU2aAB06uOOrr9RISxPQ\nu7cWK1ZkYdu2TMhkIj76SG2axe7RJLq6daULapcuOjRsWLQT2mzapMDZs3L07KnDhx9KQ+P+9z/H\ndcEfOSLD1asyvPyyDjNmADqdUKZbR2WdVgv8+6+QZ9c78Hgt9ZwcYMYMValdFEYUpcWRjP78s+wF\nxfj4B+X/6iv2fjkSg/oTRhCA1q31WLgwBwcOZGL4cA1ycwVcvAh07arFjz9m48SJDHz1VQ6Cg/Vo\n3tyA11/X4vRp8+FoDyfR9eghJdAFB+sLPaGNtSFyoii10gVBxDvv5OLZZw1o0kSPTZsUDmutbNwo\ntYg6d9YhIgJo3VqHLVuU2LOn7F1IncGVKwL0esFiethHVaokomZNA44cKXiy3KpVSsycqS61sx4e\nOiTD5csyNGgg3Tzv21e2vot6PbBypRLlyol48UUd9u5V4K+/GHochTX7BKtdW8THH+fi+PEM3LkD\nLFiQgy5ddBazdo0bp0G5ciJmzFBbTRwzrsrWtq0uz6Fwtp7F20qumz5dhcOH5ejcWYf69UUIAjBw\noBZ6vYClS4u+tS6KwIYNSri5iWjfXppAZ9IkqXcgLk4NQ96NRXIA4+OcvJ6nGxmT5a5fL9gN3y+/\nSDdyGzYoSmVipLGVPmGCBq6uYplrqe/eLcf16zK8+qoWY8ZIN/1srTsOgzpBrYbNpVwBoHJlEe+/\nLw1H+/RT8x9jaqqAv/+WoVUrPTw9pW22hsLZasXbmsr2+++lzxo16sFxPXtq4eEhYskSJXRFvNLm\nmTMynDsnQ3CwDm5u0rbmzQ3o0UOLf/6RY9UqZh4XN3sy340K0wV/+7aAP/6QQyYTodEIiI8vXf/G\nOh2wbp0ClSoZEBKiQ4sWepw6JUNaWkmXzH7GrvfISC2CgvR4+mmpt425Ko7BoE52GTxYiwYN9Fi0\nSIkTJx58bXbtkkMUBQQH5z//66OteF9f6RhbraPMTAFt2+pw4YLM1DXfubMbWrbU4/p1GbZuVVjt\nti+sh7veH/Z//5cLFxcR06apkZVV6NNTIeQ3Rv1hDyahsf+ytmmTAnq9gHfe0UCtFrFkiapUZWf/\n9pscqakydOumg1IpPToTRQEHDpSN1np6ulTH9evr0bKlAYIAjBypgSgK+PZbttYdgUGd7KJUApMn\n58JgEDBhgtp04du507gqm33N5odb8fv3ZyE8XAvA9h17ixZ6i6753bulz/z0U5XNMfGFsXGjAkql\niNBQ879LzZoihg3T4Pp1Gb77jhei4lSQlnpgoLTP/v32B7x166TvSv/+WnTtqsO5czLs3Vt6Aqax\n6717dylLtXVr43P10tWjYMvatUrk5gqIjHywHkSnTjr4+hoQH6/EzZtlt7UuisDp0zJ8+60SvXu7\n4t131aXihpBBnewWHKxHaKgOf/yhwKZNChgMUku9alUDmjQp3APn99+33iUPSM9Rt2yxfvFycxNx\n8qT1i29+y8Nac+mSgKNH5WjbVo9y5SzfHzVKg8qVDZg7V1WmL0RlzYULAipUEFGhQv77Vq4sonVr\nHfbssa9rNzVVwJ49crRooUft2iKioqTAuWRJ6VifIDtbutGsXduAZ5+Vfl8tW+ohl5ed5+orVigh\nk4no1Utr2iaXA2+/rYFGI+D770tHXdsrPV2a3XLMGDWeftodbdq4Iy7OBbt2KbBsmQqrV5f8zRaD\nOhXIpEk5UChExMWpceCAHLdvy8xWZSuopk0N6NpV+sHXqiV1y1eoIF3APvooF2fPWv+K5uTYPmde\nM97ZsmmT9a53I09P4IMPNMjKsswreBIcOiTDgAEuSEoqvs/U66Vx2fa00o3eeEP6Li1YkP+/kbHr\n/ZVXpGOee04Pf399qUmY275dgcxMARERWtPvy8ND6pE4ckRW6h8FnTkjw19/yfHSS3pUq2behO3T\nR4vKlQ343/9UuH+/hApYQJ98okKjRh4YMsQVS5eqkJ0t4NVXtZg7NxubNmXCxUXExInqYpnKOi8M\n6lQgfn4i3nxTi8uXZRgxQkqT79Dh8dZTfe89DQRBao0dPJiJzEwB9evr0amT7Yz5hg0NkMut93UZ\nj8nrefuj7y1eLLUoOna0/Rjh9de1aNhQmuZ2/nwl1q5VIDFRjgMHZDh1SlrPOzPzMSqiFDIYgLlz\nVeja1Q2bNysxcCCKPEHRluvXBWg0+Y9Rf1h4uA7VqhmwYoUy32BhzHrv2lX6CwmC1A1fWhLmjK2+\n7t3NK7x1az10OgFJSaW7tW6sw8hIrcV7Li7A0KFa3LsnYPFi2631mzcFxMWpS/yRyIYNCnzxhRrV\nq0tJw5s3Z+LEiQzMn5+DyEgdnnnGgOhoDW7dkuGzz0p2aCSDOhXY2LG5qFzZgCtXZJDLpaFsj6Nx\nYwNefVWHo0fliIpyhVYrJS7JZLYz5qOjNXj5ZeufO3q0xuZKcmvWKKy+d+6cHPXrG+DtbfuhmEIB\nTJxozCtwwdChroiMdEOXLu5o29YdTz/tgYYNPUzBoqy7dUtAnz6umDJFjcqVRbRrp8PRoyi25XPt\nmR72UUqlNOwxM1Mwm/DkUampUtZ7y5Z61Kr14N+8d29tqUiYS0uT8lUaN9ajcWPzv7/xuXpp7oLX\n66Xx/+XLiwgLs/47HThQA3d3EfPmqaB55GcuisDKlQq0aeOOb79VYcKEggXKe/eAiRPV2LhRYZo0\nq7AuXxYQHe0CV1cRP/2Ujfff16BlSwPkj1T/229r4OtrwA8/mCcTFzcGdSqwcuWAmBjpV/jMM3qU\nL//453zvPQ1kMhFHj8pRvbrBNKFNXuPep0zJhSCIcHERLd7La/Y6W++lp+ff5dqhgx7bt2fi66+z\nMX16Dv7v/3IxalQuBg7UoEcPLeRyICZGXeAV8UqbXbvkaN/eDbt3KxASosOvv2bhm29yUK4cMGOG\nGnfuOL4MBRmj/rDXX9dCpRKxYIHK5twCUk6IYHr0Y+TlhVKRMLdxoxIajWD6HTzsueekbY87CU1m\nJvDDD/n3aBTG7t1y3LghQ0SE1mLeC6MKFaSekRs3ZGbPoq9fF9C/vytGjnSFRiP9+x87JsfFi/Y/\nElm4UIVvvlFh0CBpxsxPPincjIFaLTBsmCvu3RMwfXqOzRkzAan3Yfr0HOj1AsaNK7mkOQZ1KpTX\nXtPiww9zERtrY5B5ATVo8CCQDx+ugeqhuGtr3HutWiJCQ/XIyRGweXOW2Xt5zV5n6z3jOu/GrnmF\nAlaHyTVrZkCvXjoMGaLF6NEaTJigwaef5uLbb3MwcqTUBffll6X3ufvWrXIsXKjE1q1yHD0qQ0qK\nYAp+Wi0wZYoKffq4Ii1NwMcf52Dp0mxUrizC21vExIlAWpqATz5xfBejcR31/GaTe5S3t4hXX5UC\n865d1gOfMevd2PX+sNKQMJeQIJXv1Vctm5kVKwING+rx11/yx2qFfv65GjExLpg6tej/LZcvfzA2\nPS/DhmmgUIj4+mvpBmz5cql1vm2bAm3a6LB7dyaio6VrjHGhJXusWSONZBk0SIPsbAFffKHGM8+4\n4/XXXbF9uxx6O58YTpumxl9/ydGjhxavvZZ/j2RwsB6dOmnx558K/PxzyfTYCaJYGpLwCy8lpeC3\nmd7enoU6zpmVhjq5exf45Rcl+vbVQmnn9XTnTjlee80N/fppMGvWgxuMdu3crGbHN2mihyjC5nuj\nR2swbJjlTDzGHoA1axSYPVuFM2dk8PeXnqMZbyQAqfXzwgvuuHNHwN69mWZdu6XBrFkqTJ9ueRFX\nqURUrSrN2nfpkgx16hgwf342nn7avGVSoYInAgL0OHdOhh07stC0aeGn2cvMlFpl9etbr6NBg1yw\ncaMSx45lwMenYPX4998yvPyyO0JDdVi2LNvsvdRUAU2buuPppw3YvNky20wUgTZt3HDxogxHjmSi\nUiXbn+2I382NGwKaNXPHs8/qsWFDttV93n9fjUWLVNiyJRMtWhT83+DmTQGtWrkjO1uAUili795M\n1KljXx2fPSvDtm1y9O2rhZeX5fsKhSeqVhVRt64Bv/+elW8S7TvvuCA+XokmTfQ4cUIODw8REyfm\non9/KUHwzh0gIMADzZoZsGVL/tmBZ87I8OKL7ggL02Lx4hxkZko3cYsXq0x5CLVqGRAbm4tu3Wwn\n+RqvLfXqGbBjR2aeCwo97MoVAS++6A4PDxH79mWiXLmi/554e3vafI8tdSo1vLyAAQPsD+gA0L69\nHrVrG/Dzz1LL0yivOejzei+vbvu8ntMbubtLS93m5gqYPNm+FpAoSheixEQ5li1T4rPPVBgzRo3I\nSFe0a+eGHj1ccfXq42djz5unxPTpatSqZcDcudmIjc3Fm29q0LmzFk2bGqDRSEG2Rw8tEhMzLQI6\nYHu+goLKyAC6dHFDUJA7fvrJeovmwgUZ3NzEPPMcbGne3ICWLfXYsUNuavEbbdwodb0bs94f5aiE\nOa0W2L5djqFDXRAV5YJDh6xffqV1DwSLBLmHPe5z9blzpezt4GAdtFoBn35q33c1NxeIinLFxx+7\noFUrD3z7rdJiRsgVKwCNRkBkpNauUTEjRki/xxMn5GjfXofffstEVNSDYytWBF54QY+kJLldv4O1\na429HFL9ubsDffvqsGVLFnbuzERUlAa3bgkYOtQVvXu74vx5y3Nevy5g5EgXqFQivv8+2+6ADkg9\niNHRGqSkyOyu16LEljoBKNt1kpgox6BBrsjJkQLOm29KF4Q1axSYM+dBq3r06AetauN7J0/KIIoC\nJk3KwVtvaVGtmgf0essfuUIhokEDg80W/q5dWaZW/OnTMqhUQE6OgA0bMtGqle2WlE4HjBjhgjVr\nrN/JuLuLyMwUULOmAT//nIV69Qr3c120SIn333dB1aoGrFuXZbNLWxSR54XY+D2JinLBli1KfP99\nNrp1K1iipF4vBYbt2xWQyUSIIjBrVg769n1wHlEEfH094OtrwK+/Fm7s1urVCgwf7ophwzSYPPlB\n5OnRwxW//65AUlIGata0Xg937wKBgR6oWVNqxdqqk/x+N8YljVeuVCIhQYHUVPNAHh6uxf/9n8Zs\nlEdoqBuOHZPh6NFMVK5svXxXrwp4+mkPU2u0IK5dk1rpVauK2LMnE2FhbjhxQoZdu7IskvIe9dln\nKnz2mRrPP6/DiRNypKcLqFPHgI8+ykWXLlKrt0sXTxw6JOLIkUxUqWLf93XlSgWUSikQW6vrhQuV\n+PBDF0yZkoOhQ2136YsiEBTkhqtXZTh+PMNmML5wQcD48S5ITFRArRbxzjsajBqlgYuL9P3s0cMV\ne/cqMH16DoYMKfgzjtxcoG1bd1y6JGDHjiy0b+/OljqRvYKD9Vi7Ngve3iImTHBBTIwaOp3tZ/GA\n9N6GDVlQqYDGjfV46y3ph2trCJ2/vyHfVeaMrXiDQUBOjnRlGjnS1WaylsEAREdLAb15cz3GjcvF\n3LnZWLUqC3v2ZOL8+fs4fz4DMTG5+PdfGV55xa1QWbUrVyrwwQdqVK5swOrV2Xk+o7Z3voGPP86F\nSiWNyy3oeOmJE9XYvl2Bl17SYdu2LHh5iXj3XRezFvutWwKysgo2nO1RXbvq4ONjwPLlSlPiYkqK\nNOFMy5Z6mwEdeLyEubt3gaQkKa+iXTs3hIS4Y/58KZv+jTc02LYtE7/8koVnn9Vj82Yl2rZ1w+jR\nLrh6VUBysoAjR+Ro315vM6ADQI0aImrVMmD/fkWBFxqaNUsFjUbA2LG5UKuBmJhciKKA6dPzzgM5\nd07AnDkqVK1qwNKl2di/PwNDh2pw9aqAIUNc0aWLG+LjFThwQPpN2hvQAaB3b2kxKFvfv06ddBAE\nEevX591zcvy4DMnJcoSG6vJsXfv6ili+PBsLFmSjYkURn3+uRtu27khMlGPmTBX27lWgUyctBg8u\nXNKCWi0lzRkMxZ80x6BOTuHpp6XnbY0b67FggQpRUa75ZqAnJiqQmyugU6cHwT6vrvm8Ar6tbvuL\nF2UYP15tdVnZDz9UY+VKJVq00CMhIQtjxmgQGalDu3Z6NGhggIeHFGSjozWYPj0Ht27J8OqrbkhK\nsv9n+8svCowa5YLy5YGVK7PRoEHRLDXn6yti+HANrl4tWFLgwoVKzJunQsOGevzwQzYCA6UbjUcD\ne0Gmh7VFpZKS3u7dE1QfRuYAABc+SURBVLBqldQTYsx679Yt/4u1rYQ5UZRuDg4dkuGnn6TW69tv\nuyA83A0NG3qgYUNPhIW5Y/JkNc6fl6FLFy0WL87CkSOZmDYtF82bG9C6tR4bNmRh8eIs+PtLNx6t\nW7tj+HApn8M4LWxeWrfW4+5doUCTLV2+LOCnn5SoV09K9gSAkBA9WrWSlhg+eND6uUQR+OADF2g0\nAqZOzYWnp9QtPmVKLv74IxOdO2tx8KAc77wjlT+/BLmCqlJFxHPP6XHggDzPGR0f7XrPiyBIN257\n9mTirbc0uHJFQGSkGz7/XHpENXt2TqEn1QKkG5vOnbU4cECBJUsKf56CYvc7AXCeOrl/H3jjDVf8\n+qsCAQF6LFuWjerVzb/ioiglI73/vgu2bVMgMTHTLOHrQbe9HP7+elO3vbE1/qh587Lx9tsuVrvt\nARHW5rYPDdVi+3YlatY0wM1NxLlz1hPvHrZiheK/8bLA0qXZCArKO4V32zY5Bg50hYsL8PPPWYVK\nqHrUw9+TjAwpKTAtTcCePfknBSYmytGvnyu8vERs3pxllph1/LgMPXq44u5dAbNm5UAmA0aNcsXM\nmTno37/wAeLmTQFPP+0OPz8DfvstCz17Sl3vhw9noEaNvMv7cMLcwIFaXL4s4NIlGS5dkiEry/Lf\nVKkUUaeOAb6+IurVM6BxYz3Cw3VWk8keJo3pVmDGDDWuXpXB1VXMs+vYaMkSJcaOdcGnn+Zg4ED7\n6ig6Wo2fflLhm2+y0bPng+/Zn3/K8corbggK0iEhIdsimK1apcCIEa4IDdVh6VLL943nmDRJjdxc\nOTZtug91ET9Onj9fiQkTXDBjRg4GDbL8+4oi8Oyz7rh9W8CJExl5rjxpzbFjMnzwgQtOnJBh1aos\n09S8j+Pff6WkuXbtBCxaVDzd7wzqBMC56kSnA8aNU2PxYhWqVDHgww81uHFDQHKyDMnJ0vKqmZnS\nValuXQP277f+zNRandh6Tm8r214uF20Ee6BqVQNu3LBsGeWVaa9UAsOGuUAuBxYsyEZoqHlg1+ul\nZ6YHDsgRHe0CmQyIj882JVY9rkfrxHix79pViwULbD/bPXlShi5d3KDRAAkJ1i+YxsB+544MTz2l\nx9GjciQkZOHFFx+v7G+95YKEBCW++066+WrRwoBNm+x7ZvDDD0rExDwYaO3hIQXuOnUMqF1bRECA\nCt7eWahXz4CaNUUoHiOvLidHWqbUx0dEeHj+Lc2zZ2UICnJH9+5afPdd/s/Vz58XEBTkjvr1Ddi1\nK8ti8pS+fV2xY4cC8fFZaN/+QZ3fvQsEBbkjM1PA779nonbtvEOGo64lxjyCNm10WL3aclRAUpIM\nYWHu6NlTi2++KViegZEoSnPuG5deLgpnz8pQs6Y7XF0Z1O3CoF40nK1ORBH49lslPv5YDVF8EFRd\nXET4+hpQv770X5cuOjz1lPU78oLUia1WvCCIZp//UAlRv74ByckFH1pXvryIQYNcodVKU23evy8N\nQ7t8WZqqVquVPk+lErF0aTZeeqloAjpgWSeiCHTu7IZDh+Ro3VqHNm30aNNGj5Yt9aZRDLduCQgP\nd8OVKzLTDYstDwd2AHa1qPNz6JAMnTpJQ4wyMgRMnpyDYcPsa9nq9dJEKl5eUjD38jLPOyjJ340o\nAgEB7lCpgMOHbSfzGQ0f7oLVq/+/vTsPjrK+4zj+3uyyZAK0CLmUo4LcCjVtSUEjqHFUDtsihQIa\njwEVU0SnQDhqxJqKCdA2Im1lGpjWKBiH2pZalVZGZiImoWEEOSyCB2rlSFKaNOYgu/v0jzWXeyTZ\n7BH2+bxmGGafhyd59pss3+d3fX+92Lq13uv6/MOHY0hP78M3v+lk9+46Yr583ly2rDeFhXaysxt5\n6CHfGzA1C2VMpk2L4+DBGI4c8VxqmJ3dmy1b7Dz/fB033xy83/lgCOeSNiV1AaI3JqWlVo4ciWH4\ncHcSHzzYaPnPqiNdjYm3Vnx+vt1rC37ECCcffRQT8Ez7DRvs/OIXdlyu1usTEtytR3cr0sWttzqC\n0uXelreYnDgRw9KlsbzzTkzL/cTFGUye7OS66xz89a+9OHDASlZWI8uXd5wUmhO702nh+PHaTv+8\nfDEMuOWWOA4edMfz4MFajyGZQEX6c9O8lr+8vNZvC/r48RimTIlj3DgXe/bU+YzpAw+4J24WFNTz\nve85KCuzctttcYwd6+SNN+o6tdw0lDHZvLkXTzwRy69+1cAdd7Q+mLlckJLSh7o6C0eP1rYrXtUT\naJ26SJBMmuRk0aImbrzRvb1mdxOEP95m2/uaeLdihf+Jdx3NtN+woXe7hA7uSUuvvVbHLbc42L3b\nxowZcV4r4gXbyJHuIi7/+lctv/99PQsXXmDwYBd79th4/PFYDhyw8sMfNrFsWccJHeDKK93dw6+8\n4jv5dIXFAgsXur/3xInOoCX0nqCz69U3bLBjGBZWrmz0G9OVKxuxWg1yc+3U10NWVu8vr2/oUv2I\nUJk5093D8NVZ8Pv3Wzl92j0psacl9HCLjp0nRHood1dzPXl5dj76yL2N6MqVrZPhvHWx+2vh+5tp\n37yPfNuv2VwgB/x3ewMdVsvrSP/+7qVHzasJzpyxUFzs/s/2/vsvdGkmcXKyu8JdsPzgBw4OHrzg\ntdv5YtY2qc+d6/29HTkSw65dvUhJcXLLLf67pYcPN7jjjiaee87O7NnueSIZGRf81loIp8svNxg/\n3klxsZXqalr2nWh+cO1qzYRopJa6SIjNmuWgtLSOs2drKS1tXS/vb7Maf0vr/LXiO0r4vraj7aha\nXkf18L1JTjaYM8fRUtQjktzrhhu55pqeNdbaXVde6aJPH8NvS339evfPfuXKxk49WC1bdoHYWIPy\ncivx8a6g7e8QLDNnuqvg7d7t/h10ONwt9/h4V7cnVUaDkCb1devW8aMf/Yh58+bx7rvvtjtXWlrK\n3LlzmTdvHqtXr8blclFWVsakSZPIyMggIyODnJycUN6eSMT5KpDjL+EHo0DOVxN358vj4rGNbWf3\nrA/1MIAZ2WyQmurk5EkrFRXujN1cdvjpp+1MmxbH66/3YuJEZ7sZ7f5ceqnB/fe7Hypzchrp3z9k\ntx+Q5p31mjd42bfPSmVlDLfd5ujW6oNoEbIQ7N+/n1OnTlFUVMQHH3zAmjVrKCoqajn/2GOP8dxz\nz5GcnMzSpUspLi4mNjaW1NRUNm3aFKrbErlozJrl8Nr9/cgj3mfGd6fbPpDW/xNPuNdVN2vb1Q+B\nDwNI10ya5OTNN2384Q+9qK218PrrNj780P1zsVoN0tIc5OZ2rpXebPXqC8ye7eiwbGwkjBhhMGaM\n+z3X1nat4IwZhKylXlJSwk033QTAFVdcQXV1NbVtSny9/PLLJCcnAzBgwADOnz8fqlsRiSqh6LYP\npPXva3MNf3vWdzQMIF3XPK6+fn1vfvMbO2fOWJg5s4nNm+s5dqyWl1+u9/nz9cVqpUcm9GYzZjho\nbLTw6qs2XnmlF8nJLr77XXW9QwiTemVlJZe0KaU0YMAAKioqWl73/bJc0rlz59i3bx9Tp04F4OTJ\nkyxevJj58+ezb9++UN2eyEUt2N32gZTH9cXfnvUdDQNA4AnfrA8K3/mOkzlzmrjzzgu88IJ7FcK2\nbQ3MndtxNbuLVfMs+J//vDfV1Ra+/31HSFe2XFSMEHn00UeNf/zjHy2v582bZ3z44Yft/k1lZaUx\na9Yso7i42DAMwzhz5ozxt7/9zXC5XMapU6eMqVOnGo2NjX6/T1OTI/g3LxKFduwwDPeIa/s/O3a0\nnp8wwTBsNvffbY97u27IEO/HJ0wwjPHjAzvXmXscP94wrFb33x3dY/N5iS4ul2GMHNn6cy4tjfQd\n9Rwhe5RNTEyksrKy5fW5c+dISEhoeV1bW8t9993HI488QlpaGgBJSUlMnz4dgKFDhxIfH8/Zs2cZ\nMmSIz+9z/nzXt2WMdMGInkgx8RRtMUlPhy1bPAvkpKc7qKhwn09Pb39N8/HW61rr4YP3JXk//rHn\nmHrbc5mZsXirh3/smMETT7gAzzkBOTlOamrazyU4fBjmz4eamvovu/u9X5eeXtft5Xq+RNvvSDCE\nKybTptk5caI3Q4e6GDbsC9p0BPc4UVF85tprr2X37t0AHD16lMTExJYud4Dc3FzuvvtupkyZ0nJs\n165dbN26FYCKigqqqqpISkoK1S2KmI6/7Wg7c11TEy3X+evqD8Xs/UAn+oWqu18i6/bbHdhsBgsW\nNHVrN7VoE9IysRs3bqS8vByLxcLatWs5duwY/fr1Iy0tjYkTJ5KSktLyb2fOnMmMGTNYvnw5NTU1\nNDU1sWTJkpaxdl9UJjY4FBNPiomnYMTE3253vmbvjxvn5PjxwMrqGgY+z/mrsQ/4bN23tvzdPRfB\navlHg3B+bs6etRAfb3hsTtPTqPZ7FyipB4di4kkx8RSsmPja7S7QhO8vOfvaFtffw8CgQa52y/Xa\nfj3wPrTgb3c9MyV8fW48hTOpq59JRMLO1xr85rK63hI++C6r6++6/HzviXvUKBfHj3d9uZ6vZlBn\nyvT6S/hmfxiQ4FBLXQDFxBvFxFOkY+Krhd/RNV1t/YOBt8l8NpuBYRDQMEBHXf3R0vqP9O9IT6SW\nuoiIF75a+B1d09XW/6BBhtfW+qhRLp9j9P5a/h1N9FPrX4JFSV1Eol5Xu/vBd1e/v3P+yvT6S/i+\nknpnNunxlfD9nfP3MKAHgYubkrqImJrv1r/v1n3rudZ1+93ZTrentP7/+c8LFBTYPY53pldAegYV\n1hMR8cLfmn5v6/abjwdSlz+QMr0dresPZM1/YWEvr8c9d+vr2va8Kv0bPoqQiEgQBTqzP5BZ/8Fu\n/Tf62Do9UsMAgc4lMDMldRGRMPE30S/Yy/z8nfP1MNC7t/fEHolJgIE+RASa8KPlIUHd7yIiPVwg\nu/IFMhSQkdHk9Xi4hwE6Kv3r7zp/wwS+uvO7U0q4pw0RaJ26AIqJN4qJJ8WkvYs5Hv6q+gWz2p+/\nMr2Blv4N5Dp/VQIDrVYIna0vENxywioT+xUX8wcxVBQTT4qJJ8WkPbPFI5CED74TX6DJNJA9AnwV\nFIrEvgLdTewqPiMiIt3WuXF/z2V+wS796+8631UCvWv+2uGsLxDKsXq11AVQTLxRTDwpJu0pHp66\nGpNASv/6u85Xr4Gv7vfu9AoEOrTw+ee1Hb4/f9RSFxGRHimQ0r/+rgukSmA4Vxj4mnAYLErqIiIS\nVQKpEhjO+gKhpO53ARQTbxQTT4pJe4qHJ8WkVesQgbd5BoFT97uIiEiYNbf+3Q86dWH5nio+IyIi\nEiWU1EVERKKEkrqIiEiUUFIXERGJEkrqIiIiUUJJXUREJEooqYuIiEQJJXUREZEooaQuIiISJS76\nMrEiIiLippa6iIhIlFBSFxERiRJK6iIiIlFCSV1ERCRKKKmLiIhECSV1ERGRKGGL9A2E27p16zh0\n6BAWi4U1a9YwYcKESN9SRLz//vtkZmZyzz33cOedd3L69GmysrJwOp0kJCSwYcMG7HZ7pG8zrNav\nX8+BAwdwOBw88MADjB8/3rQxqa+vZ9WqVVRVVdHY2EhmZiZjxowxbTzaamhoYObMmWRmZjJ58mRT\nx6SsrIyHH36YkSNHAjBq1CgWLVpk6pgA7Nq1i4KCAmw2G0uXLmX06NFhi4mpWur79+/n1KlTFBUV\n8eSTT/Lkk09G+pYioq6ujpycHCZPntxybNOmTSxYsIDt27fzjW98g507d0bwDsOvtLSUEydOUFRU\nREFBAevWrTN1TN58802uuuoqnn/+efLz88nNzTV1PNr67W9/y9e//nVAnxuA1NRUCgsLKSwsJDs7\n2/QxOX/+PL/+9a/Zvn07zz77LHv27AlrTEyV1EtKSrjpppsAuOKKK6iurqa2tjbCdxV+drud3/3u\ndyQmJrYcKysrIz09HYAbbriBkpKSSN1eREycOJGnn34agK997WvU19ebOibTp0/nvvvuA+D06dMk\nJSWZOh7NPvjgA06ePMn1118P6HPjjdljUlJSwuTJk+nbty+JiYnk5OSENSamSuqVlZVccsklLa8H\nDBhARUVFBO8oMmw2G7Gxse2O1dfXt3QHDRw40HRxsVqtxMXFAbBz506mTJli+pgAzJs3j+XLl7Nm\nzRrFA8jLy2PVqlUtrxUTOHnyJIsXL2b+/Pns27fP9DH57LPPaGhoYPHixSxYsICSkpKwxsR0Y+pt\nqUKud2aOyxtvvMHOnTvZtm0bN998c8txs8bkxRdf5L333mPFihXtYmDGePz5z3/m6quvZsiQIV7P\nmzEml19+OUuWLGHatGl8+umn3HXXXTidzpbzZowJwH//+182b97M559/zl133RXWz46pknpiYiKV\nlZUtr8+dO0dCQkIE76jniIuLo6GhgdjYWM6ePduua94siouLefbZZykoKKBfv36mjsmRI0cYOHAg\nl156KWPHjsXpdNKnTx/TxgNg7969fPrpp+zdu5czZ85gt9tN/TsCkJSUxPTp0wEYOnQo8fHxHD58\n2NQxGThwICkpKdhsNoYOHUqfPn2wWq1hi4mput+vvfZadu/eDcDRo0dJTEykb9++Eb6rnuGaa65p\nic3f//53rrvuugjfUXj973//Y/369WzZsoX+/fsD5o5JeXk527ZtA9zDVnV1daaOB0B+fj5//OMf\neemll5gzZw6ZmZmmj8muXbvYunUrABUVFVRVVXH77bebOiZpaWmUlpbicrk4f/582D87ptulbePG\njZSXl2OxWFi7di1jxoyJ9C2F3ZEjR8jLy+Pf//43NpuNpKQkNm7cyKpVq2hsbOSyyy7jqaeeolev\nXpG+1bApKirimWeeYdiwYS3HcnNzefTRR00Zk4aGBn76059y+vRpGhoaWLJkCVdddRUrV640ZTy+\n6plnnmHQoEGkpaWZOia1tbUsX76cmpoampqaWLJkCWPHjjV1TMA9bNU8w/3BBx9k/PjxYYuJ6ZK6\niIhItDJV97uIiEg0U1IXERGJEkrqIiIiUUJJXUREJEooqYuIiEQJUxWfERG3zz77jFtvvZWUlJR2\nx6dOncqiRYu6/fXLysrIz89nx44d3f5aItJ5SuoiJjVgwAAKCwsjfRsiEkRK6iLSzrhx48jMzKSs\nrIwvvviC3NxcRo0axaFDh8jNzcVms2GxWHjssccYMWIEH3/8MdnZ2bhcLnr37s1TTz0FgMvlYu3a\ntbz33nvY7Xa2bNkCwLJly6ipqcHhcHDDDTfw4IMPRvLtikQVjamLSDtOp5ORI0dSWFjI/Pnz2bRp\nEwBZWVmsXr2awsJC7r33Xn72s58BsHbtWhYuXMgLL7zA7Nmzee211wD3NqUPPfQQL730Ejabjbfe\neou3334bh8PB9u3befHFF4mLi8PlckXsvYpEG7XURUzqP//5DxkZGe2OrVixAnDXrwb41re+xdat\nW6mpqaGqqooJEyYAkJqayk9+8hMA3n33XVJTUwGYMWMG4B5THz58OPHx8QAkJydTU1PDjTfeyKZN\nm3j44YeZOnUqc+bMISZGbQuRYFFSFzEpf2PqbatHWywWLBaLz/OA19a21Wr1ODZw4ED+8pe/8M47\n77Bnzx5mz57Nn/70J2JjYwN5CyLyFXpEFhEPpaWlABw4cIDRo0fTr18/EhISOHToEAAlJSVcffXV\ngLs1X1xcDMCrr77KL3/5S59f96233mLv3r18+9vfJisri7i4OKqqqkL8bkTMQy11EZPy1v0+ePBg\nAI4dO8aOHTuorq4mLy8PgLy8PHJzc7FarcTExPD4448DkJ2dTXZ2Ntu3b8dms7Fu3To++eQTr99z\n2LBhrFq1ioKCAqxWK2lpaQwaNCh0b1LEZLRLm4i0M3r0aI4ePYrNpmd+kYuNut9FRESihFrqIiIi\nUUItdRERkSihpC4iIhIllNRFRESihJK6iIhIlFBSFxERiRJK6iIiIlHi/x48pSoEV1mfAAAAAElF\nTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f975cafeef0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "6hXx-xOv-llh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "01dde93c-3736-4469-b422-e64e57d2656a"
      },
      "cell_type": "code",
      "source": [
        "plt.clf()   # clear figure\n",
        "acc_values = history_dict['acc']\n",
        "val_acc_values = history_dict['val_acc']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f975cafe7f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "oFEmZ5zq-llk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this plot, the dots represent the training loss and accuracy, and the solid lines are the validation loss and accuracy.\n",
        "\n",
        "Notice the training loss *decreases* with each epoch and the training accuracy *increases* with each epoch. This is expected when using a gradient descent optimization—it should minimize the desired quantity on every iteration.\n",
        "\n",
        "This isn't the case for the validation loss and accuracy—they seem to peak after about twenty epochs. This is an example of overfitting: the model performs better on the training data than it does on data it has never seen before. After this point, the model over-optimizes and learns representations *specific* to the training data that do not *generalize* to test data.\n",
        "\n",
        "For this particular case, we could prevent overfitting by simply stopping the training after twenty or so epochs. Later, you'll see how to do this automatically with a callback."
      ]
    },
    {
      "metadata": {
        "id": "h157y2CHRdqB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 提取倒数第一层的特征"
      ]
    },
    {
      "metadata": {
        "id": "Ok8oY5juS1RJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1e963564-e13a-4d42-d571-5b4274409337"
      },
      "cell_type": "code",
      "source": [
        "model.layers[-2].name"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dense_12'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "S6vC1hdLRcsb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dense_layer_model = keras.models.Model(inputs=model.input,outputs=model.get_layer(model.layers[-2].name).output)\n",
        "dense_output = dense_layer_model.predict(split_features(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kpUw3VU2cl1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c8e53fa3-e292-4c28-bd84-d2677a95fac6"
      },
      "cell_type": "code",
      "source": [
        "dense_output.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(742861, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "CEEZKfIETTkH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "fe146ca2-110c-4113-e826-c956d5d5e276"
      },
      "cell_type": "code",
      "source": [
        "dense_output_csv = pd.DataFrame(dense_output)\n",
        "dense_output_csv.head()\n",
        "dense_output_csv.to_csv('deep_features.csv', index=False)\n",
        "\n",
        "y_label = class_label.inverse_transform(y)\n",
        "y_label_csv = pd.DataFrame(y_label)\n",
        "y_label_csv.to_csv('deep_feature_labels.csv', index=False)\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "6pne6pZ4eEYt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上传文件到谷歌云盘"
      ]
    },
    {
      "metadata": {
        "id": "SeDWlvn7eDuA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "759166ea-9326-47de-d494-91e24dc33d7c"
      },
      "cell_type": "code",
      "source": [
        "#保存文件\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "# Create & upload a text file.\n",
        "#你想要导出的文件的名字\n",
        "uploaded = drive.CreateFile({'title': 'deep_features_googledrive.csv'})\n",
        "#改为之前生成文件的名字\n",
        "uploaded.SetContentFile('deep_features.csv')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1bYSZZA3F5Ey2rElD_07sNOgmTclonIHp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DEwk5tUwZ6nK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predict Label"
      ]
    },
    {
      "metadata": {
        "id": "puMruz2z9eCr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "How to predict https://blog.csdn.net/baimafujinji/article/details/78385745"
      ]
    },
    {
      "metadata": {
        "id": "T7C2nYlM7dA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "be81d97f-ad14-4130-f898-f575a6b91f87"
      },
      "cell_type": "code",
      "source": [
        "predict_data = pd.read_csv(\"https://github.com/never770/mobile/raw/master/test_datas.csv\")\n",
        "#predict_data.head()\n",
        "\n",
        "Xnew = predict_data.drop(['user_id'], axis=1).as_matrix() #Xnew = predict_data.iloc[:, 2:(predict_data.shape[1])].as_matrix()\n",
        "#Xnew = np.column_stack((Xnew[:,:-1],Xnew[:,:-1]-1))\n",
        "\n",
        "ynew = model.predict(split_features(Xnew))\n",
        "ynew_arr = np.array(ynew)\n",
        "label_tmp = np.argmax(ynew_arr,axis=1)\n",
        "#label_proba = ynew_arr[label_tmp]\n",
        "\n",
        "ynew_ = class_label.inverse_transform(label_tmp)\n",
        "sub_filename=predict_data['user_id'].tolist()\n",
        "submission = pd.DataFrame({'user_id':sub_filename, 'current_service':ynew_})\n",
        "submission = submission[['user_id','current_service']]\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "yHXKpuxjeECd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_predict = model.predict(split_features(x))\n",
        "y_predict = np.array(y_predict)\n",
        "y_label_predict = np.argmax(y_predict,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Bxnpa5d9ooT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    #print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KQhu71BSDQBW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1159
        },
        "outputId": "199a5cb2-b1f9-490f-ab43-f6f414dfcca6"
      },
      "cell_type": "code",
      "source": [
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y, y_label_predict)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure(figsize=(8,8))\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_label.classes_,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plt.figure(figsize=(8,8))\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_label.classes_, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "Normalized confusion matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAIpCAYAAAC43dIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngqBiiUAmCIIgCIKK5f8BfTDCu9vb/4gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f97eb1a7b38>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAIpCAYAAAACflphAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuw1xAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f97eaedb518>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "O0mLD1euBlH8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "针对每个类别给出详细的准确率、召回率和F-值这三个参数和宏平均值，用来评价算法好坏 https://blog.csdn.net/akadiao/article/details/78788864"
      ]
    },
    {
      "metadata": {
        "id": "JXgOILQ4_2ud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "ff482cbb-6a45-42d5-f07c-5d3d6e5d568a"
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(y, y_label_predict, target_names=class_label.classes_.astype('str')))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "   89950166       0.89      0.93      0.91    133140\n",
            "   89950167       0.86      0.82      0.84     73820\n",
            "   89950168       0.93      0.94      0.93     33423\n",
            "   90063345       0.99      1.00      0.99    286364\n",
            "   90109916       0.99      0.99      0.99     38089\n",
            "   90155946       0.98      0.84      0.90     21966\n",
            "   99999825       0.92      0.92      0.92     20336\n",
            "   99999826       0.70      0.83      0.76     29047\n",
            "   99999827       0.70      0.73      0.71     32521\n",
            "   99999828       0.85      0.74      0.79     52928\n",
            "   99999830       0.77      0.66      0.71     21227\n",
            "\n",
            "avg / total       0.91      0.91      0.91    742861\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WSwgaSIMqdYv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "e5c17118-9680-41dd-d8d7-0a83d8b05f98"
      },
      "cell_type": "code",
      "source": [
        "hard_train_data = x[y_label_predict!=y]\n",
        "hard_train_labels = y[y_label_predict!=y]\n",
        "#print(np.unique(hard_train_labels))\n",
        "#print(np.bincount(hard_train_labels))\n",
        "#print(np.bincount(y))\n",
        "len(hard_train_labels)\n",
        "prob=y_predict[y_label_predict!=y]\n",
        "print(prob)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.7949199e-02 1.5433926e-02 3.5438400e-03 ... 4.1687760e-01\n",
            "  5.2917826e-01 1.2017355e-01]\n",
            " [2.6423114e-03 2.3558596e-03 3.5411151e-05 ... 5.1202639e-03\n",
            "  4.0581659e-03 8.6449413e-04]\n",
            " [5.4874516e-01 1.4818865e-01 4.9636392e-03 ... 6.1192882e-04\n",
            "  6.7117810e-02 1.3104518e-02]\n",
            " ...\n",
            " [3.2603952e-01 1.0743314e-01 1.3764834e-04 ... 2.3921109e-07\n",
            "  8.5756155e-06 1.1708571e-02]\n",
            " [1.3581942e-01 1.8009733e-01 3.8785290e-03 ... 8.8484041e-02\n",
            "  1.2835729e-01 2.2650184e-01]\n",
            " [1.1619221e-01 1.1325046e-01 1.8114707e-04 ... 1.5452715e-03\n",
            "  7.6938428e-02 1.2952482e-02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n3vvyFalWaJU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##保存分类出错的样本"
      ]
    },
    {
      "metadata": {
        "id": "7bw2fkvyUCYA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "error_data=data[y_label_predict!=y]\n",
        "#error_data.head()\n",
        "error_data.to_csv(\"error_data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A0uvjfrrTjPq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns  # 可视化 https://www.cnblogs.com/gczr/p/6767175.html\n",
        "\n",
        "%matplotlib inline\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K7gGTvWuTnX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c3ed8e79-43a8-45a2-a1f6-4364ca3673c5"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(prob[1:10])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhNzAwMDgMscQcgMDA4PLnP8PawvELHG5NjYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f975745a5c0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "z1qp3_Z9sZaj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hard_predict = model.predict(split_features(hard_train_data))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JTvSzt_225fl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b70561c9-7eb2-48e3-f780-69cf89de956c"
      },
      "cell_type": "code",
      "source": [
        "prob = np.max(hard_predict,axis=1)\n",
        "print(len(prob[prob>0.5]))\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jDlWh8xKWiPG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##重新训练分类出错的样本"
      ]
    },
    {
      "metadata": {
        "id": "z9ALgZ5YsYtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "outputId": "d5696aa1-66cd-4093-a6eb-647d49ba9dbb"
      },
      "cell_type": "code",
      "source": [
        "# 'service_type','is_mix_service','many_over_bill','contract_type','is_promise_low_consume','net_service','complaint_level','gender'\n",
        "\n",
        "input_continue_array = keras.layers.Input(shape=(len(train_data[0])-8,))\n",
        "\n",
        "input_service_type = keras.layers.Input(shape=(1,))\n",
        "output_service_type = keras.layers.Embedding(5,4)(input_service_type)\n",
        "output_service_type = keras.layers.Reshape(target_shape=(4,))(output_service_type)\n",
        "\n",
        "input_mix_service = keras.layers.Input(shape=(1,))\n",
        "\n",
        "input_over_bill = keras.layers.Input(shape=(1,))\n",
        "\n",
        "input_contract_type = keras.layers.Input(shape=(1,))\n",
        "output_contract_type = keras.layers.Embedding(13,7)(input_contract_type)\n",
        "output_contract_type = keras.layers.Reshape(target_shape=(7,))(output_contract_type)\n",
        "\n",
        "input_low_consume = keras.layers.Input(shape=(1,))\n",
        "\n",
        "input_net_service = keras.layers.Input(shape=(1,))\n",
        "output_net_service = keras.layers.Embedding(10,5)(input_net_service)\n",
        "output_net_service = keras.layers.Reshape(target_shape=(5,))(output_net_service)\n",
        "\n",
        "input_complaint_level = keras.layers.Input(shape=(1,))\n",
        "\n",
        "input_gender = keras.layers.Input(shape=(1,))\n",
        "\n",
        "input_model = [input_continue_array, input_service_type, input_mix_service, input_over_bill, input_contract_type, input_low_consume, input_net_service, input_complaint_level, input_gender]\n",
        "output_embeding = [input_continue_array, output_service_type, input_mix_service, input_over_bill, output_contract_type, input_low_consume, output_net_service, input_complaint_level, input_gender]\n",
        "output_model = keras.layers.Concatenate()(input_model)\n",
        "output_model = keras.layers.BatchNormalization()(output_model)\n",
        "#output_model = keras.layers.Dropout(0.05)(output_model)\n",
        "output_model = keras.layers.Dense(500, activation=tf.nn.relu)(output_model)\n",
        "output_model = keras.layers.BatchNormalization()(output_model)\n",
        "\n",
        "output_model = keras.layers.Dense(128, activation=tf.nn.relu)(output_model)\n",
        "output_model = keras.layers.BatchNormalization()(output_model)\n",
        "\n",
        "output_model = keras.layers.Dense(11, activation=tf.nn.sigmoid)(output_model)\n",
        "\n",
        "hard_model = keras.models.Model(inputs=input_model, outputs=output_model)\n",
        "\n",
        "hard_model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_19 (InputLayer)           (None, 17)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_20 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_21 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_22 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_23 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_24 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_25 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_26 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_27 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 25)           0           input_19[0][0]                   \n",
            "                                                                 input_20[0][0]                   \n",
            "                                                                 input_21[0][0]                   \n",
            "                                                                 input_22[0][0]                   \n",
            "                                                                 input_23[0][0]                   \n",
            "                                                                 input_24[0][0]                   \n",
            "                                                                 input_25[0][0]                   \n",
            "                                                                 input_26[0][0]                   \n",
            "                                                                 input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 25)           100         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 500)          13000       batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 500)          2000        dense_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 128)          64128       batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 128)          512         dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 11)           1419        batch_normalization_10[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 81,159\n",
            "Trainable params: 79,853\n",
            "Non-trainable params: 1,306\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FSlvYsS_uzDD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2195
        },
        "outputId": "74e80e67-756b-47e6-927a-1c50673b4657"
      },
      "cell_type": "code",
      "source": [
        "hard_model.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "hard_train_data, hard_test_data, hard_train_labels, hard_test_labels = train_test_split(hard_train_data,hard_train_labels,test_size=0.2,random_state=0)\n",
        "\n",
        "x_val = hard_train_data[:1000]\n",
        "partial_x_train = hard_train_data[1000:]\n",
        "\n",
        "y_val = hard_train_labels[:1000]\n",
        "partial_y_train = hard_train_labels[1000:]\n",
        "\n",
        "hard_history = hard_model.fit(split_features(partial_x_train),\n",
        "                    partial_y_train,\n",
        "                    epochs=60,\n",
        "                    batch_size=256,\n",
        "                    validation_data=([split_features(x_val), y_val]),\n",
        "                    verbose=1)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 52016 samples, validate on 1000 samples\n",
            "Epoch 1/60\n",
            "52016/52016 [==============================] - 3s 66us/step - loss: 1.6889 - acc: 0.3245 - val_loss: 1.5961 - val_acc: 0.3550\n",
            "Epoch 2/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 1.4339 - acc: 0.3705 - val_loss: 1.3896 - val_acc: 0.3750\n",
            "Epoch 3/60\n",
            "52016/52016 [==============================] - 3s 52us/step - loss: 1.3603 - acc: 0.3901 - val_loss: 1.3452 - val_acc: 0.3970\n",
            "Epoch 4/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 1.3072 - acc: 0.4209 - val_loss: 1.2906 - val_acc: 0.4250\n",
            "Epoch 5/60\n",
            "52016/52016 [==============================] - 3s 50us/step - loss: 1.2730 - acc: 0.4336 - val_loss: 1.2994 - val_acc: 0.4330\n",
            "Epoch 6/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 1.2504 - acc: 0.4438 - val_loss: 1.2960 - val_acc: 0.4280\n",
            "Epoch 7/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 1.2313 - acc: 0.4508 - val_loss: 1.2642 - val_acc: 0.4340\n",
            "Epoch 8/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 1.2125 - acc: 0.4627 - val_loss: 1.2603 - val_acc: 0.4530\n",
            "Epoch 9/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 1.1989 - acc: 0.4678 - val_loss: 1.2612 - val_acc: 0.4440\n",
            "Epoch 10/60\n",
            "52016/52016 [==============================] - 3s 50us/step - loss: 1.1849 - acc: 0.4745 - val_loss: 1.2876 - val_acc: 0.4470\n",
            "Epoch 11/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 1.1718 - acc: 0.4820 - val_loss: 1.2673 - val_acc: 0.4510\n",
            "Epoch 12/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 1.1562 - acc: 0.4894 - val_loss: 1.2730 - val_acc: 0.4590\n",
            "Epoch 13/60\n",
            "52016/52016 [==============================] - 3s 50us/step - loss: 1.1424 - acc: 0.4962 - val_loss: 1.2470 - val_acc: 0.4780\n",
            "Epoch 14/60\n",
            "52016/52016 [==============================] - 3s 50us/step - loss: 1.1285 - acc: 0.5041 - val_loss: 1.2556 - val_acc: 0.4570\n",
            "Epoch 15/60\n",
            "52016/52016 [==============================] - 3s 50us/step - loss: 1.1203 - acc: 0.5076 - val_loss: 1.2615 - val_acc: 0.4780\n",
            "Epoch 16/60\n",
            "52016/52016 [==============================] - 3s 49us/step - loss: 1.1061 - acc: 0.5188 - val_loss: 1.2502 - val_acc: 0.4790\n",
            "Epoch 17/60\n",
            "52016/52016 [==============================] - 3s 50us/step - loss: 1.0936 - acc: 0.5241 - val_loss: 1.2628 - val_acc: 0.4680\n",
            "Epoch 18/60\n",
            "52016/52016 [==============================] - 3s 52us/step - loss: 1.0839 - acc: 0.5275 - val_loss: 1.2756 - val_acc: 0.4860\n",
            "Epoch 19/60\n",
            "52016/52016 [==============================] - 3s 52us/step - loss: 1.0771 - acc: 0.5327 - val_loss: 1.2628 - val_acc: 0.4820\n",
            "Epoch 20/60\n",
            "52016/52016 [==============================] - 3s 52us/step - loss: 1.0606 - acc: 0.5393 - val_loss: 1.2609 - val_acc: 0.4840\n",
            "Epoch 21/60\n",
            "52016/52016 [==============================] - 3s 52us/step - loss: 1.0512 - acc: 0.5430 - val_loss: 1.2588 - val_acc: 0.4900\n",
            "Epoch 22/60\n",
            "52016/52016 [==============================] - 3s 52us/step - loss: 1.0451 - acc: 0.5471 - val_loss: 1.2673 - val_acc: 0.4880\n",
            "Epoch 23/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 1.0304 - acc: 0.5543 - val_loss: 1.2850 - val_acc: 0.4880\n",
            "Epoch 24/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 1.0185 - acc: 0.5594 - val_loss: 1.2700 - val_acc: 0.4970\n",
            "Epoch 25/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 1.0106 - acc: 0.5627 - val_loss: 1.2748 - val_acc: 0.4690\n",
            "Epoch 26/60\n",
            "52016/52016 [==============================] - 3s 52us/step - loss: 1.0008 - acc: 0.5680 - val_loss: 1.2717 - val_acc: 0.4870\n",
            "Epoch 27/60\n",
            "52016/52016 [==============================] - 3s 52us/step - loss: 0.9948 - acc: 0.5736 - val_loss: 1.2994 - val_acc: 0.4870\n",
            "Epoch 28/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 0.9838 - acc: 0.5806 - val_loss: 1.2840 - val_acc: 0.5130\n",
            "Epoch 29/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 0.9780 - acc: 0.5824 - val_loss: 1.2989 - val_acc: 0.4900\n",
            "Epoch 30/60\n",
            "52016/52016 [==============================] - 3s 52us/step - loss: 0.9685 - acc: 0.5856 - val_loss: 1.2979 - val_acc: 0.4670\n",
            "Epoch 31/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 0.9558 - acc: 0.5938 - val_loss: 1.2748 - val_acc: 0.4960\n",
            "Epoch 32/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 0.9500 - acc: 0.5952 - val_loss: 1.2987 - val_acc: 0.5000\n",
            "Epoch 33/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 0.9421 - acc: 0.5970 - val_loss: 1.2871 - val_acc: 0.4930\n",
            "Epoch 34/60\n",
            "52016/52016 [==============================] - 3s 55us/step - loss: 0.9420 - acc: 0.6001 - val_loss: 1.2875 - val_acc: 0.5060\n",
            "Epoch 35/60\n",
            "52016/52016 [==============================] - 3s 55us/step - loss: 0.9289 - acc: 0.6040 - val_loss: 1.2989 - val_acc: 0.5100\n",
            "Epoch 36/60\n",
            "52016/52016 [==============================] - 3s 54us/step - loss: 0.9199 - acc: 0.6086 - val_loss: 1.3158 - val_acc: 0.4970\n",
            "Epoch 37/60\n",
            "52016/52016 [==============================] - 3s 54us/step - loss: 0.9140 - acc: 0.6106 - val_loss: 1.2910 - val_acc: 0.5210\n",
            "Epoch 38/60\n",
            "52016/52016 [==============================] - 3s 55us/step - loss: 0.9071 - acc: 0.6148 - val_loss: 1.3115 - val_acc: 0.5130\n",
            "Epoch 39/60\n",
            "52016/52016 [==============================] - 3s 52us/step - loss: 0.9014 - acc: 0.6198 - val_loss: 1.3271 - val_acc: 0.4880\n",
            "Epoch 40/60\n",
            "52016/52016 [==============================] - 3s 50us/step - loss: 0.8979 - acc: 0.6225 - val_loss: 1.3208 - val_acc: 0.5110\n",
            "Epoch 41/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 0.8836 - acc: 0.6265 - val_loss: 1.3223 - val_acc: 0.5090\n",
            "Epoch 42/60\n",
            "52016/52016 [==============================] - 3s 50us/step - loss: 0.8870 - acc: 0.6252 - val_loss: 1.3306 - val_acc: 0.5180\n",
            "Epoch 43/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 0.8750 - acc: 0.6299 - val_loss: 1.2879 - val_acc: 0.5300\n",
            "Epoch 44/60\n",
            "52016/52016 [==============================] - 3s 50us/step - loss: 0.8720 - acc: 0.6323 - val_loss: 1.2958 - val_acc: 0.5130\n",
            "Epoch 45/60\n",
            "52016/52016 [==============================] - 3s 50us/step - loss: 0.8636 - acc: 0.6372 - val_loss: 1.3031 - val_acc: 0.5260\n",
            "Epoch 46/60\n",
            "52016/52016 [==============================] - 3s 50us/step - loss: 0.8654 - acc: 0.6343 - val_loss: 1.3381 - val_acc: 0.5130\n",
            "Epoch 47/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 0.8588 - acc: 0.6381 - val_loss: 1.3129 - val_acc: 0.5240\n",
            "Epoch 48/60\n",
            "52016/52016 [==============================] - 3s 50us/step - loss: 0.8494 - acc: 0.6441 - val_loss: 1.3040 - val_acc: 0.5360\n",
            "Epoch 49/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 0.8416 - acc: 0.6435 - val_loss: 1.3368 - val_acc: 0.5200\n",
            "Epoch 50/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 0.8403 - acc: 0.6457 - val_loss: 1.3677 - val_acc: 0.5180\n",
            "Epoch 51/60\n",
            "52016/52016 [==============================] - 3s 50us/step - loss: 0.8361 - acc: 0.6495 - val_loss: 1.3651 - val_acc: 0.5040\n",
            "Epoch 52/60\n",
            "52016/52016 [==============================] - 3s 50us/step - loss: 0.8336 - acc: 0.6489 - val_loss: 1.3293 - val_acc: 0.5110\n",
            "Epoch 53/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 0.8289 - acc: 0.6531 - val_loss: 1.3585 - val_acc: 0.4970\n",
            "Epoch 54/60\n",
            "52016/52016 [==============================] - 3s 50us/step - loss: 0.8213 - acc: 0.6550 - val_loss: 1.3484 - val_acc: 0.5100\n",
            "Epoch 55/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 0.8195 - acc: 0.6583 - val_loss: 1.3329 - val_acc: 0.5230\n",
            "Epoch 56/60\n",
            "52016/52016 [==============================] - 3s 51us/step - loss: 0.8129 - acc: 0.6600 - val_loss: 1.3692 - val_acc: 0.5340\n",
            "Epoch 57/60\n",
            "52016/52016 [==============================] - 3s 50us/step - loss: 0.8125 - acc: 0.6612 - val_loss: 1.3506 - val_acc: 0.5270\n",
            "Epoch 58/60\n",
            "52016/52016 [==============================] - 3s 49us/step - loss: 0.8081 - acc: 0.6631 - val_loss: 1.3453 - val_acc: 0.5200\n",
            "Epoch 59/60\n",
            "52016/52016 [==============================] - 3s 49us/step - loss: 0.8046 - acc: 0.6655 - val_loss: 1.3700 - val_acc: 0.5250\n",
            "Epoch 60/60\n",
            "52016/52016 [==============================] - 3s 49us/step - loss: 0.7999 - acc: 0.6661 - val_loss: 1.3465 - val_acc: 0.5280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NT0AkvE209qI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "49ee31c9-422d-415c-eec9-8c5e9501e13d"
      },
      "cell_type": "code",
      "source": [
        "results = hard_model.evaluate(split_features(hard_test_data), hard_test_labels)\n",
        "\n",
        "print(results)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13255/13255 [==============================] - 1s 61us/step\n",
            "[1.3634830422151407, 0.5004149377615845]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h0_puyqk3kAc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hard_predict = hard_model.predict(split_features(hard_train_data))\n",
        "hard_predict = np.array(hard_predict)\n",
        "hard_label_predict = np.argmax(hard_predict,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kE1WdV2Z3jM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "322b1d6c-efb8-4329-a606-e2715e77b9ec"
      },
      "cell_type": "code",
      "source": [
        "prob = np.max(hard_predict,axis=1)\n",
        "print(len(prob[prob>0.5]))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KqwxGCvV7tEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "628fbb5e-a6a5-4abd-d215-f82370e67646"
      },
      "cell_type": "code",
      "source": [
        "hard_predict_true = hard_predict[hard_label_predict==hard_train_labels]\n",
        "prob = np.max(hard_predict_true,axis=1)\n",
        "print(len(prob))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X3_RxzaAKoiZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2cde98b9-8b4c-4513-a404-5389773ecb38"
      },
      "cell_type": "code",
      "source": [
        "hard_predict_flase = hard_predict[hard_label_predict!=hard_train_labels]\n",
        "prob = np.max(hard_predict_flase,axis=1)\n",
        "print(len(prob))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15807\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}